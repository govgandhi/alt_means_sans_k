{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have modified the scripts where each clustering method and embedding method is independently added and can be called specifically based on what we specify. This notebook is to test this and make it ready for easy testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to change in this code?  \n",
    "- Create more runs\n",
    "- Parallelise the runs too\n",
    "- ~~Save the files in a separate folder experiment_mu_change_N/Run1/~~\n",
    "- Create suitable output pipeline\n",
    "- Then next experiment: do same for testing different embedding methods against proposed. Same format as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewriting it without parallelisation for Snakemake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, you can find results at:\n",
      " /nobackup/gogandhi/alt_means_sans_k/data/experiment_mu_change_1000_5_3.0\n",
      "1 0.0 8.527341777458787\n",
      "1 0.05 5.95676807872951\n",
      "1 0.1 6.453159363940358\n",
      "1 0.15 6.863448414951563\n",
      "1 0.2 6.7510784063488245\n",
      "1 0.25 7.145088411867619\n",
      "1 0.3 7.3099792674183846\n",
      "1 0.35 8.639540607109666\n",
      "1 0.4 8.212126119062304\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from itertools import cycle\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.resetwarnings() # To change it back (optional)\n",
    "\n",
    "sys.path.append(\"/nobackup/gogandhi/alt_means_sans_k/\")\n",
    "\n",
    "from scripts.similarity_scores import get_scores\n",
    "\n",
    "\n",
    "\n",
    "def process_and_save_result(run_no, mu, path_name, score_keys, device_name, emb_params, params,csv_file_path):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    if not os.path.isdir(f\"{path_name}/Run_{run_no}/\"):\n",
    "        os.mkdir(f\"{path_name}/Run_{run_no}/\")\n",
    "\n",
    "    params['mu'] = mu\n",
    "    result_run_mu = get_scores(params, emb_params, score_keys, f\"{path_name}/Run_{run_no}/\", device_name)\n",
    "    \n",
    "    with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([run_no, mu] + [result_run_mu[key] for key in score_keys])\n",
    "        \n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    \n",
    "    print(run_no,mu,elapsed_time)\n",
    "    return run_no, mu, result_run_mu\n",
    "\n",
    "def save_accumulated_results(results, pathname, score_keys):\n",
    "    for run_no, mu, result_run_mu in results:\n",
    "        df = pd.DataFrame.from_dict(result_run_mu, orient='index')\n",
    "        df.reset_index(inplace=True)\n",
    "        df.columns = ['mu'] + list(df.columns[1:])\n",
    "        df.to_csv(f\"{pathname}/Run_{run_no}/mu_{mu:.2f}_change.csv\", index=False)\n",
    "\n",
    "accumulator = []  # List to accumulate results for each run and mu\n",
    "\n",
    "params = {\n",
    "    \"N\": 1000,\n",
    "    \"k\": 5,\n",
    "    \"maxk\": 100,\n",
    "    \"minc\": 5,\n",
    "    \"maxc\": 100,\n",
    "    \"tau\": 3.0,\n",
    "    \"tau2\": 1.0,\n",
    "    \"mu\": 0.2,\n",
    "}\n",
    "\n",
    "emb_params = {\n",
    "    \"method\": \"node2vec\",\n",
    "    \"window_length\": 10,\n",
    "    \"walk_length\": 80,\n",
    "    \"num_walks\": 10,\n",
    "    \"dim\": 64,\n",
    "}\n",
    "\n",
    "#If you want to test faster for results, remove belief_prop, then optics and dbscan for now and add them separately.\n",
    "score_keys = ['kmeans','dbscan', 'optics', 'xmeans', 'infomap', 'flatsbm', 'proposed']\n",
    "\n",
    "\n",
    "num_cores = 10\n",
    "runs = np.arange(1, 11)\n",
    "#runs = [1,2]\n",
    "\n",
    "mu_values = np.round(np.arange(0, 1.05, 0.05),decimals=2)\n",
    "#mu_values = [0.6, 0.8]\n",
    "test_run=False\n",
    "\n",
    "device_names = [f\"cuda:{i}\" for i in [0,1]]  # ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']\n",
    "\n",
    "path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_mu_change_{params['N']}_{params['k']}_{params['tau']}\"\n",
    "if test_run:\n",
    "    path_name += \"_test_run\"\n",
    "\n",
    "\n",
    "#################### End of Params #################\n",
    "\n",
    "#if not os.path.isdir(path_name):\n",
    "#    os.mkdir(path_name)\n",
    "\n",
    "def create_unique_folder(base_folder):\n",
    "    if os.path.exists(base_folder):\n",
    "        index = 1\n",
    "        while True:\n",
    "            new_folder = f\"{base_folder}_{index}\"\n",
    "            if not os.path.exists(new_folder):\n",
    "                break\n",
    "            index += 1\n",
    "    else:\n",
    "        new_folder = base_folder\n",
    "\n",
    "    os.mkdir(new_folder)\n",
    "    return new_folder\n",
    "    \n",
    "path_name = create_unique_folder(path_name)\n",
    "csv_file_path = path_name + \"/result_stream.csv\"\n",
    "\n",
    "print(\"Hello, you can find results at:\\n\",path_name)\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['run_no', 'mu'] + score_keys)\n",
    "\n",
    "for run_no in runs:\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for mu, device_name in zip(mu_values, cycle(device_names)):\n",
    "        \n",
    "        run_no, mu, result_run_mu = process_and_save_result(run_no, mu, path_name, score_keys, device_name, emb_params, deepcopy(params),csv_file_path)\n",
    "        \n",
    "    print(f\"Run took: {time.perf_counter() - start_time}, avg time per mu_val: {(time.perf_counter() - start_time)/len(mu_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_mu_change_{params['N']}_{params['k']}_{params['tau']}_final\"\n",
    "# csv_file_path = path_name + \"/result_stream.csv\"\n",
    "\n",
    "result_df = pd.read_csv(csv_file_path)\n",
    "df_grouped = result_df.groupby('mu').agg(['mean', 'std'])\n",
    "plt.figure(figsize=(7,4))\n",
    "\n",
    "for column in df_grouped.columns.levels[0][1:]:\n",
    "    \n",
    "    mean_values = df_grouped[column]['mean']\n",
    "    std_values = df_grouped[column]['std']\n",
    "    \n",
    "    plt.plot(mean_values.index, mean_values, '-o',label=column)\n",
    "    plt.fill_between(mean_values.index, mean_values - std_values, mean_values + std_values, alpha=0.2)\n",
    "\n",
    "plt.xlabel(r'Mixing Parameter: $\\mu$')\n",
    "plt.ylabel('Element Centric Similarity')\n",
    "plt.legend(title=\"Algorithm\", loc='upper right', bbox_to_anchor=(1.3, 0.8))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.title(rf'Runs: {len(runs)} | Nodes: {params[\"N\"]} | $\\tau$: {params[\"tau\"]} | $<k>$: {params[\"k\"]}')\n",
    "\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f\"{path_name}/experiment_plot.png\",bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdify this so that snakemake can be used to parallelize mu and runs.\n",
    "# your_script.py\n",
    "import argparse\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Experiment: Changing Mu')\n",
    "    #parser.add_argument('--input', required=True, help='Input file path')\n",
    "    parser.add_argument('--output', required=True, help='Output file path')\n",
    "    parser.add_argument('--mu', type=float, required=True, help='Value of mu')\n",
    "    parser.add_argument('--runs', type=float, required=True, help='Value of mu')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Your script logic using args.input, args.output, and args.mu\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmeans_env",
   "language": "python",
   "name": "kmeans_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
