2023-12-09 15:38:03,823 - collecting all words and their counts
2023-12-09 15:38:03,823 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:38:03,881 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:38:03,882 - Creating a fresh vocabulary
2023-12-09 15:38:03,884 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:38:03.884040', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:38:03,884 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:38:03.884138', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:38:03,887 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:38:03,887 - sample=0.001 downsamples 37 most-common words
2023-12-09 15:38:03,887 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 774968.4671231643 word corpus (96.9%% of prior 800000)', 'datetime': '2023-12-09T15:38:03.887281', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:38:03,892 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:38:03,892 - resetting layer weights
2023-12-09 15:38:03,892 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:38:03.892730', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:38:03,892 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:38:03.892954', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:38:04,961 - EPOCH 0 - PROGRESS: at 46.25% examples, 336702 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:38:05,993 - EPOCH 0 - PROGRESS: at 96.25% examples, 355823 words/s, in_qsize 3, out_qsize 1
2023-12-09 15:38:06,005 - EPOCH 0: training on 800000 raw words (775208 effective words) took 2.1s, 367474 effective words/s
2023-12-09 15:38:06,006 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (775208 effective words) took 2.1s, 366872 effective words/s', 'datetime': '2023-12-09T15:38:06.006027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:38:06,006 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:38:06.006093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:40:03,874 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 121.19 seconds
2023-12-09 15:40:58,898 - collecting all words and their counts
2023-12-09 15:40:58,898 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:40:58,957 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:40:58,957 - Creating a fresh vocabulary
2023-12-09 15:40:58,959 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:40:58.959747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:40:58,959 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:40:58.959849', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:40:58,962 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:40:58,962 - sample=0.001 downsamples 38 most-common words
2023-12-09 15:40:58,962 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 768904.170667134 word corpus (96.1%% of prior 800000)', 'datetime': '2023-12-09T15:40:58.962887', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:40:58,967 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:40:58,967 - resetting layer weights
2023-12-09 15:40:58,968 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:40:58.968054', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:40:58,968 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:40:58.968567', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:41:00,007 - EPOCH 0 - PROGRESS: at 46.25% examples, 343654 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:41:01,032 - EPOCH 0 - PROGRESS: at 96.25% examples, 359274 words/s, in_qsize 3, out_qsize 1
2023-12-09 15:41:01,076 - EPOCH 0: training on 800000 raw words (768709 effective words) took 2.1s, 365427 effective words/s
2023-12-09 15:41:01,076 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (768709 effective words) took 2.1s, 364770 effective words/s', 'datetime': '2023-12-09T15:41:01.076511', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:41:01,076 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:41:01.076725', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:43:33,314 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 154.80 seconds
2023-12-09 15:45:40,612 - collecting all words and their counts
2023-12-09 15:45:40,612 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:45:40,671 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:45:40,671 - Creating a fresh vocabulary
2023-12-09 15:45:40,673 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:45:40.673582', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:45:40,673 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:45:40.673675', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:45:40,676 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:45:40,676 - sample=0.001 downsamples 38 most-common words
2023-12-09 15:45:40,676 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 766796.3892618972 word corpus (95.8%% of prior 800000)', 'datetime': '2023-12-09T15:45:40.676695', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:45:40,681 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:45:40,681 - resetting layer weights
2023-12-09 15:45:40,681 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:45:40.681894', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:45:40,682 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:45:40.682416', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:45:41,726 - EPOCH 0 - PROGRESS: at 46.25% examples, 341093 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:45:42,738 - EPOCH 0 - PROGRESS: at 96.25% examples, 359652 words/s, in_qsize 3, out_qsize 1
2023-12-09 15:45:42,760 - EPOCH 0: training on 800000 raw words (766929 effective words) took 2.1s, 369814 effective words/s
2023-12-09 15:45:42,760 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (766929 effective words) took 2.1s, 369135 effective words/s', 'datetime': '2023-12-09T15:45:42.760550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:45:42,760 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:45:42.760756', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:48:36,445 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 176.19 seconds
2023-12-09 15:48:36,905 - collecting all words and their counts
2023-12-09 15:48:36,905 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:48:36,964 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:48:36,964 - Creating a fresh vocabulary
2023-12-09 15:48:36,966 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:48:36.966407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:48:36,966 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:48:36.966478', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:48:36,969 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:48:36,969 - sample=0.001 downsamples 40 most-common words
2023-12-09 15:48:36,969 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 768736.2397049093 word corpus (96.1%% of prior 800000)', 'datetime': '2023-12-09T15:48:36.969562', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:48:36,974 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:48:36,974 - resetting layer weights
2023-12-09 15:48:36,974 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:48:36.974868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:48:36,975 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:48:36.975372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:48:38,029 - EPOCH 0 - PROGRESS: at 46.25% examples, 338157 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:48:39,047 - EPOCH 0 - PROGRESS: at 96.25% examples, 357638 words/s, in_qsize 3, out_qsize 1
2023-12-09 15:48:39,063 - EPOCH 0: training on 800000 raw words (768413 effective words) took 2.1s, 368578 effective words/s
2023-12-09 15:48:39,064 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (768413 effective words) took 2.1s, 367887 effective words/s', 'datetime': '2023-12-09T15:48:39.064166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:48:39,064 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:48:39.064335', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:52:12,500 - Processed run 1 for mu=0.8 on cuda:2. Elapsed time: 216.05 seconds
2023-12-09 15:52:12,938 - collecting all words and their counts
2023-12-09 15:52:12,938 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:52:12,998 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:52:12,998 - Creating a fresh vocabulary
2023-12-09 15:52:13,000 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:52:13.000491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:52:13,000 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:52:13.000565', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:52:13,003 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:52:13,003 - sample=0.001 downsamples 40 most-common words
2023-12-09 15:52:13,003 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 772157.2349547147 word corpus (96.5%% of prior 800000)', 'datetime': '2023-12-09T15:52:13.003587', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:52:13,008 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:52:13,008 - resetting layer weights
2023-12-09 15:52:13,008 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:52:13.008757', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:52:13,009 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:52:13.009139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:52:14,074 - EPOCH 0 - PROGRESS: at 46.25% examples, 336398 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:52:15,107 - EPOCH 0 - PROGRESS: at 96.25% examples, 354666 words/s, in_qsize 3, out_qsize 1
2023-12-09 15:52:15,117 - EPOCH 0: training on 800000 raw words (772117 effective words) took 2.1s, 366745 effective words/s
2023-12-09 15:52:15,118 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (772117 effective words) took 2.1s, 366148 effective words/s', 'datetime': '2023-12-09T15:52:15.117972', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:52:15,118 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:52:15.118142', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:55:09,251 - Processed run 2 for mu=0.6 on cuda:1. Elapsed time: 176.75 seconds
2023-12-09 15:55:09,627 - collecting all words and their counts
2023-12-09 15:55:09,627 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 15:55:09,689 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 15:55:09,689 - Creating a fresh vocabulary
2023-12-09 15:55:09,691 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T15:55:09.691334', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:55:09,691 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T15:55:09.691400', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:55:09,694 - deleting the raw counts dictionary of 1000 items
2023-12-09 15:55:09,694 - sample=0.001 downsamples 30 most-common words
2023-12-09 15:55:09,694 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 783047.6270621106 word corpus (97.9%% of prior 800000)', 'datetime': '2023-12-09T15:55:09.694488', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 15:55:09,699 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 15:55:09,699 - resetting layer weights
2023-12-09 15:55:09,699 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T15:55:09.699702', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 15:55:09,700 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T15:55:09.700224', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:55:10,703 - EPOCH 0 - PROGRESS: at 47.50% examples, 371802 words/s, in_qsize 7, out_qsize 0
2023-12-09 15:55:11,681 - EPOCH 0: training on 800000 raw words (782968 effective words) took 2.0s, 395883 effective words/s
2023-12-09 15:55:11,681 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (782968 effective words) took 2.0s, 395219 effective words/s', 'datetime': '2023-12-09T15:55:11.681474', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 15:55:11,681 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T15:55:11.681592', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 15:57:46,823 - Processed run 2 for mu=0.8 on cuda:2. Elapsed time: 157.57 seconds
2023-12-09 16:18:44,719 - collecting all words and their counts
2023-12-09 16:18:44,719 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:18:44,779 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:18:44,779 - Creating a fresh vocabulary
2023-12-09 16:18:44,781 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:18:44.781387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:18:44,781 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:18:44.781474', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:18:44,784 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:18:44,784 - sample=0.001 downsamples 35 most-common words
2023-12-09 16:18:44,784 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 766883.1543335504 word corpus (95.9%% of prior 800000)', 'datetime': '2023-12-09T16:18:44.784823', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:18:44,789 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:18:44,790 - resetting layer weights
2023-12-09 16:18:44,790 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:18:44.790524', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:18:44,790 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:18:44.790775', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:18:45,821 - EPOCH 0 - PROGRESS: at 46.25% examples, 345213 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:18:46,827 - EPOCH 0 - PROGRESS: at 96.25% examples, 363013 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:18:46,863 - EPOCH 0: training on 800000 raw words (766917 effective words) took 2.1s, 370685 effective words/s
2023-12-09 16:18:46,863 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (766917 effective words) took 2.1s, 370031 effective words/s', 'datetime': '2023-12-09T16:18:46.863421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:18:46,863 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:18:46.863603', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:19:50,025 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 66.43 seconds
2023-12-09 16:19:50,413 - collecting all words and their counts
2023-12-09 16:19:50,413 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:19:50,474 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:19:50,474 - Creating a fresh vocabulary
2023-12-09 16:19:50,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:19:50.476454', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:19:50,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:19:50.476547', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:19:50,479 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:19:50,479 - sample=0.001 downsamples 49 most-common words
2023-12-09 16:19:50,479 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 760399.7937619879 word corpus (95.0%% of prior 800000)', 'datetime': '2023-12-09T16:19:50.479607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:19:50,484 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:19:50,484 - resetting layer weights
2023-12-09 16:19:50,484 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:19:50.484876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:19:50,485 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:19:50.485237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:19:51,507 - EPOCH 0 - PROGRESS: at 46.25% examples, 345193 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:19:52,518 - EPOCH 0 - PROGRESS: at 96.25% examples, 360483 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:19:52,555 - EPOCH 0: training on 800000 raw words (760347 effective words) took 2.1s, 367826 effective words/s
2023-12-09 16:19:52,556 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (760347 effective words) took 2.1s, 367182 effective words/s', 'datetime': '2023-12-09T16:19:52.556080', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:19:52,556 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:19:52.556258', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:39:11,980 - collecting all words and their counts
2023-12-09 16:39:11,980 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:39:12,039 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:39:12,039 - Creating a fresh vocabulary
2023-12-09 16:39:12,041 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:39:12.041443', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:12,041 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:39:12.041544', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:12,044 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:39:12,044 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:39:12,044 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:39:12.044566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:12,049 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:39:12,049 - resetting layer weights
2023-12-09 16:39:12,049 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:39:12.049870', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:39:12,050 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:39:12.050168', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:13,073 - EPOCH 0 - PROGRESS: at 46.25% examples, 362849 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:14,077 - EPOCH 0 - PROGRESS: at 96.25% examples, 380545 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:39:14,102 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 390414 effective words/s
2023-12-09 16:39:14,103 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 389719 effective words/s', 'datetime': '2023-12-09T16:39:14.103001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:14,103 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:39:14.103172', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:39:25,174 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 15.11 seconds
2023-12-09 16:39:27,032 - collecting all words and their counts
2023-12-09 16:39:27,032 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:39:27,090 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:39:27,090 - Creating a fresh vocabulary
2023-12-09 16:39:27,092 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:39:27.092407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:27,092 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:39:27.092525', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:27,095 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:39:27,095 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:39:27,095 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:39:27.095430', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:27,100 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:39:27,100 - resetting layer weights
2023-12-09 16:39:27,100 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:39:27.100485', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:39:27,101 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:39:27.101037', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:28,115 - EPOCH 0 - PROGRESS: at 45.00% examples, 356508 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:29,165 - EPOCH 0 - PROGRESS: at 91.25% examples, 354353 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:29,279 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367948 effective words/s
2023-12-09 16:39:29,279 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367300 effective words/s', 'datetime': '2023-12-09T16:39:29.279559', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:29,279 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:39:29.279629', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:39:41,832 - Processed run 1 for mu=0.8 on cuda:2. Elapsed time: 16.66 seconds
2023-12-09 16:39:43,262 - collecting all words and their counts
2023-12-09 16:39:43,262 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:39:43,321 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:39:43,321 - Creating a fresh vocabulary
2023-12-09 16:39:43,323 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:39:43.323173', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:43,323 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:39:43.323266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:43,326 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:39:43,326 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:39:43,326 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:39:43.326191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:43,330 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:39:43,330 - resetting layer weights
2023-12-09 16:39:43,331 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:39:43.331287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:39:43,331 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:39:43.331871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:44,337 - EPOCH 0 - PROGRESS: at 45.00% examples, 359571 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:45,378 - EPOCH 0 - PROGRESS: at 91.25% examples, 357577 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:45,506 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368651 effective words/s
2023-12-09 16:39:45,506 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367898 effective words/s', 'datetime': '2023-12-09T16:39:45.506952', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:45,507 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:39:45.507128', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:39:52,518 - Processed run 2 for mu=0.6 on cuda:1. Elapsed time: 10.68 seconds
2023-12-09 16:39:54,229 - collecting all words and their counts
2023-12-09 16:39:54,229 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:39:54,290 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:39:54,290 - Creating a fresh vocabulary
2023-12-09 16:39:54,292 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:39:54.292119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:54,292 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:39:54.292199', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:54,294 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:39:54,295 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:39:54,295 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:39:54.295044', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:39:54,299 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:39:54,299 - resetting layer weights
2023-12-09 16:39:54,300 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:39:54.299979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:39:54,300 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:39:54.300484', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:55,326 - EPOCH 0 - PROGRESS: at 46.25% examples, 362097 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:39:56,329 - EPOCH 0 - PROGRESS: at 96.25% examples, 380218 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:39:56,350 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 390967 effective words/s
2023-12-09 16:39:56,350 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390284 effective words/s', 'datetime': '2023-12-09T16:39:56.350850', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:39:56,351 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:39:56.351020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:40:08,704 - Processed run 2 for mu=0.8 on cuda:2. Elapsed time: 16.18 seconds
2023-12-09 16:51:13,048 - collecting all words and their counts
2023-12-09 16:51:13,048 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:51:13,108 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:51:13,109 - Creating a fresh vocabulary
2023-12-09 16:51:13,111 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:51:13.111007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:13,111 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:51:13.111093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:13,113 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:51:13,113 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:51:13,114 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:51:13.114021', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:13,118 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:51:13,118 - resetting layer weights
2023-12-09 16:51:13,119 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:51:13.119243', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:51:13,119 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:51:13.119668', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:14,150 - EPOCH 0 - PROGRESS: at 41.25% examples, 321188 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:51:15,172 - EPOCH 0 - PROGRESS: at 86.25% examples, 336622 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:51:15,407 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350154 effective words/s
2023-12-09 16:51:15,407 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349625 effective words/s', 'datetime': '2023-12-09T16:51:15.407912', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:15,408 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:51:15.408090', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:51:25,232 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 13.53 seconds
2023-12-09 16:51:27,105 - collecting all words and their counts
2023-12-09 16:51:27,105 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:51:27,165 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:51:27,165 - Creating a fresh vocabulary
2023-12-09 16:51:27,167 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:51:27.167762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:27,167 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:51:27.167833', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:27,170 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:51:27,170 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:51:27,170 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:51:27.170625', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:27,175 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:51:27,175 - resetting layer weights
2023-12-09 16:51:27,175 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:51:27.175672', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:51:27,176 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:51:27.176195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:28,206 - EPOCH 0 - PROGRESS: at 41.25% examples, 321362 words/s, in_qsize 7, out_qsize 1
2023-12-09 16:51:29,214 - EPOCH 0 - PROGRESS: at 87.50% examples, 343930 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:51:29,442 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353511 effective words/s
2023-12-09 16:51:29,442 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352984 effective words/s', 'datetime': '2023-12-09T16:51:29.442660', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:29,442 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:51:29.442835', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:51:46,857 - Processed run 1 for mu=0.8 on cuda:2. Elapsed time: 21.62 seconds
2023-12-09 16:51:48,181 - collecting all words and their counts
2023-12-09 16:51:48,181 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:51:48,244 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:51:48,244 - Creating a fresh vocabulary
2023-12-09 16:51:48,246 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:51:48.246869', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:48,246 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:51:48.246954', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:48,249 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:51:48,249 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:51:48,249 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:51:48.249874', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:48,254 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:51:48,254 - resetting layer weights
2023-12-09 16:51:48,255 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:51:48.255146', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:51:48,255 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:51:48.255444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:49,282 - EPOCH 0 - PROGRESS: at 41.25% examples, 322325 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:51:50,299 - EPOCH 0 - PROGRESS: at 86.25% examples, 338059 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:51:50,534 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351443 effective words/s
2023-12-09 16:51:50,535 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350933 effective words/s', 'datetime': '2023-12-09T16:51:50.535155', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:51:50,535 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:51:50.535336', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:51:57,403 - Processed run 2 for mu=0.6 on cuda:1. Elapsed time: 10.54 seconds
2023-12-09 16:51:59,220 - collecting all words and their counts
2023-12-09 16:51:59,220 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:51:59,281 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:51:59,281 - Creating a fresh vocabulary
2023-12-09 16:51:59,283 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:51:59.283331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:59,283 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:51:59.283414', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:59,286 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:51:59,286 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:51:59,286 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:51:59.286285', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:51:59,291 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:51:59,291 - resetting layer weights
2023-12-09 16:51:59,291 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:51:59.291455', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:51:59,291 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:51:59.291915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:52:00,310 - EPOCH 0 - PROGRESS: at 41.25% examples, 324910 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:52:01,345 - EPOCH 0 - PROGRESS: at 86.25% examples, 336570 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:52:01,575 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350818 effective words/s
2023-12-09 16:52:01,575 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350274 effective words/s', 'datetime': '2023-12-09T16:52:01.575922', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:52:01,576 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:52:01.576179', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:52:12,656 - Processed run 2 for mu=0.8 on cuda:2. Elapsed time: 15.25 seconds
2023-12-09 16:52:51,532 - collecting all words and their counts
2023-12-09 16:52:51,532 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:52:51,590 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:52:51,590 - Creating a fresh vocabulary
2023-12-09 16:52:51,592 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:52:51.592717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:51,592 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:52:51.592792', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:51,595 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:52:51,595 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:52:51,595 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:52:51.595629', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:51,600 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:52:51,600 - resetting layer weights
2023-12-09 16:52:51,600 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:52:51.600665', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:52:51,601 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:52:51.601187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:52:52,639 - EPOCH 0 - PROGRESS: at 56.25% examples, 434954 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:52:53,211 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 497794 effective words/s
2023-12-09 16:52:53,211 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 496707 effective words/s', 'datetime': '2023-12-09T16:52:53.211868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:52:53,212 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:52:53.212050', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:52:57,187 - Processed run 1 for mu=0.0 on cuda:1. Elapsed time: 6.69 seconds
2023-12-09 16:52:58,181 - collecting all words and their counts
2023-12-09 16:52:58,181 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:52:58,239 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:52:58,239 - Creating a fresh vocabulary
2023-12-09 16:52:58,241 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:52:58.241204', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:58,241 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:52:58.241282', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:58,244 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:52:58,244 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:52:58,244 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:52:58.244221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:52:58,248 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:52:58,248 - resetting layer weights
2023-12-09 16:52:58,249 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:52:58.249335', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:52:58,249 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:52:58.249794', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:52:59,283 - EPOCH 0 - PROGRESS: at 41.25% examples, 320167 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:00,291 - EPOCH 0 - PROGRESS: at 87.50% examples, 343475 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:00,530 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351300 effective words/s
2023-12-09 16:53:00,530 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350772 effective words/s', 'datetime': '2023-12-09T16:53:00.530558', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:00,530 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:00.530744', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:04,902 - Processed run 1 for mu=0.05 on cuda:2. Elapsed time: 7.71 seconds
2023-12-09 16:53:05,891 - collecting all words and their counts
2023-12-09 16:53:05,892 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:05,951 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:05,951 - Creating a fresh vocabulary
2023-12-09 16:53:05,953 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:05.953573', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:05,953 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:05.953663', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:05,956 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:05,956 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:05,956 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:05.956675', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:05,961 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:05,961 - resetting layer weights
2023-12-09 16:53:05,961 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:05.961824', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:05,962 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:05.962307', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:06,978 - EPOCH 0 - PROGRESS: at 41.25% examples, 325631 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:07,979 - EPOCH 0 - PROGRESS: at 87.50% examples, 347504 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:08,214 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355635 effective words/s
2023-12-09 16:53:08,215 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355112 effective words/s', 'datetime': '2023-12-09T16:53:08.215191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:08,215 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:08.215385', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:13,000 - Processed run 1 for mu=0.1 on cuda:3. Elapsed time: 8.10 seconds
2023-12-09 16:53:13,796 - collecting all words and their counts
2023-12-09 16:53:13,796 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:13,855 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:13,855 - Creating a fresh vocabulary
2023-12-09 16:53:13,857 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:13.857814', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:13,857 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:13.857886', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:13,860 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:13,860 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:13,860 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:13.860775', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:13,865 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:13,865 - resetting layer weights
2023-12-09 16:53:13,865 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:13.865979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:13,866 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:13.866450', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:14,892 - EPOCH 0 - PROGRESS: at 41.25% examples, 322737 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:15,897 - EPOCH 0 - PROGRESS: at 87.50% examples, 345193 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:16,131 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353721 effective words/s
2023-12-09 16:53:16,131 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353187 effective words/s', 'datetime': '2023-12-09T16:53:16.131611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:16,131 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:16.131785', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:20,686 - Processed run 1 for mu=0.15 on cuda:4. Elapsed time: 7.68 seconds
2023-12-09 16:53:21,536 - collecting all words and their counts
2023-12-09 16:53:21,536 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:21,594 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:21,594 - Creating a fresh vocabulary
2023-12-09 16:53:21,596 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:21.596634', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:21,596 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:21.596704', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:21,599 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:21,599 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:21,599 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:21.599574', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:21,604 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:21,604 - resetting layer weights
2023-12-09 16:53:21,604 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:21.604621', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:21,605 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:21.605039', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:22,653 - EPOCH 0 - PROGRESS: at 46.25% examples, 354136 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:23,677 - EPOCH 0 - PROGRESS: at 96.25% examples, 372188 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:53:23,692 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383735 effective words/s
2023-12-09 16:53:23,693 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383128 effective words/s', 'datetime': '2023-12-09T16:53:23.693187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:23,693 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:23.693358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:28,676 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 7.99 seconds
2023-12-09 16:53:29,662 - collecting all words and their counts
2023-12-09 16:53:29,662 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:29,721 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:29,722 - Creating a fresh vocabulary
2023-12-09 16:53:29,723 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:29.723847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:29,723 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:29.723918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:29,726 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:29,726 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:29,726 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:29.726744', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:29,731 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:29,731 - resetting layer weights
2023-12-09 16:53:29,731 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:29.731885', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:29,732 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:29.732358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:30,755 - EPOCH 0 - PROGRESS: at 41.25% examples, 323647 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:53:31,773 - EPOCH 0 - PROGRESS: at 87.50% examples, 343422 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:53:32,010 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351666 effective words/s
2023-12-09 16:53:32,010 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351138 effective words/s', 'datetime': '2023-12-09T16:53:32.010739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:32,010 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:32.010929', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:37,206 - Processed run 1 for mu=0.25 on cuda:2. Elapsed time: 8.53 seconds
2023-12-09 16:53:38,104 - collecting all words and their counts
2023-12-09 16:53:38,104 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:38,164 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:38,164 - Creating a fresh vocabulary
2023-12-09 16:53:38,166 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:38.166059', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:38,166 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:38.166135', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:38,169 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:38,169 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:38,169 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:38.169108', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:38,173 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:38,173 - resetting layer weights
2023-12-09 16:53:38,174 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:38.174253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:38,174 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:38.174671', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:39,179 - EPOCH 0 - PROGRESS: at 41.25% examples, 329485 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:53:40,209 - EPOCH 0 - PROGRESS: at 87.50% examples, 344627 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:40,450 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352048 effective words/s
2023-12-09 16:53:40,450 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351509 effective words/s', 'datetime': '2023-12-09T16:53:40.450644', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:40,450 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:40.450825', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:45,962 - Processed run 1 for mu=0.3 on cuda:3. Elapsed time: 8.76 seconds
2023-12-09 16:53:46,932 - collecting all words and their counts
2023-12-09 16:53:46,932 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:46,990 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:46,991 - Creating a fresh vocabulary
2023-12-09 16:53:46,992 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:46.992970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:46,993 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:46.993040', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:46,995 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:46,995 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:46,995 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:46.995949', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:47,000 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:47,000 - resetting layer weights
2023-12-09 16:53:47,001 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:47.001073', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:47,001 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:47.001427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:48,025 - EPOCH 0 - PROGRESS: at 46.25% examples, 362422 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:49,028 - EPOCH 0 - PROGRESS: at 96.25% examples, 380474 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:53:49,049 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 391243 effective words/s
2023-12-09 16:53:49,049 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390609 effective words/s', 'datetime': '2023-12-09T16:53:49.049568', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:49,049 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:49.049636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:53:54,060 - Processed run 1 for mu=0.35 on cuda:4. Elapsed time: 8.10 seconds
2023-12-09 16:53:55,148 - collecting all words and their counts
2023-12-09 16:53:55,148 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:53:55,208 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:53:55,208 - Creating a fresh vocabulary
2023-12-09 16:53:55,210 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:53:55.210536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:55,210 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:53:55.210602', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:55,213 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:53:55,213 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:53:55,213 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:53:55.213554', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:53:55,218 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:53:55,218 - resetting layer weights
2023-12-09 16:53:55,218 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:53:55.218633', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:53:55,219 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:53:55.219113', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:56,227 - EPOCH 0 - PROGRESS: at 42.50% examples, 338339 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:57,277 - EPOCH 0 - PROGRESS: at 90.00% examples, 350410 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:53:57,472 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355601 effective words/s
2023-12-09 16:53:57,472 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355074 effective words/s', 'datetime': '2023-12-09T16:53:57.472236', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:53:57,472 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:53:57.472377', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:04,426 - Processed run 1 for mu=0.4 on cuda:1. Elapsed time: 10.37 seconds
2023-12-09 16:54:05,503 - collecting all words and their counts
2023-12-09 16:54:05,503 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:05,563 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:05,563 - Creating a fresh vocabulary
2023-12-09 16:54:05,565 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:05.565429', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:05,565 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:05.565520', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:05,568 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:05,568 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:05,568 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:05.568418', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:05,573 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:05,573 - resetting layer weights
2023-12-09 16:54:05,573 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:05.573543', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:05,574 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:05.573989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:06,599 - EPOCH 0 - PROGRESS: at 41.25% examples, 322892 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:07,616 - EPOCH 0 - PROGRESS: at 86.25% examples, 338349 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:07,873 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348381 effective words/s
2023-12-09 16:54:07,873 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347873 effective words/s', 'datetime': '2023-12-09T16:54:07.873741', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:07,873 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:54:07.873859', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:13,808 - Processed run 1 for mu=0.45 on cuda:2. Elapsed time: 9.38 seconds
2023-12-09 16:54:14,956 - collecting all words and their counts
2023-12-09 16:54:14,956 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:15,015 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:15,015 - Creating a fresh vocabulary
2023-12-09 16:54:15,017 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:15.017665', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:15,017 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:15.017759', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:15,020 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:15,020 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:15,020 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:15.020670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:15,025 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:15,025 - resetting layer weights
2023-12-09 16:54:15,025 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:15.025784', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:15,026 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:15.026239', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:16,071 - EPOCH 0 - PROGRESS: at 46.25% examples, 355148 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:17,091 - EPOCH 0 - PROGRESS: at 96.25% examples, 373515 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:54:17,113 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383897 effective words/s
2023-12-09 16:54:17,114 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383225 effective words/s', 'datetime': '2023-12-09T16:54:17.114215', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:17,114 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:54:17.114389', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:23,296 - Processed run 1 for mu=0.5 on cuda:3. Elapsed time: 9.49 seconds
2023-12-09 16:54:24,572 - collecting all words and their counts
2023-12-09 16:54:24,572 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:24,631 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:24,631 - Creating a fresh vocabulary
2023-12-09 16:54:24,633 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:24.633407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:24,633 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:24.633476', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:24,636 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:24,636 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:24,636 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:24.636314', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:24,641 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:24,641 - resetting layer weights
2023-12-09 16:54:24,641 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:24.641475', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:24,641 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:24.641903', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:25,663 - EPOCH 0 - PROGRESS: at 41.25% examples, 324078 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:26,675 - EPOCH 0 - PROGRESS: at 87.50% examples, 344757 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:26,933 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349550 effective words/s
2023-12-09 16:54:26,934 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349032 effective words/s', 'datetime': '2023-12-09T16:54:26.934029', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:26,934 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:54:26.934219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:33,586 - Processed run 1 for mu=0.55 on cuda:4. Elapsed time: 10.29 seconds
2023-12-09 16:54:35,016 - collecting all words and their counts
2023-12-09 16:54:35,016 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:35,075 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:35,075 - Creating a fresh vocabulary
2023-12-09 16:54:35,077 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:35.077834', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:35,077 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:35.077915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:35,080 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:35,080 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:35,080 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:35.080747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:35,085 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:35,085 - resetting layer weights
2023-12-09 16:54:35,085 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:35.085761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:35,086 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:35.086192', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:36,102 - EPOCH 0 - PROGRESS: at 42.50% examples, 335691 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:37,185 - EPOCH 0 - PROGRESS: at 91.25% examples, 348340 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:37,318 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358964 effective words/s
2023-12-09 16:54:37,318 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358426 effective words/s', 'datetime': '2023-12-09T16:54:37.318247', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:37,318 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:54:37.318426', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:44,976 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 11.39 seconds
2023-12-09 16:54:46,424 - collecting all words and their counts
2023-12-09 16:54:46,424 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:46,484 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:46,484 - Creating a fresh vocabulary
2023-12-09 16:54:46,486 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:46.486283', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:46,486 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:46.486357', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:46,489 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:46,489 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:46,489 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:46.489270', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:46,493 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:46,494 - resetting layer weights
2023-12-09 16:54:46,494 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:46.494358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:46,494 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:46.494802', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:47,528 - EPOCH 0 - PROGRESS: at 41.25% examples, 320341 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:48,528 - EPOCH 0 - PROGRESS: at 86.25% examples, 339774 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:54:48,763 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353118 effective words/s
2023-12-09 16:54:48,763 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352604 effective words/s', 'datetime': '2023-12-09T16:54:48.763691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:54:48,763 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:54:48.763773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:54:57,457 - Processed run 1 for mu=0.65 on cuda:2. Elapsed time: 12.48 seconds
2023-12-09 16:54:59,164 - collecting all words and their counts
2023-12-09 16:54:59,165 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:54:59,225 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:54:59,225 - Creating a fresh vocabulary
2023-12-09 16:54:59,227 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:54:59.227693', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:59,227 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:54:59.227768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:59,230 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:54:59,230 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:54:59,230 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:54:59.230680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:54:59,235 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:54:59,235 - resetting layer weights
2023-12-09 16:54:59,235 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:54:59.235727', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:54:59,236 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:54:59.236246', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:00,259 - EPOCH 0 - PROGRESS: at 41.25% examples, 323641 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:01,269 - EPOCH 0 - PROGRESS: at 86.25% examples, 339943 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:01,522 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350390 effective words/s
2023-12-09 16:55:01,522 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349872 effective words/s', 'datetime': '2023-12-09T16:55:01.522872', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:01,523 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:55:01.523058', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:55:10,058 - Processed run 1 for mu=0.7 on cuda:3. Elapsed time: 12.60 seconds
2023-12-09 16:55:11,688 - collecting all words and their counts
2023-12-09 16:55:11,688 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:55:11,747 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:55:11,747 - Creating a fresh vocabulary
2023-12-09 16:55:11,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:55:11.749032', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:11,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:55:11.749101', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:11,751 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:55:11,751 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:55:11,751 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:55:11.751966', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:11,756 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:55:11,756 - resetting layer weights
2023-12-09 16:55:11,757 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:55:11.757077', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:55:11,757 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:55:11.757479', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:12,768 - EPOCH 0 - PROGRESS: at 42.50% examples, 337400 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:13,770 - EPOCH 0 - PROGRESS: at 88.75% examples, 353240 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:14,004 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356509 effective words/s
2023-12-09 16:55:14,004 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355977 effective words/s', 'datetime': '2023-12-09T16:55:14.004887', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:14,005 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:55:14.005069', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:55:25,230 - Processed run 1 for mu=0.75 on cuda:4. Elapsed time: 15.17 seconds
2023-12-09 16:55:27,093 - collecting all words and their counts
2023-12-09 16:55:27,093 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:55:27,151 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:55:27,151 - Creating a fresh vocabulary
2023-12-09 16:55:27,153 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:55:27.153867', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:27,153 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:55:27.153942', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:27,156 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:55:27,156 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:55:27,156 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:55:27.156859', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:27,161 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:55:27,161 - resetting layer weights
2023-12-09 16:55:27,161 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:55:27.161943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:55:27,162 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:55:27.162414', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:28,188 - EPOCH 0 - PROGRESS: at 41.25% examples, 322716 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:29,202 - EPOCH 0 - PROGRESS: at 86.25% examples, 338751 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:29,461 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348398 effective words/s
2023-12-09 16:55:29,462 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347896 effective words/s', 'datetime': '2023-12-09T16:55:29.462013', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:29,462 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:55:29.462140', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:55:39,856 - Processed run 1 for mu=0.8 on cuda:1. Elapsed time: 14.62 seconds
2023-12-09 16:55:41,875 - collecting all words and their counts
2023-12-09 16:55:41,875 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:55:41,935 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:55:41,935 - Creating a fresh vocabulary
2023-12-09 16:55:41,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:55:41.937635', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:41,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:55:41.937715', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:41,940 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:55:41,940 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:55:41,940 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:55:41.940536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:41,945 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:55:41,945 - resetting layer weights
2023-12-09 16:55:41,945 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:55:41.945597', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:55:41,946 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:55:41.946000', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:42,955 - EPOCH 0 - PROGRESS: at 42.50% examples, 337958 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:55:44,048 - EPOCH 0 - PROGRESS: at 91.25% examples, 347715 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:44,168 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360519 effective words/s
2023-12-09 16:55:44,168 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359982 effective words/s', 'datetime': '2023-12-09T16:55:44.168407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:44,168 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:55:44.168592', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:55:55,418 - Processed run 1 for mu=0.85 on cuda:2. Elapsed time: 15.56 seconds
2023-12-09 16:55:57,563 - collecting all words and their counts
2023-12-09 16:55:57,563 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:55:57,623 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:55:57,624 - Creating a fresh vocabulary
2023-12-09 16:55:57,625 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:55:57.625974', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:57,626 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:55:57.626060', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:57,628 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:55:57,628 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:55:57,629 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:55:57.628996', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:55:57,633 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:55:57,633 - resetting layer weights
2023-12-09 16:55:57,634 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:55:57.634166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:55:57,634 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:55:57.634688', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:58,674 - EPOCH 0 - PROGRESS: at 41.25% examples, 318351 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:59,690 - EPOCH 0 - PROGRESS: at 86.25% examples, 336104 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:55:59,940 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 347401 effective words/s
2023-12-09 16:55:59,941 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 346883 effective words/s', 'datetime': '2023-12-09T16:55:59.941016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:55:59,941 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:55:59.941201', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:56:12,350 - Processed run 1 for mu=0.9 on cuda:3. Elapsed time: 16.93 seconds
2023-12-09 16:56:14,568 - collecting all words and their counts
2023-12-09 16:56:14,569 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:56:14,630 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:56:14,630 - Creating a fresh vocabulary
2023-12-09 16:56:14,632 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:56:14.632868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:14,632 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:56:14.632946', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:14,635 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:56:14,635 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:56:14,635 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:56:14.635889', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:14,640 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:56:14,640 - resetting layer weights
2023-12-09 16:56:14,641 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:56:14.640996', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:56:14,641 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:56:14.641398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:15,658 - EPOCH 0 - PROGRESS: at 41.25% examples, 325376 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:16,692 - EPOCH 0 - PROGRESS: at 90.00% examples, 351594 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:16,900 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354550 effective words/s
2023-12-09 16:56:16,901 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354015 effective words/s', 'datetime': '2023-12-09T16:56:16.901265', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:16,901 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:56:16.901451', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:56:29,641 - Processed run 1 for mu=0.95 on cuda:4. Elapsed time: 17.29 seconds
2023-12-09 16:56:32,079 - collecting all words and their counts
2023-12-09 16:56:32,079 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:56:32,139 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:56:32,139 - Creating a fresh vocabulary
2023-12-09 16:56:32,141 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:56:32.141530', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:32,141 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:56:32.141599', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:32,144 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:56:32,144 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:56:32,144 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:56:32.144491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:32,149 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:56:32,149 - resetting layer weights
2023-12-09 16:56:32,149 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:56:32.149591', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:56:32,150 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:56:32.150001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:33,163 - EPOCH 0 - PROGRESS: at 42.50% examples, 336524 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:34,179 - EPOCH 0 - PROGRESS: at 90.00% examples, 355272 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:34,391 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357427 effective words/s
2023-12-09 16:56:34,391 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356909 effective words/s', 'datetime': '2023-12-09T16:56:34.391538', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:34,391 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:56:34.391713', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:56:45,635 - Processed run 1 for mu=1.0 on cuda:1. Elapsed time: 15.99 seconds
2023-12-09 16:56:46,856 - collecting all words and their counts
2023-12-09 16:56:46,856 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:56:46,922 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:56:46,923 - Creating a fresh vocabulary
2023-12-09 16:56:46,925 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:56:46.925071', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:46,925 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:56:46.925148', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:46,927 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:56:46,927 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:56:46,928 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:56:46.928014', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:46,932 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:56:46,932 - resetting layer weights
2023-12-09 16:56:46,933 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:56:46.933149', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:56:46,933 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:56:46.933559', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:47,937 - EPOCH 0 - PROGRESS: at 53.75% examples, 429577 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:48,569 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 490046 effective words/s
2023-12-09 16:56:48,569 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 489035 effective words/s', 'datetime': '2023-12-09T16:56:48.569507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:48,569 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:56:48.569686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:56:52,601 - Processed run 2 for mu=0.0 on cuda:1. Elapsed time: 6.96 seconds
2023-12-09 16:56:53,523 - collecting all words and their counts
2023-12-09 16:56:53,523 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:56:53,583 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:56:53,583 - Creating a fresh vocabulary
2023-12-09 16:56:53,585 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:56:53.585881', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:53,585 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:56:53.585951', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:53,588 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:56:53,588 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:56:53,588 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:56:53.588822', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:56:53,593 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:56:53,593 - resetting layer weights
2023-12-09 16:56:53,593 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:56:53.593851', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:56:53,594 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:56:53.594308', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:54,598 - EPOCH 0 - PROGRESS: at 42.50% examples, 339607 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:55,676 - EPOCH 0 - PROGRESS: at 91.25% examples, 351222 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:56:55,803 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 362727 effective words/s
2023-12-09 16:56:55,803 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 362159 effective words/s', 'datetime': '2023-12-09T16:56:55.803358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:56:55,803 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:56:55.803531', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:00,220 - Processed run 2 for mu=0.05 on cuda:2. Elapsed time: 7.62 seconds
2023-12-09 16:57:01,070 - collecting all words and their counts
2023-12-09 16:57:01,070 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:01,128 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:01,129 - Creating a fresh vocabulary
2023-12-09 16:57:01,130 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:01.130930', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:01,131 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:01.130996', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:01,133 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:01,133 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:01,134 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:01.134019', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:01,138 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:01,138 - resetting layer weights
2023-12-09 16:57:01,139 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:01.139146', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:01,139 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:01.139594', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:02,185 - EPOCH 0 - PROGRESS: at 46.25% examples, 354916 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:57:03,210 - EPOCH 0 - PROGRESS: at 96.25% examples, 372482 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:57:03,226 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383839 effective words/s
2023-12-09 16:57:03,227 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383224 effective words/s', 'datetime': '2023-12-09T16:57:03.227221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:03,227 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:03.227392', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:07,849 - Processed run 2 for mu=0.1 on cuda:3. Elapsed time: 7.63 seconds
2023-12-09 16:57:08,754 - collecting all words and their counts
2023-12-09 16:57:08,755 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:08,814 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:08,814 - Creating a fresh vocabulary
2023-12-09 16:57:08,816 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:08.816810', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:08,816 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:08.816876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:08,821 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:08,821 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:08,821 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:08.821949', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:08,838 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:08,838 - resetting layer weights
2023-12-09 16:57:08,839 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:08.839584', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:08,839 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:08.839747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:09,887 - EPOCH 0 - PROGRESS: at 46.25% examples, 354140 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:10,917 - EPOCH 0 - PROGRESS: at 96.25% examples, 371226 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:57:10,933 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382677 effective words/s
2023-12-09 16:57:10,933 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382032 effective words/s', 'datetime': '2023-12-09T16:57:10.933915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:10,934 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:10.934085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:15,542 - Processed run 2 for mu=0.15 on cuda:4. Elapsed time: 7.69 seconds
2023-12-09 16:57:16,472 - collecting all words and their counts
2023-12-09 16:57:16,472 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:16,532 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:16,532 - Creating a fresh vocabulary
2023-12-09 16:57:16,534 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:16.534900', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:16,534 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:16.534979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:16,537 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:16,537 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:16,538 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:16.538037', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:16,542 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:16,542 - resetting layer weights
2023-12-09 16:57:16,543 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:16.543230', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:16,543 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:16.543688', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:17,565 - EPOCH 0 - PROGRESS: at 41.25% examples, 323830 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:18,566 - EPOCH 0 - PROGRESS: at 87.50% examples, 346621 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:18,799 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355215 effective words/s
2023-12-09 16:57:18,799 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354694 effective words/s', 'datetime': '2023-12-09T16:57:18.799214', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:18,799 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:18.799296', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:24,287 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 8.74 seconds
2023-12-09 16:57:25,193 - collecting all words and their counts
2023-12-09 16:57:25,193 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:25,252 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:25,253 - Creating a fresh vocabulary
2023-12-09 16:57:25,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:25.255013', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:25,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:25.255097', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:25,257 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:25,257 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:25,258 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:25.258023', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:25,262 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:25,262 - resetting layer weights
2023-12-09 16:57:25,263 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:25.263191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:25,263 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:25.263645', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:26,271 - EPOCH 0 - PROGRESS: at 41.25% examples, 328594 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:27,292 - EPOCH 0 - PROGRESS: at 88.75% examples, 350501 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:27,511 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356351 effective words/s
2023-12-09 16:57:27,512 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355817 effective words/s', 'datetime': '2023-12-09T16:57:27.512066', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:27,512 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:27.512245', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:32,927 - Processed run 2 for mu=0.25 on cuda:2. Elapsed time: 8.64 seconds
2023-12-09 16:57:33,794 - collecting all words and their counts
2023-12-09 16:57:33,794 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:33,855 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:33,855 - Creating a fresh vocabulary
2023-12-09 16:57:33,857 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:33.857345', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:33,857 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:33.857427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:33,860 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:33,860 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:33,860 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:33.860351', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:33,865 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:33,865 - resetting layer weights
2023-12-09 16:57:33,865 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:33.865413', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:33,865 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:33.865897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:34,880 - EPOCH 0 - PROGRESS: at 41.25% examples, 326220 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:35,978 - EPOCH 0 - PROGRESS: at 91.25% examples, 346037 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:36,099 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358602 effective words/s
2023-12-09 16:57:36,100 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358070 effective words/s', 'datetime': '2023-12-09T16:57:36.100171', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:36,100 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:36.100346', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:41,478 - Processed run 2 for mu=0.3 on cuda:3. Elapsed time: 8.55 seconds
2023-12-09 16:57:42,482 - collecting all words and their counts
2023-12-09 16:57:42,482 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:42,543 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:42,543 - Creating a fresh vocabulary
2023-12-09 16:57:42,545 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:42.545263', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:42,545 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:42.545341', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:42,548 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:42,548 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:42,548 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:42.548257', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:42,553 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:42,553 - resetting layer weights
2023-12-09 16:57:42,553 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:42.553546', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:42,554 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:42.554083', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:43,565 - EPOCH 0 - PROGRESS: at 41.25% examples, 327220 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:44,574 - EPOCH 0 - PROGRESS: at 87.50% examples, 347106 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:44,806 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355701 effective words/s
2023-12-09 16:57:44,806 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355158 effective words/s', 'datetime': '2023-12-09T16:57:44.806680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:44,806 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:44.806857', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:57:52,894 - Processed run 2 for mu=0.35 on cuda:4. Elapsed time: 11.42 seconds
2023-12-09 16:57:53,973 - collecting all words and their counts
2023-12-09 16:57:53,973 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:57:54,032 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:57:54,032 - Creating a fresh vocabulary
2023-12-09 16:57:54,034 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:57:54.034398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:54,034 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:57:54.034463', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:54,037 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:57:54,037 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:57:54,037 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:57:54.037347', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:57:54,042 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:57:54,042 - resetting layer weights
2023-12-09 16:57:54,042 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:57:54.042484', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:57:54,042 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:57:54.042919', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:55,074 - EPOCH 0 - PROGRESS: at 46.25% examples, 359875 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:57:56,074 - EPOCH 0 - PROGRESS: at 98.75% examples, 389417 words/s, in_qsize 1, out_qsize 1
2023-12-09 16:57:56,084 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392401 effective words/s
2023-12-09 16:57:56,085 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 391735 effective words/s', 'datetime': '2023-12-09T16:57:56.085191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:57:56,085 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:57:56.085373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:02,832 - Processed run 2 for mu=0.4 on cuda:1. Elapsed time: 9.94 seconds
2023-12-09 16:58:03,907 - collecting all words and their counts
2023-12-09 16:58:03,907 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:03,968 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:03,968 - Creating a fresh vocabulary
2023-12-09 16:58:03,970 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:03.970780', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:03,970 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:03.970847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:03,973 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:03,973 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:03,973 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:03.973741', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:03,978 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:03,978 - resetting layer weights
2023-12-09 16:58:03,978 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:03.978812', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:03,979 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:03.979315', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:04,999 - EPOCH 0 - PROGRESS: at 46.25% examples, 363739 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:06,002 - EPOCH 0 - PROGRESS: at 97.50% examples, 386086 words/s, in_qsize 2, out_qsize 1
2023-12-09 16:58:06,041 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 388532 effective words/s
2023-12-09 16:58:06,041 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 387894 effective words/s', 'datetime': '2023-12-09T16:58:06.041807', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:06,042 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:58:06.041982', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:12,038 - Processed run 2 for mu=0.45 on cuda:2. Elapsed time: 9.20 seconds
2023-12-09 16:58:13,212 - collecting all words and their counts
2023-12-09 16:58:13,213 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:13,274 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:13,274 - Creating a fresh vocabulary
2023-12-09 16:58:13,276 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:13.276254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:13,276 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:13.276338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:13,279 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:13,279 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:13,279 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:13.279217', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:13,283 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:13,283 - resetting layer weights
2023-12-09 16:58:13,284 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:13.284276', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:13,284 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:13.284785', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:14,318 - EPOCH 0 - PROGRESS: at 46.25% examples, 358926 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:15,319 - EPOCH 0 - PROGRESS: at 96.25% examples, 378977 words/s, in_qsize 3, out_qsize 1
2023-12-09 16:58:15,334 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 390833 effective words/s
2023-12-09 16:58:15,335 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 390196 effective words/s', 'datetime': '2023-12-09T16:58:15.335112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:15,335 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:58:15.335284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:22,398 - Processed run 2 for mu=0.5 on cuda:3. Elapsed time: 10.36 seconds
2023-12-09 16:58:23,663 - collecting all words and their counts
2023-12-09 16:58:23,663 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:23,722 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:23,722 - Creating a fresh vocabulary
2023-12-09 16:58:23,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:23.724755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:23,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:23.724833', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:23,727 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:23,727 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:23,727 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:23.727678', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:23,732 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:23,732 - resetting layer weights
2023-12-09 16:58:23,732 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:23.732734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:23,733 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:23.733166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:24,758 - EPOCH 0 - PROGRESS: at 41.25% examples, 322964 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:25,769 - EPOCH 0 - PROGRESS: at 86.25% examples, 339432 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:26,023 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349780 effective words/s
2023-12-09 16:58:26,023 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349270 effective words/s', 'datetime': '2023-12-09T16:58:26.023733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:26,023 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:58:26.023912', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:32,945 - Processed run 2 for mu=0.55 on cuda:4. Elapsed time: 10.55 seconds
2023-12-09 16:58:34,386 - collecting all words and their counts
2023-12-09 16:58:34,386 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:34,463 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:34,463 - Creating a fresh vocabulary
2023-12-09 16:58:34,465 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:34.465491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:34,465 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:34.465569', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:34,468 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:34,468 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:34,468 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:34.468518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:34,473 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:34,473 - resetting layer weights
2023-12-09 16:58:34,473 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:34.473665', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:34,474 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:34.474058', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:35,489 - EPOCH 0 - PROGRESS: at 41.25% examples, 326120 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:36,503 - EPOCH 0 - PROGRESS: at 88.75% examples, 350460 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:36,736 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354045 effective words/s
2023-12-09 16:58:36,737 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353524 effective words/s', 'datetime': '2023-12-09T16:58:36.737059', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:36,737 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:58:36.737240', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:44,226 - Processed run 2 for mu=0.6 on cuda:1. Elapsed time: 11.28 seconds
2023-12-09 16:58:45,677 - collecting all words and their counts
2023-12-09 16:58:45,677 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:45,739 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:45,739 - Creating a fresh vocabulary
2023-12-09 16:58:45,741 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:45.741058', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:45,741 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:45.741129', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:45,743 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:45,744 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:45,744 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:45.744062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:45,748 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:45,748 - resetting layer weights
2023-12-09 16:58:45,749 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:45.749090', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:45,749 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:45.749488', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:46,765 - EPOCH 0 - PROGRESS: at 41.25% examples, 325887 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:58:47,782 - EPOCH 0 - PROGRESS: at 88.75% examples, 349851 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:58:48,004 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355311 effective words/s
2023-12-09 16:58:48,004 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354773 effective words/s', 'datetime': '2023-12-09T16:58:48.004526', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:48,004 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:58:48.004723', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:58:56,594 - Processed run 2 for mu=0.65 on cuda:2. Elapsed time: 12.37 seconds
2023-12-09 16:58:58,142 - collecting all words and their counts
2023-12-09 16:58:58,142 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:58:58,202 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:58:58,202 - Creating a fresh vocabulary
2023-12-09 16:58:58,204 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:58:58.204182', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:58,204 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:58:58.204261', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:58,207 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:58:58,207 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:58:58,207 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:58:58.207216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:58:58,212 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:58:58,212 - resetting layer weights
2023-12-09 16:58:58,212 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:58:58.212366', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:58:58,212 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:58:58.212866', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:58:59,232 - EPOCH 0 - PROGRESS: at 41.25% examples, 324763 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:00,238 - EPOCH 0 - PROGRESS: at 87.50% examples, 346169 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:00,469 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355037 effective words/s
2023-12-09 16:59:00,469 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354501 effective words/s', 'datetime': '2023-12-09T16:59:00.469621', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:00,469 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:59:00.469703', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:59:09,833 - Processed run 2 for mu=0.7 on cuda:3. Elapsed time: 13.24 seconds
2023-12-09 16:59:11,622 - collecting all words and their counts
2023-12-09 16:59:11,623 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:59:11,687 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:59:11,687 - Creating a fresh vocabulary
2023-12-09 16:59:11,689 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:59:11.689253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:11,689 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:59:11.689323', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:11,692 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:59:11,692 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:59:11,692 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:59:11.692211', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:11,697 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:59:11,697 - resetting layer weights
2023-12-09 16:59:11,697 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:59:11.697390', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:59:11,697 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:59:11.697789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:12,714 - EPOCH 0 - PROGRESS: at 42.50% examples, 335515 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:13,723 - EPOCH 0 - PROGRESS: at 87.50% examples, 346117 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:13,953 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355100 effective words/s
2023-12-09 16:59:13,954 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354562 effective words/s', 'datetime': '2023-12-09T16:59:13.954165', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:13,954 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:59:13.954351', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:59:23,546 - Processed run 2 for mu=0.75 on cuda:4. Elapsed time: 13.71 seconds
2023-12-09 16:59:25,337 - collecting all words and their counts
2023-12-09 16:59:25,337 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:59:25,395 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:59:25,395 - Creating a fresh vocabulary
2023-12-09 16:59:25,397 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:59:25.397871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:25,397 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:59:25.397943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:25,400 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:59:25,400 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:59:25,400 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:59:25.400809', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:25,405 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:59:25,405 - resetting layer weights
2023-12-09 16:59:25,405 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:59:25.405898', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:59:25,406 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:59:25.406374', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:26,415 - EPOCH 0 - PROGRESS: at 41.25% examples, 328235 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:27,416 - EPOCH 0 - PROGRESS: at 86.25% examples, 343876 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:27,667 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354384 effective words/s
2023-12-09 16:59:27,667 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353847 effective words/s', 'datetime': '2023-12-09T16:59:27.667312', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:27,667 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:59:27.667490', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:59:39,396 - Processed run 2 for mu=0.8 on cuda:1. Elapsed time: 15.85 seconds
2023-12-09 16:59:41,323 - collecting all words and their counts
2023-12-09 16:59:41,323 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:59:41,385 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:59:41,385 - Creating a fresh vocabulary
2023-12-09 16:59:41,387 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:59:41.387431', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:41,387 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:59:41.387509', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:41,390 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:59:41,390 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:59:41,390 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:59:41.390444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:41,395 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:59:41,395 - resetting layer weights
2023-12-09 16:59:41,395 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:59:41.395597', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:59:41,396 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:59:41.396021', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:42,422 - EPOCH 0 - PROGRESS: at 41.25% examples, 322366 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:43,425 - EPOCH 0 - PROGRESS: at 86.25% examples, 340481 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:43,688 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349466 effective words/s
2023-12-09 16:59:43,688 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348949 effective words/s', 'datetime': '2023-12-09T16:59:43.688696', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:43,688 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:59:43.688880', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 16:59:55,215 - Processed run 2 for mu=0.85 on cuda:2. Elapsed time: 15.82 seconds
2023-12-09 16:59:57,336 - collecting all words and their counts
2023-12-09 16:59:57,336 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 16:59:57,395 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 16:59:57,395 - Creating a fresh vocabulary
2023-12-09 16:59:57,397 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T16:59:57.397965', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:57,398 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T16:59:57.398068', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:57,400 - deleting the raw counts dictionary of 1000 items
2023-12-09 16:59:57,400 - sample=0.001 downsamples 0 most-common words
2023-12-09 16:59:57,400 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T16:59:57.400984', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 16:59:57,405 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 16:59:57,405 - resetting layer weights
2023-12-09 16:59:57,406 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T16:59:57.406139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 16:59:57,406 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T16:59:57.406397', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:58,428 - EPOCH 0 - PROGRESS: at 41.25% examples, 324078 words/s, in_qsize 7, out_qsize 0
2023-12-09 16:59:59,438 - EPOCH 0 - PROGRESS: at 86.25% examples, 340119 words/s, in_qsize 8, out_qsize 0
2023-12-09 16:59:59,680 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352233 effective words/s
2023-12-09 16:59:59,681 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351691 effective words/s', 'datetime': '2023-12-09T16:59:59.681196', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 16:59:59,681 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T16:59:59.681707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:00:12,209 - Processed run 2 for mu=0.9 on cuda:3. Elapsed time: 16.99 seconds
2023-12-09 17:00:14,490 - collecting all words and their counts
2023-12-09 17:00:14,490 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:00:14,551 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:00:14,551 - Creating a fresh vocabulary
2023-12-09 17:00:14,553 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:00:14.553336', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:14,553 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:00:14.553432', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:14,556 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:00:14,556 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:00:14,556 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:00:14.556499', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:14,561 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:00:14,561 - resetting layer weights
2023-12-09 17:00:14,561 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:00:14.561717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:00:14,562 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:00:14.562075', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:15,585 - EPOCH 0 - PROGRESS: at 46.25% examples, 362573 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:00:16,587 - EPOCH 0 - PROGRESS: at 97.50% examples, 385676 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:00:16,615 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 390179 effective words/s
2023-12-09 17:00:16,615 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 389539 effective words/s', 'datetime': '2023-12-09T17:00:16.615856', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:16,616 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:00:16.616030', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:00:27,283 - Processed run 2 for mu=0.95 on cuda:4. Elapsed time: 15.07 seconds
2023-12-09 17:00:29,583 - collecting all words and their counts
2023-12-09 17:00:29,583 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:00:29,642 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:00:29,642 - Creating a fresh vocabulary
2023-12-09 17:00:29,644 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:00:29.644693', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:29,644 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:00:29.644768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:29,647 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:00:29,647 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:00:29,647 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:00:29.647658', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:29,652 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:00:29,652 - resetting layer weights
2023-12-09 17:00:29,652 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:00:29.652907', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:00:29,653 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:00:29.653318', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:30,671 - EPOCH 0 - PROGRESS: at 46.25% examples, 364601 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:00:31,675 - EPOCH 0 - PROGRESS: at 97.50% examples, 386403 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:00:31,695 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392375 effective words/s
2023-12-09 17:00:31,695 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 391735 effective words/s', 'datetime': '2023-12-09T17:00:31.695594', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:31,695 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:00:31.695766', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:00:42,747 - Processed run 2 for mu=1.0 on cuda:1. Elapsed time: 15.46 seconds
2023-12-09 17:00:43,725 - collecting all words and their counts
2023-12-09 17:00:43,725 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:00:43,782 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:00:43,782 - Creating a fresh vocabulary
2023-12-09 17:00:43,784 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:00:43.784651', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:43,784 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:00:43.784721', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:43,787 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:00:43,787 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:00:43,787 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:00:43.787647', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:43,792 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:00:43,792 - resetting layer weights
2023-12-09 17:00:43,792 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:00:43.792768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:00:43,793 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:00:43.793195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:44,801 - EPOCH 0 - PROGRESS: at 60.00% examples, 477682 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:00:45,326 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 522833 effective words/s
2023-12-09 17:00:45,326 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 521669 effective words/s', 'datetime': '2023-12-09T17:00:45.326806', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:45,327 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:00:45.326989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:00:49,370 - Processed run 3 for mu=0.0 on cuda:1. Elapsed time: 6.62 seconds
2023-12-09 17:00:50,301 - collecting all words and their counts
2023-12-09 17:00:50,301 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:00:50,359 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:00:50,359 - Creating a fresh vocabulary
2023-12-09 17:00:50,361 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:00:50.361868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:50,361 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:00:50.361936', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:50,364 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:00:50,364 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:00:50,364 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:00:50.364842', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:50,369 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:00:50,369 - resetting layer weights
2023-12-09 17:00:50,369 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:00:50.369931', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:00:50,370 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:00:50.370365', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:51,376 - EPOCH 0 - PROGRESS: at 41.25% examples, 329056 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:00:52,378 - EPOCH 0 - PROGRESS: at 86.25% examples, 344097 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:00:52,627 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354859 effective words/s
2023-12-09 17:00:52,628 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354340 effective words/s', 'datetime': '2023-12-09T17:00:52.628147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:52,628 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:00:52.628252', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:00:57,170 - Processed run 3 for mu=0.05 on cuda:2. Elapsed time: 7.80 seconds
2023-12-09 17:00:58,131 - collecting all words and their counts
2023-12-09 17:00:58,132 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:00:58,191 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:00:58,191 - Creating a fresh vocabulary
2023-12-09 17:00:58,193 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:00:58.193533', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:58,193 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:00:58.193602', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:58,196 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:00:58,196 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:00:58,196 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:00:58.196456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:00:58,201 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:00:58,201 - resetting layer weights
2023-12-09 17:00:58,201 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:00:58.201511', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:00:58,201 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:00:58.201967', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:00:59,224 - EPOCH 0 - PROGRESS: at 41.25% examples, 323662 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:00,232 - EPOCH 0 - PROGRESS: at 86.25% examples, 340297 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:00,463 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354222 effective words/s
2023-12-09 17:01:00,463 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353706 effective words/s', 'datetime': '2023-12-09T17:01:00.463804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:00,464 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:00.463985', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:05,495 - Processed run 3 for mu=0.1 on cuda:3. Elapsed time: 8.32 seconds
2023-12-09 17:01:06,395 - collecting all words and their counts
2023-12-09 17:01:06,396 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:06,455 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:06,455 - Creating a fresh vocabulary
2023-12-09 17:01:06,457 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:06.457311', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:06,457 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:06.457380', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:06,460 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:06,460 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:06,460 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:06.460280', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:06,465 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:06,465 - resetting layer weights
2023-12-09 17:01:06,465 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:06.465400', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:06,465 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:06.465823', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:07,495 - EPOCH 0 - PROGRESS: at 41.25% examples, 321592 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:08,503 - EPOCH 0 - PROGRESS: at 86.25% examples, 339224 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:08,770 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 347648 effective words/s
2023-12-09 17:01:08,770 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347145 effective words/s', 'datetime': '2023-12-09T17:01:08.770409', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:08,770 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:08.770590', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:13,465 - Processed run 3 for mu=0.15 on cuda:4. Elapsed time: 7.97 seconds
2023-12-09 17:01:14,411 - collecting all words and their counts
2023-12-09 17:01:14,411 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:14,471 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:14,471 - Creating a fresh vocabulary
2023-12-09 17:01:14,473 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:14.473540', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:14,473 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:14.473611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:14,476 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:14,476 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:14,476 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:14.476498', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:14,481 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:14,481 - resetting layer weights
2023-12-09 17:01:14,481 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:14.481705', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:14,482 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:14.482149', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:15,509 - EPOCH 0 - PROGRESS: at 41.25% examples, 322323 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:16,514 - EPOCH 0 - PROGRESS: at 86.25% examples, 340078 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:16,768 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350371 effective words/s
2023-12-09 17:01:16,768 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349867 effective words/s', 'datetime': '2023-12-09T17:01:16.768805', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:16,769 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:16.768978', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:22,929 - Processed run 3 for mu=0.2 on cuda:1. Elapsed time: 9.46 seconds
2023-12-09 17:01:23,751 - collecting all words and their counts
2023-12-09 17:01:23,751 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:23,810 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:23,810 - Creating a fresh vocabulary
2023-12-09 17:01:23,812 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:23.812409', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:23,812 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:23.812494', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:23,815 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:23,815 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:23,815 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:23.815414', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:23,820 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:23,820 - resetting layer weights
2023-12-09 17:01:23,820 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:23.820455', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:23,820 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:23.820901', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:24,851 - EPOCH 0 - PROGRESS: at 41.25% examples, 321194 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:25,857 - EPOCH 0 - PROGRESS: at 86.25% examples, 339355 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:26,093 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352597 effective words/s
2023-12-09 17:01:26,093 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352068 effective words/s', 'datetime': '2023-12-09T17:01:26.093279', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:26,093 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:26.093517', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:31,468 - Processed run 3 for mu=0.25 on cuda:2. Elapsed time: 8.54 seconds
2023-12-09 17:01:32,520 - collecting all words and their counts
2023-12-09 17:01:32,520 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:32,580 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:32,580 - Creating a fresh vocabulary
2023-12-09 17:01:32,582 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:32.582012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:32,582 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:32.582086', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:32,584 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:32,584 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:32,585 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:32.585007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:32,589 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:32,589 - resetting layer weights
2023-12-09 17:01:32,590 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:32.590225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:32,590 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:32.590754', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:33,617 - EPOCH 0 - PROGRESS: at 41.25% examples, 322381 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:34,629 - EPOCH 0 - PROGRESS: at 86.25% examples, 339024 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:34,889 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348560 effective words/s
2023-12-09 17:01:34,889 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348044 effective words/s', 'datetime': '2023-12-09T17:01:34.889386', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:34,889 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:34.889574', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:41,387 - Processed run 3 for mu=0.3 on cuda:3. Elapsed time: 9.92 seconds
2023-12-09 17:01:42,362 - collecting all words and their counts
2023-12-09 17:01:42,362 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:42,422 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:42,422 - Creating a fresh vocabulary
2023-12-09 17:01:42,424 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:42.424514', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:42,424 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:42.424603', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:42,427 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:42,427 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:42,427 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:42.427548', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:42,432 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:42,432 - resetting layer weights
2023-12-09 17:01:42,432 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:42.432869', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:42,433 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:42.433304', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:43,474 - EPOCH 0 - PROGRESS: at 46.25% examples, 356518 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:44,495 - EPOCH 0 - PROGRESS: at 96.25% examples, 373949 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:01:44,541 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 379970 effective words/s
2023-12-09 17:01:44,542 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379360 effective words/s', 'datetime': '2023-12-09T17:01:44.542200', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:44,542 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:44.542373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:49,885 - Processed run 3 for mu=0.35 on cuda:4. Elapsed time: 8.50 seconds
2023-12-09 17:01:50,990 - collecting all words and their counts
2023-12-09 17:01:50,990 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:01:51,051 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:01:51,051 - Creating a fresh vocabulary
2023-12-09 17:01:51,053 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:01:51.053148', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:51,053 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:01:51.053228', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:51,056 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:01:51,056 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:01:51,056 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:01:51.056118', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:01:51,060 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:01:51,060 - resetting layer weights
2023-12-09 17:01:51,061 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:01:51.061328', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:01:51,061 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:01:51.061698', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:52,101 - EPOCH 0 - PROGRESS: at 46.25% examples, 356984 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:01:53,126 - EPOCH 0 - PROGRESS: at 96.25% examples, 373524 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:01:53,150 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383574 effective words/s
2023-12-09 17:01:53,150 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382964 effective words/s', 'datetime': '2023-12-09T17:01:53.150739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:01:53,150 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:01:53.150913', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:01:59,003 - Processed run 3 for mu=0.4 on cuda:1. Elapsed time: 9.12 seconds
2023-12-09 17:02:00,081 - collecting all words and their counts
2023-12-09 17:02:00,081 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:00,140 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:00,140 - Creating a fresh vocabulary
2023-12-09 17:02:00,142 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:00.142064', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:00,142 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:00.142136', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:00,144 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:00,144 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:00,145 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:00.145018', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:00,149 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:00,149 - resetting layer weights
2023-12-09 17:02:00,150 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:00.150181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:00,150 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:00.150422', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:01,198 - EPOCH 0 - PROGRESS: at 46.25% examples, 354134 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:02,232 - EPOCH 0 - PROGRESS: at 96.25% examples, 370401 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:02,237 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383893 effective words/s
2023-12-09 17:02:02,237 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383276 effective words/s', 'datetime': '2023-12-09T17:02:02.237764', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:02,238 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:02.238340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:02:08,335 - Processed run 3 for mu=0.45 on cuda:2. Elapsed time: 9.33 seconds
2023-12-09 17:02:09,490 - collecting all words and their counts
2023-12-09 17:02:09,490 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:09,549 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:09,549 - Creating a fresh vocabulary
2023-12-09 17:02:09,551 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:09.551755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:09,551 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:09.551831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:09,554 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:09,554 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:09,554 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:09.554769', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:09,559 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:09,559 - resetting layer weights
2023-12-09 17:02:09,559 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:09.559844', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:09,560 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:09.560327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:10,607 - EPOCH 0 - PROGRESS: at 46.25% examples, 354468 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:11,630 - EPOCH 0 - PROGRESS: at 96.25% examples, 372472 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:11,652 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382976 effective words/s
2023-12-09 17:02:11,652 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382349 effective words/s', 'datetime': '2023-12-09T17:02:11.652732', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:11,652 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:11.652903', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:02:18,024 - Processed run 3 for mu=0.5 on cuda:3. Elapsed time: 9.69 seconds
2023-12-09 17:02:19,242 - collecting all words and their counts
2023-12-09 17:02:19,242 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:19,303 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:19,303 - Creating a fresh vocabulary
2023-12-09 17:02:19,305 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:19.305461', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:19,305 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:19.305532', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:19,308 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:19,308 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:19,308 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:19.308409', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:19,313 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:19,313 - resetting layer weights
2023-12-09 17:02:19,313 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:19.313482', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:19,313 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:19.313860', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:20,359 - EPOCH 0 - PROGRESS: at 46.25% examples, 354765 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:21,382 - EPOCH 0 - PROGRESS: at 96.25% examples, 372850 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:21,391 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385705 effective words/s
2023-12-09 17:02:21,391 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385099 effective words/s', 'datetime': '2023-12-09T17:02:21.391310', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:21,391 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:21.391425', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:02:27,918 - Processed run 3 for mu=0.55 on cuda:4. Elapsed time: 9.89 seconds
2023-12-09 17:02:29,302 - collecting all words and their counts
2023-12-09 17:02:29,302 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:29,363 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:29,363 - Creating a fresh vocabulary
2023-12-09 17:02:29,365 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:29.365215', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:29,365 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:29.365293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:29,368 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:29,368 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:29,368 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:29.368109', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:29,372 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:29,372 - resetting layer weights
2023-12-09 17:02:29,373 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:29.373308', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:29,373 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:29.373575', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:30,419 - EPOCH 0 - PROGRESS: at 46.25% examples, 354764 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:31,447 - EPOCH 0 - PROGRESS: at 96.25% examples, 371779 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:31,474 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381337 effective words/s
2023-12-09 17:02:31,474 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380718 effective words/s', 'datetime': '2023-12-09T17:02:31.474939', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:31,475 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:31.475438', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:02:38,639 - Processed run 3 for mu=0.6 on cuda:1. Elapsed time: 10.72 seconds
2023-12-09 17:02:40,165 - collecting all words and their counts
2023-12-09 17:02:40,165 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:40,225 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:40,226 - Creating a fresh vocabulary
2023-12-09 17:02:40,227 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:40.227948', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:40,228 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:40.228029', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:40,230 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:40,230 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:40,230 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:40.230920', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:40,235 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:40,235 - resetting layer weights
2023-12-09 17:02:40,236 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:40.236210', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:40,236 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:40.236531', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:41,289 - EPOCH 0 - PROGRESS: at 46.25% examples, 352527 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:42,316 - EPOCH 0 - PROGRESS: at 96.25% examples, 370831 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:42,335 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381635 effective words/s
2023-12-09 17:02:42,336 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381040 effective words/s', 'datetime': '2023-12-09T17:02:42.336117', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:42,336 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:42.336181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:02:50,873 - Processed run 3 for mu=0.65 on cuda:2. Elapsed time: 12.23 seconds
2023-12-09 17:02:52,486 - collecting all words and their counts
2023-12-09 17:02:52,486 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:02:52,546 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:02:52,546 - Creating a fresh vocabulary
2023-12-09 17:02:52,548 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:02:52.548754', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:52,548 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:02:52.548821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:52,551 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:02:52,551 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:02:52,551 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:02:52.551687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:02:52,556 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:02:52,556 - resetting layer weights
2023-12-09 17:02:52,556 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:02:52.556738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:02:52,556 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:02:52.556955', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:53,604 - EPOCH 0 - PROGRESS: at 46.25% examples, 354383 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:02:54,627 - EPOCH 0 - PROGRESS: at 96.25% examples, 372498 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:02:54,648 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383160 effective words/s
2023-12-09 17:02:54,648 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382545 effective words/s', 'datetime': '2023-12-09T17:02:54.648287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:02:54,648 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:02:54.648841', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:03:02,962 - Processed run 3 for mu=0.7 on cuda:3. Elapsed time: 12.09 seconds
2023-12-09 17:03:04,583 - collecting all words and their counts
2023-12-09 17:03:04,583 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:03:04,642 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:03:04,642 - Creating a fresh vocabulary
2023-12-09 17:03:04,644 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:03:04.644537', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:04,644 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:03:04.644628', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:04,647 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:03:04,647 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:03:04,647 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:03:04.647550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:04,652 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:03:04,652 - resetting layer weights
2023-12-09 17:03:04,652 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:03:04.652679', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:03:04,652 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:03:04.652891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:05,676 - EPOCH 0 - PROGRESS: at 41.25% examples, 323376 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:03:06,678 - EPOCH 0 - PROGRESS: at 86.25% examples, 341157 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:03:06,908 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355148 effective words/s
2023-12-09 17:03:06,908 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354614 effective words/s', 'datetime': '2023-12-09T17:03:06.908943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:06,909 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:03:06.909582', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:03:24,810 - Processed run 3 for mu=0.75 on cuda:4. Elapsed time: 21.85 seconds
2023-12-09 17:03:26,712 - collecting all words and their counts
2023-12-09 17:03:26,712 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:03:26,777 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:03:26,777 - Creating a fresh vocabulary
2023-12-09 17:03:26,779 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:03:26.779664', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:26,779 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:03:26.779731', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:26,782 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:03:26,782 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:03:26,782 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:03:26.782704', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:26,787 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:03:26,787 - resetting layer weights
2023-12-09 17:03:26,787 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:03:26.787848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:03:26,788 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:03:26.788133', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:27,807 - EPOCH 0 - PROGRESS: at 46.25% examples, 363953 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:03:28,809 - EPOCH 0 - PROGRESS: at 96.25% examples, 381523 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:03:28,825 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393188 effective words/s
2023-12-09 17:03:28,826 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392547 effective words/s', 'datetime': '2023-12-09T17:03:28.826186', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:28,826 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:03:28.826417', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:03:39,273 - Processed run 3 for mu=0.8 on cuda:1. Elapsed time: 14.46 seconds
2023-12-09 17:03:41,226 - collecting all words and their counts
2023-12-09 17:03:41,226 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:03:41,287 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:03:41,287 - Creating a fresh vocabulary
2023-12-09 17:03:41,289 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:03:41.289258', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:41,289 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:03:41.289338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:41,292 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:03:41,292 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:03:41,292 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:03:41.292219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:41,296 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:03:41,297 - resetting layer weights
2023-12-09 17:03:41,297 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:03:41.297348', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:03:41,297 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:03:41.297768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:42,322 - EPOCH 0 - PROGRESS: at 46.25% examples, 362093 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:03:43,324 - EPOCH 0 - PROGRESS: at 97.50% examples, 385547 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:03:43,327 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 394811 effective words/s
2023-12-09 17:03:43,327 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 394160 effective words/s', 'datetime': '2023-12-09T17:03:43.327474', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:43,327 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:03:43.327648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:03:54,849 - Processed run 3 for mu=0.85 on cuda:2. Elapsed time: 15.57 seconds
2023-12-09 17:03:56,913 - collecting all words and their counts
2023-12-09 17:03:56,913 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:03:56,974 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:03:56,974 - Creating a fresh vocabulary
2023-12-09 17:03:56,976 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:03:56.976421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:56,976 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:03:56.976489', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:56,979 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:03:56,979 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:03:56,979 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:03:56.979375', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:03:56,984 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:03:56,984 - resetting layer weights
2023-12-09 17:03:56,984 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:03:56.984475', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:03:56,984 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:03:56.984900', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:58,004 - EPOCH 0 - PROGRESS: at 46.25% examples, 364203 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:03:59,008 - EPOCH 0 - PROGRESS: at 97.50% examples, 386139 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:03:59,024 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392854 effective words/s
2023-12-09 17:03:59,024 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392193 effective words/s', 'datetime': '2023-12-09T17:03:59.024784', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:03:59,024 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:03:59.024955', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:04:11,704 - Processed run 3 for mu=0.9 on cuda:3. Elapsed time: 16.85 seconds
2023-12-09 17:04:13,987 - collecting all words and their counts
2023-12-09 17:04:13,987 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:04:14,048 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:04:14,048 - Creating a fresh vocabulary
2023-12-09 17:04:14,050 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:04:14.050682', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:14,050 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:04:14.050752', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:14,053 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:04:14,053 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:04:14,053 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:04:14.053729', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:14,058 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:04:14,058 - resetting layer weights
2023-12-09 17:04:14,058 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:04:14.058892', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:04:14,059 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:04:14.059548', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:15,089 - EPOCH 0 - PROGRESS: at 41.25% examples, 321538 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:16,096 - EPOCH 0 - PROGRESS: at 87.50% examples, 344132 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:16,333 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352301 effective words/s
2023-12-09 17:04:16,333 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351769 effective words/s', 'datetime': '2023-12-09T17:04:16.333831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:16,334 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:04:16.334022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:04:27,833 - Processed run 3 for mu=0.95 on cuda:4. Elapsed time: 16.13 seconds
2023-12-09 17:04:30,288 - collecting all words and their counts
2023-12-09 17:04:30,288 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:04:30,349 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:04:30,350 - Creating a fresh vocabulary
2023-12-09 17:04:30,352 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:04:30.352005', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:30,352 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:04:30.352078', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:30,354 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:04:30,354 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:04:30,354 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:04:30.354940', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:30,359 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:04:30,359 - resetting layer weights
2023-12-09 17:04:30,360 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:04:30.360019', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:04:30,360 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:04:30.360442', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:31,386 - EPOCH 0 - PROGRESS: at 41.25% examples, 322632 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:32,394 - EPOCH 0 - PROGRESS: at 86.25% examples, 339775 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:32,642 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351071 effective words/s
2023-12-09 17:04:32,642 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350558 effective words/s', 'datetime': '2023-12-09T17:04:32.642611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:32,642 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:04:32.642799', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:04:45,255 - Processed run 3 for mu=1.0 on cuda:1. Elapsed time: 17.42 seconds
2023-12-09 17:04:46,265 - collecting all words and their counts
2023-12-09 17:04:46,265 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:04:46,323 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:04:46,323 - Creating a fresh vocabulary
2023-12-09 17:04:46,325 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:04:46.325829', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:46,325 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:04:46.325906', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:46,328 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:04:46,328 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:04:46,328 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:04:46.328831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:46,333 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:04:46,333 - resetting layer weights
2023-12-09 17:04:46,334 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:04:46.334030', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:04:46,334 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:04:46.334506', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:47,369 - EPOCH 0 - PROGRESS: at 56.25% examples, 436028 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:47,942 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 498552 effective words/s
2023-12-09 17:04:47,942 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 497496 effective words/s', 'datetime': '2023-12-09T17:04:47.942634', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:47,942 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:04:47.942826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:04:51,907 - Processed run 4 for mu=0.0 on cuda:1. Elapsed time: 6.65 seconds
2023-12-09 17:04:52,812 - collecting all words and their counts
2023-12-09 17:04:52,813 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:04:52,871 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:04:52,871 - Creating a fresh vocabulary
2023-12-09 17:04:52,873 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:04:52.873371', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:52,873 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:04:52.873447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:52,876 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:04:52,876 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:04:52,876 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:04:52.876366', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:04:52,881 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:04:52,881 - resetting layer weights
2023-12-09 17:04:52,881 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:04:52.881586', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:04:52,882 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:04:52.882013', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:53,897 - EPOCH 0 - PROGRESS: at 46.25% examples, 365607 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:04:54,908 - EPOCH 0 - PROGRESS: at 100.00% examples, 395319 words/s, in_qsize 0, out_qsize 1
2023-12-09 17:04:54,909 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 395272 effective words/s
2023-12-09 17:04:54,909 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 394630 effective words/s', 'datetime': '2023-12-09T17:04:54.909299', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:04:54,909 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:04:54.909927', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:00,094 - Processed run 4 for mu=0.05 on cuda:2. Elapsed time: 8.19 seconds
2023-12-09 17:05:01,086 - collecting all words and their counts
2023-12-09 17:05:01,086 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:01,151 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:01,151 - Creating a fresh vocabulary
2023-12-09 17:05:01,153 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:01.153132', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:01,153 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:01.153201', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:01,155 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:01,156 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:01,156 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:01.156074', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:01,160 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:01,160 - resetting layer weights
2023-12-09 17:05:01,161 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:01.161209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:01,161 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:01.161598', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:02,175 - EPOCH 0 - PROGRESS: at 46.25% examples, 365997 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:03,183 - EPOCH 0 - PROGRESS: at 98.75% examples, 391323 words/s, in_qsize 1, out_qsize 1
2023-12-09 17:05:03,202 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392683 effective words/s
2023-12-09 17:05:03,202 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392042 effective words/s', 'datetime': '2023-12-09T17:05:03.202270', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:03,202 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:03.202441', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:08,908 - Processed run 4 for mu=0.1 on cuda:3. Elapsed time: 8.81 seconds
2023-12-09 17:05:09,657 - collecting all words and their counts
2023-12-09 17:05:09,657 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:09,715 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:09,716 - Creating a fresh vocabulary
2023-12-09 17:05:09,717 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:09.717960', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:09,718 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:09.718028', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:09,720 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:09,720 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:09,720 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:09.720949', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:09,725 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:09,725 - resetting layer weights
2023-12-09 17:05:09,726 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:09.726035', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:09,726 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:09.726460', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:10,741 - EPOCH 0 - PROGRESS: at 46.25% examples, 365571 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:05:11,753 - EPOCH 0 - PROGRESS: at 97.50% examples, 385364 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:05:11,765 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393052 effective words/s
2023-12-09 17:05:11,765 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392408 effective words/s', 'datetime': '2023-12-09T17:05:11.765227', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:11,765 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:11.765395', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:16,289 - Processed run 4 for mu=0.15 on cuda:4. Elapsed time: 7.38 seconds
2023-12-09 17:05:17,190 - collecting all words and their counts
2023-12-09 17:05:17,190 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:17,249 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:17,249 - Creating a fresh vocabulary
2023-12-09 17:05:17,251 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:17.251694', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:17,251 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:17.251763', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:17,254 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:17,254 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:17,254 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:17.254619', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:17,259 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:17,259 - resetting layer weights
2023-12-09 17:05:17,259 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:17.259648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:17,260 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:17.260129', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:18,283 - EPOCH 0 - PROGRESS: at 46.25% examples, 362819 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:19,285 - EPOCH 0 - PROGRESS: at 96.25% examples, 380857 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:05:19,291 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 394528 effective words/s
2023-12-09 17:05:19,291 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393882 effective words/s', 'datetime': '2023-12-09T17:05:19.291265', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:19,291 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:19.291438', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:25,635 - Processed run 4 for mu=0.2 on cuda:1. Elapsed time: 9.34 seconds
2023-12-09 17:05:26,472 - collecting all words and their counts
2023-12-09 17:05:26,473 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:26,535 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:26,535 - Creating a fresh vocabulary
2023-12-09 17:05:26,537 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:26.537743', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:26,537 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:26.537819', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:26,540 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:26,540 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:26,540 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:26.540789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:26,545 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:26,545 - resetting layer weights
2023-12-09 17:05:26,545 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:26.545947', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:26,546 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:26.546232', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:27,564 - EPOCH 0 - PROGRESS: at 46.25% examples, 364606 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:28,589 - EPOCH 0 - PROGRESS: at 97.50% examples, 382367 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:05:28,593 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 391452 effective words/s
2023-12-09 17:05:28,593 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390826 effective words/s', 'datetime': '2023-12-09T17:05:28.593668', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:28,593 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:28.593843', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:33,593 - Processed run 4 for mu=0.25 on cuda:2. Elapsed time: 7.96 seconds
2023-12-09 17:05:34,613 - collecting all words and their counts
2023-12-09 17:05:34,613 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:34,672 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:34,672 - Creating a fresh vocabulary
2023-12-09 17:05:34,675 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:34.675101', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:34,675 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:34.675190', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:34,678 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:34,678 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:34,678 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:34.678272', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:34,683 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:34,683 - resetting layer weights
2023-12-09 17:05:34,683 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:34.683727', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:34,683 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:34.683918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:35,703 - EPOCH 0 - PROGRESS: at 41.25% examples, 324737 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:36,791 - EPOCH 0 - PROGRESS: at 91.25% examples, 346939 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:36,910 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359778 effective words/s
2023-12-09 17:05:36,911 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359207 effective words/s', 'datetime': '2023-12-09T17:05:36.911144', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:36,911 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:36.911411', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:42,319 - Processed run 4 for mu=0.3 on cuda:3. Elapsed time: 8.72 seconds
2023-12-09 17:05:43,350 - collecting all words and their counts
2023-12-09 17:05:43,350 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:43,411 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:43,411 - Creating a fresh vocabulary
2023-12-09 17:05:43,413 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:43.413747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:43,413 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:43.413846', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:43,416 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:43,416 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:43,416 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:43.416930', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:43,422 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:43,422 - resetting layer weights
2023-12-09 17:05:43,422 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:43.422908', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:43,423 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:43.423023', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:44,450 - EPOCH 0 - PROGRESS: at 46.25% examples, 361258 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:05:45,461 - EPOCH 0 - PROGRESS: at 96.25% examples, 378458 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:05:45,466 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392175 effective words/s
2023-12-09 17:05:45,466 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 391536 effective words/s', 'datetime': '2023-12-09T17:05:45.466628', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:45,466 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:45.466694', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:50,494 - Processed run 4 for mu=0.35 on cuda:4. Elapsed time: 8.17 seconds
2023-12-09 17:05:51,630 - collecting all words and their counts
2023-12-09 17:05:51,630 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:05:51,689 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:05:51,690 - Creating a fresh vocabulary
2023-12-09 17:05:51,691 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:05:51.691970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:51,692 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:05:51.692038', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:51,694 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:05:51,694 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:05:51,695 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:05:51.695001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:05:51,699 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:05:51,699 - resetting layer weights
2023-12-09 17:05:51,700 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:05:51.700062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:05:51,700 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:05:51.700575', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:52,724 - EPOCH 0 - PROGRESS: at 46.25% examples, 362504 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:05:53,727 - EPOCH 0 - PROGRESS: at 96.25% examples, 380411 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:05:53,740 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392725 effective words/s
2023-12-09 17:05:53,741 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392090 effective words/s', 'datetime': '2023-12-09T17:05:53.741015', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:05:53,741 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:05:53.741187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:05:59,768 - Processed run 4 for mu=0.4 on cuda:1. Elapsed time: 9.27 seconds
2023-12-09 17:06:00,875 - collecting all words and their counts
2023-12-09 17:06:00,875 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:06:00,937 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:06:00,937 - Creating a fresh vocabulary
2023-12-09 17:06:00,939 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:06:00.939082', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:00,939 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:06:00.939166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:00,942 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:06:00,942 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:06:00,942 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:06:00.942406', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:00,947 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:06:00,947 - resetting layer weights
2023-12-09 17:06:00,947 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:06:00.947480', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:06:00,947 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:06:00.947831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:01,960 - EPOCH 0 - PROGRESS: at 46.25% examples, 366439 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:06:02,962 - EPOCH 0 - PROGRESS: at 97.50% examples, 387811 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:06:02,981 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393956 effective words/s
2023-12-09 17:06:02,982 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393295 effective words/s', 'datetime': '2023-12-09T17:06:02.982001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:02,982 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:06:02.982175', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:06:09,038 - Processed run 4 for mu=0.45 on cuda:2. Elapsed time: 9.27 seconds
2023-12-09 17:06:10,210 - collecting all words and their counts
2023-12-09 17:06:10,210 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:06:10,270 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:06:10,270 - Creating a fresh vocabulary
2023-12-09 17:06:10,272 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:06:10.272400', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:10,272 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:06:10.272474', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:10,275 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:06:10,275 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:06:10,275 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:06:10.275372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:10,280 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:06:10,280 - resetting layer weights
2023-12-09 17:06:10,280 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:06:10.280397', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:06:10,280 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:06:10.280815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:11,299 - EPOCH 0 - PROGRESS: at 46.25% examples, 364448 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:06:12,324 - EPOCH 0 - PROGRESS: at 97.50% examples, 382239 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:06:12,334 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 390089 effective words/s
2023-12-09 17:06:12,335 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 389427 effective words/s', 'datetime': '2023-12-09T17:06:12.335191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:12,335 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:06:12.335364', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:06:34,547 - Processed run 4 for mu=0.5 on cuda:3. Elapsed time: 25.51 seconds
2023-12-09 17:06:35,773 - collecting all words and their counts
2023-12-09 17:06:35,773 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:06:35,832 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:06:35,832 - Creating a fresh vocabulary
2023-12-09 17:06:35,834 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:06:35.834826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:35,834 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:06:35.834896', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:35,837 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:06:35,837 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:06:35,837 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:06:35.837824', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:35,842 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:06:35,842 - resetting layer weights
2023-12-09 17:06:35,843 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:06:35.843041', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:06:35,843 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:06:35.843430', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:36,874 - EPOCH 0 - PROGRESS: at 46.25% examples, 359969 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:06:37,875 - EPOCH 0 - PROGRESS: at 97.50% examples, 384528 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:06:37,878 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393806 effective words/s
2023-12-09 17:06:37,878 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393161 effective words/s', 'datetime': '2023-12-09T17:06:37.878294', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:37,878 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:06:37.878455', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:06:44,176 - Processed run 4 for mu=0.55 on cuda:4. Elapsed time: 9.63 seconds
2023-12-09 17:06:45,537 - collecting all words and their counts
2023-12-09 17:06:45,537 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:06:45,597 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:06:45,597 - Creating a fresh vocabulary
2023-12-09 17:06:45,599 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:06:45.599756', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:45,599 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:06:45.599836', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:45,602 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:06:45,602 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:06:45,602 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:06:45.602711', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:45,607 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:06:45,607 - resetting layer weights
2023-12-09 17:06:45,607 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:06:45.607746', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:06:45,608 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:06:45.608218', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:46,636 - EPOCH 0 - PROGRESS: at 46.25% examples, 360861 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:06:47,644 - EPOCH 0 - PROGRESS: at 97.50% examples, 383603 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:06:47,655 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 391409 effective words/s
2023-12-09 17:06:47,655 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390771 effective words/s', 'datetime': '2023-12-09T17:06:47.655529', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:47,655 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:06:47.655709', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:06:54,604 - Processed run 4 for mu=0.6 on cuda:1. Elapsed time: 10.43 seconds
2023-12-09 17:06:56,009 - collecting all words and their counts
2023-12-09 17:06:56,009 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:06:56,069 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:06:56,070 - Creating a fresh vocabulary
2023-12-09 17:06:56,072 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:06:56.072038', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:56,072 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:06:56.072135', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:56,075 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:06:56,075 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:06:56,075 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:06:56.075163', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:06:56,079 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:06:56,079 - resetting layer weights
2023-12-09 17:06:56,080 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:06:56.080248', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:06:56,080 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:06:56.080762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:57,097 - EPOCH 0 - PROGRESS: at 42.50% examples, 335319 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:06:58,179 - EPOCH 0 - PROGRESS: at 91.25% examples, 348393 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:06:58,302 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360649 effective words/s
2023-12-09 17:06:58,302 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 360095 effective words/s', 'datetime': '2023-12-09T17:06:58.302476', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:06:58,302 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:06:58.302656', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:07:34,690 - Processed run 4 for mu=0.65 on cuda:2. Elapsed time: 40.08 seconds
2023-12-09 17:07:36,223 - collecting all words and their counts
2023-12-09 17:07:36,224 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:07:36,284 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:07:36,284 - Creating a fresh vocabulary
2023-12-09 17:07:36,286 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:07:36.286888', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:36,286 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:07:36.286970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:36,289 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:07:36,290 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:07:36,290 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:07:36.290085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:36,294 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:07:36,294 - resetting layer weights
2023-12-09 17:07:36,295 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:07:36.295314', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:07:36,295 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:07:36.295813', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:07:37,314 - EPOCH 0 - PROGRESS: at 46.25% examples, 364450 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:07:38,333 - EPOCH 0 - PROGRESS: at 98.75% examples, 388312 words/s, in_qsize 1, out_qsize 1
2023-12-09 17:07:38,334 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393017 effective words/s
2023-12-09 17:07:38,334 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392371 effective words/s', 'datetime': '2023-12-09T17:07:38.334777', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:07:38,335 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:07:38.335196', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:07:46,917 - Processed run 4 for mu=0.7 on cuda:3. Elapsed time: 12.23 seconds
2023-12-09 17:07:48,587 - collecting all words and their counts
2023-12-09 17:07:48,587 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:07:48,646 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:07:48,646 - Creating a fresh vocabulary
2023-12-09 17:07:48,648 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:07:48.648786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:48,648 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:07:48.648865', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:48,651 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:07:48,651 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:07:48,651 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:07:48.651741', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:07:48,656 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:07:48,656 - resetting layer weights
2023-12-09 17:07:48,656 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:07:48.656933', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:07:48,657 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:07:48.657296', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:07:49,674 - EPOCH 0 - PROGRESS: at 46.25% examples, 364912 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:07:50,684 - EPOCH 0 - PROGRESS: at 98.75% examples, 390232 words/s, in_qsize 1, out_qsize 1
2023-12-09 17:07:50,686 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 394869 effective words/s
2023-12-09 17:07:50,686 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 394217 effective words/s', 'datetime': '2023-12-09T17:07:50.686708', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:07:50,686 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:07:50.686872', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:08:02,029 - Processed run 4 for mu=0.75 on cuda:4. Elapsed time: 15.11 seconds
2023-12-09 17:08:03,832 - collecting all words and their counts
2023-12-09 17:08:03,832 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:08:03,891 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:08:03,892 - Creating a fresh vocabulary
2023-12-09 17:08:03,893 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:08:03.893940', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:03,894 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:08:03.894014', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:03,896 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:08:03,896 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:08:03,896 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:08:03.896899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:03,901 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:08:03,901 - resetting layer weights
2023-12-09 17:08:03,902 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:08:03.902049', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:08:03,902 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:08:03.902494', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:04,927 - EPOCH 0 - PROGRESS: at 46.25% examples, 362198 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:08:05,931 - EPOCH 0 - PROGRESS: at 96.25% examples, 380199 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:08:05,937 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393673 effective words/s
2023-12-09 17:08:05,938 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393019 effective words/s', 'datetime': '2023-12-09T17:08:05.938093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:05,938 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:08:05.938267', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:08:16,422 - Processed run 4 for mu=0.8 on cuda:1. Elapsed time: 14.39 seconds
2023-12-09 17:08:18,549 - collecting all words and their counts
2023-12-09 17:08:18,550 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:08:18,610 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:08:18,610 - Creating a fresh vocabulary
2023-12-09 17:08:18,612 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:08:18.612061', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:18,612 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:08:18.612140', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:18,614 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:08:18,614 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:08:18,615 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:08:18.615022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:18,619 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:08:18,619 - resetting layer weights
2023-12-09 17:08:18,620 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:08:18.619988', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:08:18,620 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:08:18.620466', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:19,635 - EPOCH 0 - PROGRESS: at 46.25% examples, 365508 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:08:20,643 - EPOCH 0 - PROGRESS: at 97.50% examples, 386103 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:08:20,662 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392319 effective words/s
2023-12-09 17:08:20,663 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 391680 effective words/s', 'datetime': '2023-12-09T17:08:20.663021', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:20,663 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:08:20.663192', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:08:32,078 - Processed run 4 for mu=0.85 on cuda:2. Elapsed time: 15.65 seconds
2023-12-09 17:08:34,109 - collecting all words and their counts
2023-12-09 17:08:34,109 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:08:34,168 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:08:34,168 - Creating a fresh vocabulary
2023-12-09 17:08:34,170 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:08:34.170778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:34,170 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:08:34.170845', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:34,173 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:08:34,173 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:08:34,173 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:08:34.173774', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:34,178 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:08:34,178 - resetting layer weights
2023-12-09 17:08:34,178 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:08:34.178897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:08:34,179 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:08:34.179372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:35,201 - EPOCH 0 - PROGRESS: at 46.25% examples, 363208 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:08:36,206 - EPOCH 0 - PROGRESS: at 97.50% examples, 385331 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:08:36,217 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393204 effective words/s
2023-12-09 17:08:36,217 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392542 effective words/s', 'datetime': '2023-12-09T17:08:36.217446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:36,217 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:08:36.217618', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:08:48,131 - Processed run 4 for mu=0.9 on cuda:3. Elapsed time: 16.05 seconds
2023-12-09 17:08:50,348 - collecting all words and their counts
2023-12-09 17:08:50,348 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:08:50,408 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:08:50,408 - Creating a fresh vocabulary
2023-12-09 17:08:50,410 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:08:50.410206', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:50,410 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:08:50.410285', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:50,413 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:08:50,413 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:08:50,413 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:08:50.413098', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:08:50,417 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:08:50,417 - resetting layer weights
2023-12-09 17:08:50,418 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:08:50.418203', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:08:50,418 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:08:50.418609', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:51,425 - EPOCH 0 - PROGRESS: at 41.25% examples, 328752 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:08:52,454 - EPOCH 0 - PROGRESS: at 87.50% examples, 344400 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:08:52,682 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353824 effective words/s
2023-12-09 17:08:52,683 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353293 effective words/s', 'datetime': '2023-12-09T17:08:52.683097', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:08:52,683 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:08:52.683654', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:05,577 - Processed run 4 for mu=0.95 on cuda:4. Elapsed time: 17.44 seconds
2023-12-09 17:09:08,002 - collecting all words and their counts
2023-12-09 17:09:08,002 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:08,063 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:08,063 - Creating a fresh vocabulary
2023-12-09 17:09:08,065 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:08.065042', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:08,065 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:08.065114', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:08,067 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:08,067 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:08,067 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:08.067959', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:08,072 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:08,072 - resetting layer weights
2023-12-09 17:09:08,072 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:08.072943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:08,073 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:08.073369', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:09,091 - EPOCH 0 - PROGRESS: at 46.25% examples, 364528 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:10,092 - EPOCH 0 - PROGRESS: at 97.50% examples, 387000 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:09:10,122 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 391080 effective words/s
2023-12-09 17:09:10,122 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390452 effective words/s', 'datetime': '2023-12-09T17:09:10.122346', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:10,122 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:10.122528', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:21,695 - Processed run 4 for mu=1.0 on cuda:1. Elapsed time: 16.12 seconds
2023-12-09 17:09:22,694 - collecting all words and their counts
2023-12-09 17:09:22,694 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:22,753 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:22,753 - Creating a fresh vocabulary
2023-12-09 17:09:22,755 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:22.755239', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:22,755 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:22.755309', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:22,758 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:22,758 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:22,758 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:22.758188', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:22,763 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:22,763 - resetting layer weights
2023-12-09 17:09:22,763 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:22.763421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:22,763 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:22.763815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:23,797 - EPOCH 0 - PROGRESS: at 61.25% examples, 475414 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:24,275 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 530385 effective words/s
2023-12-09 17:09:24,275 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 529178 effective words/s', 'datetime': '2023-12-09T17:09:24.275665', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:24,275 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:24.275852', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:28,252 - Processed run 5 for mu=0.0 on cuda:1. Elapsed time: 6.56 seconds
2023-12-09 17:09:29,183 - collecting all words and their counts
2023-12-09 17:09:29,183 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:29,247 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:29,247 - Creating a fresh vocabulary
2023-12-09 17:09:29,249 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:29.249589', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:29,249 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:29.249680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:29,252 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:29,252 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:29,252 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:29.252584', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:29,257 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:29,257 - resetting layer weights
2023-12-09 17:09:29,257 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:29.257630', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:29,258 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:29.258009', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:30,265 - EPOCH 0 - PROGRESS: at 46.25% examples, 368306 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:09:31,278 - EPOCH 0 - PROGRESS: at 97.50% examples, 386633 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:09:31,286 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 394999 effective words/s
2023-12-09 17:09:31,286 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 394352 effective words/s', 'datetime': '2023-12-09T17:09:31.286726', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:31,286 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:31.286897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:35,930 - Processed run 5 for mu=0.05 on cuda:2. Elapsed time: 7.68 seconds
2023-12-09 17:09:36,688 - collecting all words and their counts
2023-12-09 17:09:36,688 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:36,746 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:36,747 - Creating a fresh vocabulary
2023-12-09 17:09:36,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:36.748989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:36,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:36.749077', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:36,751 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:36,751 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:36,751 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:36.751980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:36,756 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:36,756 - resetting layer weights
2023-12-09 17:09:36,757 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:36.757254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:36,757 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:36.757673', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:37,777 - EPOCH 0 - PROGRESS: at 41.25% examples, 324531 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:38,791 - EPOCH 0 - PROGRESS: at 86.25% examples, 339886 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:39,049 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349572 effective words/s
2023-12-09 17:09:39,049 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349051 effective words/s', 'datetime': '2023-12-09T17:09:39.049685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:39,049 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:39.049922', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:43,823 - Processed run 5 for mu=0.1 on cuda:3. Elapsed time: 7.89 seconds
2023-12-09 17:09:44,619 - collecting all words and their counts
2023-12-09 17:09:44,619 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:44,678 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:44,678 - Creating a fresh vocabulary
2023-12-09 17:09:44,680 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:44.680456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:44,680 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:44.680550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:44,683 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:44,683 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:44,683 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:44.683626', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:44,688 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:44,688 - resetting layer weights
2023-12-09 17:09:44,689 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:44.689159', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:44,689 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:44.689292', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:45,710 - EPOCH 0 - PROGRESS: at 46.25% examples, 363358 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:46,713 - EPOCH 0 - PROGRESS: at 100.00% examples, 395888 words/s, in_qsize 0, out_qsize 1
2023-12-09 17:09:46,713 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 395863 effective words/s
2023-12-09 17:09:46,713 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 395231 effective words/s', 'datetime': '2023-12-09T17:09:46.713498', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:46,713 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:46.713953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:09:51,165 - Processed run 5 for mu=0.15 on cuda:4. Elapsed time: 7.34 seconds
2023-12-09 17:09:52,036 - collecting all words and their counts
2023-12-09 17:09:52,036 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:09:52,095 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:09:52,095 - Creating a fresh vocabulary
2023-12-09 17:09:52,097 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:09:52.097601', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:52,097 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:09:52.097685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:52,100 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:09:52,100 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:09:52,100 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:09:52.100595', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:09:52,105 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:09:52,105 - resetting layer weights
2023-12-09 17:09:52,105 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:09:52.105686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:09:52,106 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:09:52.106101', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:53,122 - EPOCH 0 - PROGRESS: at 41.25% examples, 325798 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:54,124 - EPOCH 0 - PROGRESS: at 88.75% examples, 352258 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:09:54,354 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356326 effective words/s
2023-12-09 17:09:54,354 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355791 effective words/s', 'datetime': '2023-12-09T17:09:54.354684', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:09:54,354 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:09:54.354860', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:00,251 - Processed run 5 for mu=0.2 on cuda:1. Elapsed time: 9.08 seconds
2023-12-09 17:10:01,190 - collecting all words and their counts
2023-12-09 17:10:01,191 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:01,250 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:01,250 - Creating a fresh vocabulary
2023-12-09 17:10:01,252 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:01.252398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:01,252 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:01.252465', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:01,255 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:01,255 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:01,255 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:01.255256', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:01,259 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:01,259 - resetting layer weights
2023-12-09 17:10:01,260 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:01.260167', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:01,260 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:01.260591', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:02,266 - EPOCH 0 - PROGRESS: at 42.50% examples, 339068 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:03,288 - EPOCH 0 - PROGRESS: at 90.00% examples, 355534 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:03,496 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358270 effective words/s
2023-12-09 17:10:03,496 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357738 effective words/s', 'datetime': '2023-12-09T17:10:03.496938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:03,497 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:03.497112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:08,684 - Processed run 5 for mu=0.25 on cuda:2. Elapsed time: 8.43 seconds
2023-12-09 17:10:09,596 - collecting all words and their counts
2023-12-09 17:10:09,596 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:09,655 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:09,655 - Creating a fresh vocabulary
2023-12-09 17:10:09,657 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:09.657461', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:09,657 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:09.657533', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:09,660 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:09,660 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:09,660 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:09.660389', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:09,665 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:09,665 - resetting layer weights
2023-12-09 17:10:09,665 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:09.665527', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:09,665 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:09.665913', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:10,669 - EPOCH 0 - PROGRESS: at 41.25% examples, 329758 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:10:11,672 - EPOCH 0 - PROGRESS: at 88.75% examples, 354484 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:11,899 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358697 effective words/s
2023-12-09 17:10:11,899 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358152 effective words/s', 'datetime': '2023-12-09T17:10:11.899674', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:11,900 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:11.900335', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:17,662 - Processed run 5 for mu=0.3 on cuda:3. Elapsed time: 8.98 seconds
2023-12-09 17:10:18,682 - collecting all words and their counts
2023-12-09 17:10:18,682 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:18,743 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:18,743 - Creating a fresh vocabulary
2023-12-09 17:10:18,745 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:18.745215', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:18,745 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:18.745280', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:18,748 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:18,748 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:18,748 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:18.748099', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:18,752 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:18,752 - resetting layer weights
2023-12-09 17:10:18,753 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:18.753112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:18,753 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:18.753456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:19,765 - EPOCH 0 - PROGRESS: at 41.25% examples, 327106 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:20,772 - EPOCH 0 - PROGRESS: at 88.75% examples, 352225 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:21,012 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354597 effective words/s
2023-12-09 17:10:21,013 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354063 effective words/s', 'datetime': '2023-12-09T17:10:21.013010', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:21,013 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:21.013182', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:26,195 - Processed run 5 for mu=0.35 on cuda:4. Elapsed time: 8.53 seconds
2023-12-09 17:10:27,270 - collecting all words and their counts
2023-12-09 17:10:27,270 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:27,329 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:27,329 - Creating a fresh vocabulary
2023-12-09 17:10:27,331 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:27.331869', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:27,331 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:27.331935', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:27,334 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:27,334 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:27,334 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:27.334814', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:27,339 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:27,339 - resetting layer weights
2023-12-09 17:10:27,340 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:27.340067', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:27,340 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:27.340460', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:28,357 - EPOCH 0 - PROGRESS: at 42.50% examples, 335364 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:29,358 - EPOCH 0 - PROGRESS: at 90.00% examples, 357423 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:29,573 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358792 effective words/s
2023-12-09 17:10:29,573 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358254 effective words/s', 'datetime': '2023-12-09T17:10:29.573580', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:29,573 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:29.573757', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:35,153 - Processed run 5 for mu=0.4 on cuda:1. Elapsed time: 8.96 seconds
2023-12-09 17:10:36,226 - collecting all words and their counts
2023-12-09 17:10:36,226 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:36,286 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:36,286 - Creating a fresh vocabulary
2023-12-09 17:10:36,288 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:36.288435', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:36,288 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:36.288502', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:36,291 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:36,291 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:36,291 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:36.291299', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:36,295 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:36,295 - resetting layer weights
2023-12-09 17:10:36,296 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:36.296301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:36,296 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:36.296767', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:37,303 - EPOCH 0 - PROGRESS: at 42.50% examples, 338987 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:10:38,317 - EPOCH 0 - PROGRESS: at 88.75% examples, 351844 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:38,533 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358120 effective words/s
2023-12-09 17:10:38,534 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357572 effective words/s', 'datetime': '2023-12-09T17:10:38.534150', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:38,534 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:38.534330', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:44,296 - Processed run 5 for mu=0.45 on cuda:2. Elapsed time: 9.14 seconds
2023-12-09 17:10:45,401 - collecting all words and their counts
2023-12-09 17:10:45,401 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:45,462 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:45,462 - Creating a fresh vocabulary
2023-12-09 17:10:45,464 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:45.464446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:45,464 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:45.464525', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:45,467 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:45,467 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:45,467 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:45.467359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:45,471 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:45,472 - resetting layer weights
2023-12-09 17:10:45,472 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:45.472353', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:45,472 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:45.472790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:46,482 - EPOCH 0 - PROGRESS: at 42.50% examples, 337890 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:47,563 - EPOCH 0 - PROGRESS: at 91.25% examples, 349704 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:47,691 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 361194 effective words/s
2023-12-09 17:10:47,691 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 360611 effective words/s', 'datetime': '2023-12-09T17:10:47.691331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:47,691 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:47.691566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:10:53,957 - Processed run 5 for mu=0.5 on cuda:3. Elapsed time: 9.66 seconds
2023-12-09 17:10:55,234 - collecting all words and their counts
2023-12-09 17:10:55,234 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:10:55,295 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:10:55,295 - Creating a fresh vocabulary
2023-12-09 17:10:55,297 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:10:55.297418', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:55,297 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:10:55.297489', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:55,300 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:10:55,300 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:10:55,300 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:10:55.300338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:10:55,305 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:10:55,305 - resetting layer weights
2023-12-09 17:10:55,305 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:10:55.305482', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:10:55,305 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:10:55.305874', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:56,316 - EPOCH 0 - PROGRESS: at 41.25% examples, 327574 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:57,331 - EPOCH 0 - PROGRESS: at 87.50% examples, 346049 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:10:57,574 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353192 effective words/s
2023-12-09 17:10:57,574 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352683 effective words/s', 'datetime': '2023-12-09T17:10:57.574274', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:10:57,574 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:10:57.574453', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:11:05,069 - Processed run 5 for mu=0.55 on cuda:4. Elapsed time: 11.11 seconds
2023-12-09 17:11:06,462 - collecting all words and their counts
2023-12-09 17:11:06,462 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:11:06,523 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:11:06,523 - Creating a fresh vocabulary
2023-12-09 17:11:06,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:11:06.525132', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:06,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:11:06.525207', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:06,527 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:11:06,528 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:11:06,528 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:11:06.528076', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:06,532 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:11:06,532 - resetting layer weights
2023-12-09 17:11:06,533 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:11:06.533210', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:11:06,533 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:11:06.533551', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:07,545 - EPOCH 0 - PROGRESS: at 41.25% examples, 327098 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:08,545 - EPOCH 0 - PROGRESS: at 90.00% examples, 358391 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:11:08,758 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360060 effective words/s
2023-12-09 17:11:08,758 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359520 effective words/s', 'datetime': '2023-12-09T17:11:08.758815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:08,759 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:11:08.758999', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:11:15,950 - Processed run 5 for mu=0.6 on cuda:1. Elapsed time: 10.88 seconds
2023-12-09 17:11:17,386 - collecting all words and their counts
2023-12-09 17:11:17,386 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:11:17,447 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:11:17,447 - Creating a fresh vocabulary
2023-12-09 17:11:17,449 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:11:17.449849', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:17,449 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:11:17.449936', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:17,452 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:11:17,452 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:11:17,452 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:11:17.452866', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:17,457 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:11:17,457 - resetting layer weights
2023-12-09 17:11:17,458 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:11:17.458058', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:11:17,458 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:11:17.458453', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:18,480 - EPOCH 0 - PROGRESS: at 42.50% examples, 333742 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:19,548 - EPOCH 0 - PROGRESS: at 91.25% examples, 349728 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:19,687 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359476 effective words/s
2023-12-09 17:11:19,687 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358940 effective words/s', 'datetime': '2023-12-09T17:11:19.687311', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:19,687 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:11:19.687485', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:11:27,972 - Processed run 5 for mu=0.65 on cuda:2. Elapsed time: 12.02 seconds
2023-12-09 17:11:29,553 - collecting all words and their counts
2023-12-09 17:11:29,554 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:11:29,613 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:11:29,614 - Creating a fresh vocabulary
2023-12-09 17:11:29,616 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:11:29.615991', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:29,616 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:11:29.616083', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:29,618 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:11:29,618 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:11:29,618 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:11:29.618989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:29,623 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:11:29,623 - resetting layer weights
2023-12-09 17:11:29,624 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:11:29.624196', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:11:29,624 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:11:29.624649', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:30,643 - EPOCH 0 - PROGRESS: at 41.25% examples, 324856 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:31,734 - EPOCH 0 - PROGRESS: at 91.25% examples, 346457 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:31,855 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359192 effective words/s
2023-12-09 17:11:31,855 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358643 effective words/s', 'datetime': '2023-12-09T17:11:31.855360', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:31,855 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:11:31.855538', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:11:49,574 - Processed run 5 for mu=0.7 on cuda:3. Elapsed time: 21.60 seconds
2023-12-09 17:11:51,236 - collecting all words and their counts
2023-12-09 17:11:51,236 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:11:51,296 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:11:51,296 - Creating a fresh vocabulary
2023-12-09 17:11:51,298 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:11:51.298117', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:51,298 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:11:51.298187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:51,301 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:11:51,301 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:11:51,301 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:11:51.301084', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:11:51,305 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:11:51,305 - resetting layer weights
2023-12-09 17:11:51,306 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:11:51.306273', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:11:51,306 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:11:51.306692', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:52,316 - EPOCH 0 - PROGRESS: at 41.25% examples, 328008 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:11:53,415 - EPOCH 0 - PROGRESS: at 91.25% examples, 346726 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:11:53,528 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360606 effective words/s
2023-12-09 17:11:53,528 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 360040 effective words/s', 'datetime': '2023-12-09T17:11:53.528738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:11:53,528 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:11:53.528911', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:12:03,891 - Processed run 5 for mu=0.75 on cuda:4. Elapsed time: 14.32 seconds
2023-12-09 17:12:05,691 - collecting all words and their counts
2023-12-09 17:12:05,691 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:12:05,752 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:12:05,752 - Creating a fresh vocabulary
2023-12-09 17:12:05,754 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:12:05.754153', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:05,754 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:12:05.754221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:05,757 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:12:05,757 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:12:05,757 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:12:05.757151', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:05,761 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:12:05,761 - resetting layer weights
2023-12-09 17:12:05,762 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:12:05.762291', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:12:05,762 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:12:05.762739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:06,768 - EPOCH 0 - PROGRESS: at 42.50% examples, 339252 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:07,850 - EPOCH 0 - PROGRESS: at 91.25% examples, 350149 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:07,976 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 361897 effective words/s
2023-12-09 17:12:07,976 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 361333 effective words/s', 'datetime': '2023-12-09T17:12:07.976836', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:07,977 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:12:07.977009', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:12:19,110 - Processed run 5 for mu=0.8 on cuda:1. Elapsed time: 15.22 seconds
2023-12-09 17:12:20,999 - collecting all words and their counts
2023-12-09 17:12:20,999 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:12:21,059 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:12:21,060 - Creating a fresh vocabulary
2023-12-09 17:12:21,062 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:12:21.062011', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:21,062 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:12:21.062093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:21,064 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:12:21,064 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:12:21,065 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:12:21.065025', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:21,069 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:12:21,069 - resetting layer weights
2023-12-09 17:12:21,070 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:12:21.070074', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:12:21,070 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:12:21.070502', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:22,083 - EPOCH 0 - PROGRESS: at 41.25% examples, 326798 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:23,088 - EPOCH 0 - PROGRESS: at 86.25% examples, 342400 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:23,325 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355353 effective words/s
2023-12-09 17:12:23,325 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354818 effective words/s', 'datetime': '2023-12-09T17:12:23.325254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:23,325 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:12:23.325436', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:12:34,654 - Processed run 5 for mu=0.85 on cuda:2. Elapsed time: 15.54 seconds
2023-12-09 17:12:36,804 - collecting all words and their counts
2023-12-09 17:12:36,804 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:12:36,867 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:12:36,867 - Creating a fresh vocabulary
2023-12-09 17:12:36,870 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:12:36.869991', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:36,870 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:12:36.870100', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:36,873 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:12:36,873 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:12:36,873 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:12:36.873154', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:36,878 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:12:36,878 - resetting layer weights
2023-12-09 17:12:36,878 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:12:36.878453', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:12:36,878 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:12:36.878848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:37,893 - EPOCH 0 - PROGRESS: at 46.25% examples, 366112 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:38,895 - EPOCH 0 - PROGRESS: at 97.50% examples, 387428 words/s, in_qsize 2, out_qsize 1
2023-12-09 17:12:38,911 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 394348 effective words/s
2023-12-09 17:12:38,911 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393607 effective words/s', 'datetime': '2023-12-09T17:12:38.911410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:38,911 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:12:38.911581', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:12:50,231 - Processed run 5 for mu=0.9 on cuda:3. Elapsed time: 15.57 seconds
2023-12-09 17:12:52,607 - collecting all words and their counts
2023-12-09 17:12:52,607 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:12:52,667 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:12:52,667 - Creating a fresh vocabulary
2023-12-09 17:12:52,669 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:12:52.669457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:52,669 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:12:52.669531', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:52,672 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:12:52,672 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:12:52,672 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:12:52.672375', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:12:52,677 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:12:52,677 - resetting layer weights
2023-12-09 17:12:52,677 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:12:52.677509', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:12:52,677 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:12:52.677938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:53,691 - EPOCH 0 - PROGRESS: at 41.25% examples, 326536 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:12:54,702 - EPOCH 0 - PROGRESS: at 88.75% examples, 351292 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:12:54,951 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352366 effective words/s
2023-12-09 17:12:54,951 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351832 effective words/s', 'datetime': '2023-12-09T17:12:54.951824', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:12:54,952 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:12:54.952001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:07,378 - Processed run 5 for mu=0.95 on cuda:4. Elapsed time: 17.15 seconds
2023-12-09 17:13:09,829 - collecting all words and their counts
2023-12-09 17:13:09,830 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:09,890 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:09,890 - Creating a fresh vocabulary
2023-12-09 17:13:09,892 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:09.892088', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:09,892 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:09.892166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:09,894 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:09,894 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:09,894 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:09.894977', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:09,899 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:09,899 - resetting layer weights
2023-12-09 17:13:09,900 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:09.900038', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:09,900 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:09.900497', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:10,943 - EPOCH 0 - PROGRESS: at 46.25% examples, 355932 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:11,961 - EPOCH 0 - PROGRESS: at 96.25% examples, 374209 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:13:11,985 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384244 effective words/s
2023-12-09 17:13:11,985 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383643 effective words/s', 'datetime': '2023-12-09T17:13:11.985841', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:11,986 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:11.986014', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:24,165 - Processed run 5 for mu=1.0 on cuda:1. Elapsed time: 16.79 seconds
2023-12-09 17:13:25,137 - collecting all words and their counts
2023-12-09 17:13:25,137 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:25,195 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:25,196 - Creating a fresh vocabulary
2023-12-09 17:13:25,198 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:25.198044', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:25,198 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:25.198115', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:25,200 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:25,201 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:25,201 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:25.201049', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:25,205 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:25,205 - resetting layer weights
2023-12-09 17:13:25,206 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:25.206119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:25,206 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:25.206566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:26,228 - EPOCH 0 - PROGRESS: at 56.25% examples, 441676 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:26,783 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 508377 effective words/s
2023-12-09 17:13:26,783 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 507279 effective words/s', 'datetime': '2023-12-09T17:13:26.783684', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:26,783 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:26.783863', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:30,695 - Processed run 6 for mu=0.0 on cuda:1. Elapsed time: 6.53 seconds
2023-12-09 17:13:31,723 - collecting all words and their counts
2023-12-09 17:13:31,723 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:31,782 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:31,783 - Creating a fresh vocabulary
2023-12-09 17:13:31,784 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:31.784948', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:31,785 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:31.785021', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:31,787 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:31,787 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:31,787 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:31.787861', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:31,792 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:31,792 - resetting layer weights
2023-12-09 17:13:31,792 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:31.792980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:31,793 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:31.793397', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:32,802 - EPOCH 0 - PROGRESS: at 41.25% examples, 328062 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:33,903 - EPOCH 0 - PROGRESS: at 91.25% examples, 346436 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:34,017 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360200 effective words/s
2023-12-09 17:13:34,018 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359634 effective words/s', 'datetime': '2023-12-09T17:13:34.017971', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:34,018 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:34.018527', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:38,408 - Processed run 6 for mu=0.05 on cuda:2. Elapsed time: 7.71 seconds
2023-12-09 17:13:39,233 - collecting all words and their counts
2023-12-09 17:13:39,233 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:39,292 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:39,292 - Creating a fresh vocabulary
2023-12-09 17:13:39,294 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:39.294704', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:39,294 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:39.294769', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:39,297 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:39,297 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:39,297 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:39.297672', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:39,302 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:39,302 - resetting layer weights
2023-12-09 17:13:39,302 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:39.302771', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:39,303 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:39.303187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:40,349 - EPOCH 0 - PROGRESS: at 46.25% examples, 354834 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:41,372 - EPOCH 0 - PROGRESS: at 96.25% examples, 372628 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:13:41,386 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384576 effective words/s
2023-12-09 17:13:41,386 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383940 effective words/s', 'datetime': '2023-12-09T17:13:41.386917', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:41,387 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:41.387093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:45,920 - Processed run 6 for mu=0.1 on cuda:3. Elapsed time: 7.51 seconds
2023-12-09 17:13:46,764 - collecting all words and their counts
2023-12-09 17:13:46,764 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:46,823 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:46,823 - Creating a fresh vocabulary
2023-12-09 17:13:46,825 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:46.825846', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:46,825 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:46.825916', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:46,828 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:46,828 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:46,828 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:46.828821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:46,833 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:46,833 - resetting layer weights
2023-12-09 17:13:46,833 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:46.833936', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:46,834 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:46.834404', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:47,845 - EPOCH 0 - PROGRESS: at 41.25% examples, 327545 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:48,854 - EPOCH 0 - PROGRESS: at 88.75% examples, 352064 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:49,091 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355023 effective words/s
2023-12-09 17:13:49,091 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354486 effective words/s', 'datetime': '2023-12-09T17:13:49.091266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:49,091 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:49.091446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:13:53,449 - Processed run 6 for mu=0.15 on cuda:4. Elapsed time: 7.53 seconds
2023-12-09 17:13:54,344 - collecting all words and their counts
2023-12-09 17:13:54,345 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:13:54,405 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:13:54,405 - Creating a fresh vocabulary
2023-12-09 17:13:54,407 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:13:54.407107', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:54,407 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:13:54.407178', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:54,410 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:13:54,410 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:13:54,410 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:13:54.410100', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:13:54,414 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:13:54,414 - resetting layer weights
2023-12-09 17:13:54,415 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:13:54.415284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:13:54,415 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:13:54.415714', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:55,435 - EPOCH 0 - PROGRESS: at 41.25% examples, 324530 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:56,441 - EPOCH 0 - PROGRESS: at 87.50% examples, 346086 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:13:56,677 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354245 effective words/s
2023-12-09 17:13:56,677 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353707 effective words/s', 'datetime': '2023-12-09T17:13:56.677550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:13:56,677 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:13:56.677734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:01,754 - Processed run 6 for mu=0.2 on cuda:1. Elapsed time: 8.30 seconds
2023-12-09 17:14:02,673 - collecting all words and their counts
2023-12-09 17:14:02,673 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:02,733 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:02,733 - Creating a fresh vocabulary
2023-12-09 17:14:02,735 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:02.735195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:02,735 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:02.735267', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:02,738 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:02,738 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:02,738 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:02.738205', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:02,742 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:02,743 - resetting layer weights
2023-12-09 17:14:02,743 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:02.743358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:02,743 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:02.743825', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:03,786 - EPOCH 0 - PROGRESS: at 46.25% examples, 355879 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:14:04,807 - EPOCH 0 - PROGRESS: at 96.25% examples, 373633 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:14:04,842 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381760 effective words/s
2023-12-09 17:14:04,842 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381154 effective words/s', 'datetime': '2023-12-09T17:14:04.842785', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:04,842 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:04.842966', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:10,151 - Processed run 6 for mu=0.25 on cuda:2. Elapsed time: 8.40 seconds
2023-12-09 17:14:11,076 - collecting all words and their counts
2023-12-09 17:14:11,076 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:11,136 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:11,136 - Creating a fresh vocabulary
2023-12-09 17:14:11,138 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:11.138242', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:11,138 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:11.138318', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:11,141 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:11,141 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:11,141 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:11.141216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:11,145 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:11,146 - resetting layer weights
2023-12-09 17:14:11,146 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:11.146359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:11,146 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:11.146827', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:12,163 - EPOCH 0 - PROGRESS: at 41.25% examples, 325734 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:14:13,163 - EPOCH 0 - PROGRESS: at 90.00% examples, 357551 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:14:13,383 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358129 effective words/s
2023-12-09 17:14:13,384 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357587 effective words/s', 'datetime': '2023-12-09T17:14:13.384119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:13,384 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:13.384304', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:19,652 - Processed run 6 for mu=0.3 on cuda:3. Elapsed time: 9.50 seconds
2023-12-09 17:14:20,670 - collecting all words and their counts
2023-12-09 17:14:20,670 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:20,731 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:20,731 - Creating a fresh vocabulary
2023-12-09 17:14:20,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:20.733588', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:20,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:20.733658', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:20,736 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:20,736 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:20,736 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:20.736510', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:20,741 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:20,741 - resetting layer weights
2023-12-09 17:14:20,741 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:20.741687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:20,742 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:20.742115', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:21,760 - EPOCH 0 - PROGRESS: at 41.25% examples, 325179 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:14:22,762 - EPOCH 0 - PROGRESS: at 88.75% examples, 351998 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:22,992 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355957 effective words/s
2023-12-09 17:14:22,992 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355436 effective words/s', 'datetime': '2023-12-09T17:14:22.992943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:22,993 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:22.993118', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:28,813 - Processed run 6 for mu=0.35 on cuda:4. Elapsed time: 9.16 seconds
2023-12-09 17:14:29,867 - collecting all words and their counts
2023-12-09 17:14:29,867 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:29,926 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:29,926 - Creating a fresh vocabulary
2023-12-09 17:14:29,928 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:29.928724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:29,928 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:29.928803', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:29,931 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:29,931 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:29,931 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:29.931628', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:29,936 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:29,936 - resetting layer weights
2023-12-09 17:14:29,936 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:29.936752', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:29,937 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:29.937143', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:30,949 - EPOCH 0 - PROGRESS: at 41.25% examples, 327143 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:31,956 - EPOCH 0 - PROGRESS: at 90.00% examples, 357206 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:32,170 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358700 effective words/s
2023-12-09 17:14:32,170 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358156 effective words/s', 'datetime': '2023-12-09T17:14:32.170876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:32,171 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:32.171056', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:37,673 - Processed run 6 for mu=0.4 on cuda:1. Elapsed time: 8.86 seconds
2023-12-09 17:14:38,738 - collecting all words and their counts
2023-12-09 17:14:38,738 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:38,799 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:38,799 - Creating a fresh vocabulary
2023-12-09 17:14:38,801 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:38.801244', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:38,801 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:38.801315', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:38,804 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:38,804 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:38,804 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:38.804177', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:38,808 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:38,808 - resetting layer weights
2023-12-09 17:14:38,809 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:38.809300', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:38,809 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:38.809699', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:39,824 - EPOCH 0 - PROGRESS: at 41.25% examples, 326098 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:40,835 - EPOCH 0 - PROGRESS: at 86.25% examples, 341069 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:41,072 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353978 effective words/s
2023-12-09 17:14:41,073 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353445 effective words/s', 'datetime': '2023-12-09T17:14:41.073220', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:41,073 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:41.073402', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:46,989 - Processed run 6 for mu=0.45 on cuda:2. Elapsed time: 9.32 seconds
2023-12-09 17:14:48,131 - collecting all words and their counts
2023-12-09 17:14:48,132 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:48,192 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:48,192 - Creating a fresh vocabulary
2023-12-09 17:14:48,194 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:48.194618', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:48,194 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:48.194697', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:48,197 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:48,197 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:48,197 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:48.197662', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:48,202 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:48,202 - resetting layer weights
2023-12-09 17:14:48,202 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:48.202889', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:48,203 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:48.203330', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:49,216 - EPOCH 0 - PROGRESS: at 42.50% examples, 336607 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:50,227 - EPOCH 0 - PROGRESS: at 88.75% examples, 351277 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:14:50,456 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355540 effective words/s
2023-12-09 17:14:50,456 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354996 effective words/s', 'datetime': '2023-12-09T17:14:50.456953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:50,457 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:14:50.457129', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:14:57,417 - Processed run 6 for mu=0.5 on cuda:3. Elapsed time: 10.43 seconds
2023-12-09 17:14:58,663 - collecting all words and their counts
2023-12-09 17:14:58,663 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:14:58,723 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:14:58,723 - Creating a fresh vocabulary
2023-12-09 17:14:58,725 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:14:58.725414', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:58,725 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:14:58.725485', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:58,728 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:14:58,728 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:14:58,728 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:14:58.728330', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:14:58,733 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:14:58,733 - resetting layer weights
2023-12-09 17:14:58,733 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:14:58.733405', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:14:58,733 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:14:58.733756', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:14:59,759 - EPOCH 0 - PROGRESS: at 42.50% examples, 332452 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:00,762 - EPOCH 0 - PROGRESS: at 90.00% examples, 355477 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:00,976 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357194 effective words/s
2023-12-09 17:15:00,976 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356657 effective words/s', 'datetime': '2023-12-09T17:15:00.976879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:00,977 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:15:00.977060', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:15:07,290 - Processed run 6 for mu=0.55 on cuda:4. Elapsed time: 9.87 seconds
2023-12-09 17:15:08,633 - collecting all words and their counts
2023-12-09 17:15:08,633 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:15:08,694 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:15:08,695 - Creating a fresh vocabulary
2023-12-09 17:15:08,696 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:15:08.696925', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:08,697 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:15:08.696994', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:08,699 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:15:08,699 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:15:08,699 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:15:08.699797', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:08,704 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:15:08,704 - resetting layer weights
2023-12-09 17:15:08,704 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:15:08.704778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:15:08,705 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:15:08.705157', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:09,751 - EPOCH 0 - PROGRESS: at 46.25% examples, 354863 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:10,774 - EPOCH 0 - PROGRESS: at 96.25% examples, 372716 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:15:10,799 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382658 effective words/s
2023-12-09 17:15:10,799 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382040 effective words/s', 'datetime': '2023-12-09T17:15:10.799251', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:10,799 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:15:10.799433', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:15:17,674 - Processed run 6 for mu=0.6 on cuda:1. Elapsed time: 10.38 seconds
2023-12-09 17:15:19,108 - collecting all words and their counts
2023-12-09 17:15:19,108 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:15:19,168 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:15:19,168 - Creating a fresh vocabulary
2023-12-09 17:15:19,170 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:15:19.170717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:19,170 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:15:19.170798', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:19,173 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:15:19,173 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:15:19,173 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:15:19.173755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:19,178 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:15:19,178 - resetting layer weights
2023-12-09 17:15:19,178 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:15:19.178952', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:15:19,179 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:15:19.179426', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:20,227 - EPOCH 0 - PROGRESS: at 46.25% examples, 354279 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:21,248 - EPOCH 0 - PROGRESS: at 96.25% examples, 372787 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:15:21,272 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382732 effective words/s
2023-12-09 17:15:21,273 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382121 effective words/s', 'datetime': '2023-12-09T17:15:21.273078', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:21,273 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:15:21.273251', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:15:29,696 - Processed run 6 for mu=0.65 on cuda:2. Elapsed time: 12.02 seconds
2023-12-09 17:15:31,145 - collecting all words and their counts
2023-12-09 17:15:31,145 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:15:31,206 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:15:31,206 - Creating a fresh vocabulary
2023-12-09 17:15:31,208 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:15:31.208817', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:31,208 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:15:31.208894', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:31,211 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:15:31,211 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:15:31,211 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:15:31.211801', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:31,216 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:15:31,216 - resetting layer weights
2023-12-09 17:15:31,216 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:15:31.216896', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:15:31,217 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:15:31.217285', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:32,261 - EPOCH 0 - PROGRESS: at 46.25% examples, 355377 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:33,283 - EPOCH 0 - PROGRESS: at 96.25% examples, 373259 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:15:33,310 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382782 effective words/s
2023-12-09 17:15:33,310 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382157 effective words/s', 'datetime': '2023-12-09T17:15:33.310740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:33,310 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:15:33.310913', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:15:41,762 - Processed run 6 for mu=0.7 on cuda:3. Elapsed time: 12.07 seconds
2023-12-09 17:15:43,445 - collecting all words and their counts
2023-12-09 17:15:43,445 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:15:43,506 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:15:43,506 - Creating a fresh vocabulary
2023-12-09 17:15:43,508 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:15:43.508250', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:43,508 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:15:43.508321', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:43,511 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:15:43,511 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:15:43,511 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:15:43.511175', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:43,515 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:15:43,515 - resetting layer weights
2023-12-09 17:15:43,516 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:15:43.516176', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:15:43,516 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:15:43.516622', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:44,544 - EPOCH 0 - PROGRESS: at 41.25% examples, 321982 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:45,544 - EPOCH 0 - PROGRESS: at 87.50% examples, 345673 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:45,767 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355938 effective words/s
2023-12-09 17:15:45,767 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355402 effective words/s', 'datetime': '2023-12-09T17:15:45.767666', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:45,767 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:15:45.767841', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:15:55,928 - Processed run 6 for mu=0.75 on cuda:4. Elapsed time: 14.16 seconds
2023-12-09 17:15:57,809 - collecting all words and their counts
2023-12-09 17:15:57,809 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:15:57,870 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:15:57,870 - Creating a fresh vocabulary
2023-12-09 17:15:57,872 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:15:57.872275', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:57,872 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:15:57.872340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:57,875 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:15:57,875 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:15:57,875 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:15:57.875292', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:15:57,879 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:15:57,880 - resetting layer weights
2023-12-09 17:15:57,880 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:15:57.880340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:15:57,880 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:15:57.880769', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:15:58,896 - EPOCH 0 - PROGRESS: at 41.25% examples, 325991 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:15:59,910 - EPOCH 0 - PROGRESS: at 88.75% examples, 350278 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:16:00,141 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354439 effective words/s
2023-12-09 17:16:00,141 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353908 effective words/s', 'datetime': '2023-12-09T17:16:00.141313', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:00,141 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:16:00.141494', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:16:11,377 - Processed run 6 for mu=0.8 on cuda:1. Elapsed time: 15.45 seconds
2023-12-09 17:16:13,339 - collecting all words and their counts
2023-12-09 17:16:13,339 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:16:13,399 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:16:13,399 - Creating a fresh vocabulary
2023-12-09 17:16:13,401 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:16:13.401102', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:13,401 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:16:13.401177', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:13,404 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:16:13,404 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:16:13,404 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:16:13.404100', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:13,408 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:16:13,408 - resetting layer weights
2023-12-09 17:16:13,409 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:16:13.409174', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:16:13,409 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:16:13.409640', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:14,452 - EPOCH 0 - PROGRESS: at 46.25% examples, 355904 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:16:15,478 - EPOCH 0 - PROGRESS: at 96.25% examples, 372670 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:16:15,511 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381152 effective words/s
2023-12-09 17:16:15,511 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380565 effective words/s', 'datetime': '2023-12-09T17:16:15.511847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:15,512 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:16:15.512020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:16:26,315 - Processed run 6 for mu=0.85 on cuda:2. Elapsed time: 14.94 seconds
2023-12-09 17:16:28,454 - collecting all words and their counts
2023-12-09 17:16:28,455 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:16:28,515 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:16:28,515 - Creating a fresh vocabulary
2023-12-09 17:16:28,517 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:16:28.517029', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:28,517 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:16:28.517101', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:28,519 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:16:28,519 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:16:28,520 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:16:28.520000', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:28,524 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:16:28,524 - resetting layer weights
2023-12-09 17:16:28,525 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:16:28.525165', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:16:28,525 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:16:28.525516', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:29,536 - EPOCH 0 - PROGRESS: at 41.25% examples, 327384 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:16:30,538 - EPOCH 0 - PROGRESS: at 90.00% examples, 358279 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:16:30,749 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360271 effective words/s
2023-12-09 17:16:30,749 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359725 effective words/s', 'datetime': '2023-12-09T17:16:30.749527', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:30,749 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:16:30.749761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:16:41,614 - Processed run 6 for mu=0.9 on cuda:3. Elapsed time: 15.30 seconds
2023-12-09 17:16:43,995 - collecting all words and their counts
2023-12-09 17:16:43,995 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:16:44,055 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:16:44,055 - Creating a fresh vocabulary
2023-12-09 17:16:44,057 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:16:44.057524', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:44,057 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:16:44.057594', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:44,060 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:16:44,060 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:16:44,060 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:16:44.060448', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:16:44,065 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:16:44,065 - resetting layer weights
2023-12-09 17:16:44,065 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:16:44.065591', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:16:44,065 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:16:44.065980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:45,080 - EPOCH 0 - PROGRESS: at 41.25% examples, 326184 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:16:46,110 - EPOCH 0 - PROGRESS: at 87.50% examples, 342912 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:16:46,354 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350014 effective words/s
2023-12-09 17:16:46,355 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349500 effective words/s', 'datetime': '2023-12-09T17:16:46.355035', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:16:46,355 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:16:46.355222', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:00,319 - Processed run 6 for mu=0.95 on cuda:4. Elapsed time: 18.70 seconds
2023-12-09 17:17:02,779 - collecting all words and their counts
2023-12-09 17:17:02,780 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:02,849 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:02,849 - Creating a fresh vocabulary
2023-12-09 17:17:02,851 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:02.851554', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:02,851 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:02.851626', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:02,854 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:02,854 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:02,854 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:02.854514', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:02,859 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:02,859 - resetting layer weights
2023-12-09 17:17:02,859 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:02.859730', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:02,860 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:02.860222', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:03,898 - EPOCH 0 - PROGRESS: at 46.25% examples, 357511 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:04,922 - EPOCH 0 - PROGRESS: at 96.25% examples, 374029 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:04,961 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381288 effective words/s
2023-12-09 17:17:04,961 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380679 effective words/s', 'datetime': '2023-12-09T17:17:04.961804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:04,962 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:04.961978', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:16,521 - Processed run 6 for mu=1.0 on cuda:1. Elapsed time: 16.20 seconds
2023-12-09 17:17:17,427 - collecting all words and their counts
2023-12-09 17:17:17,427 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:17,486 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:17,486 - Creating a fresh vocabulary
2023-12-09 17:17:17,488 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:17.488578', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:17,488 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:17.488647', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:17,491 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:17,491 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:17,491 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:17.491547', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:17,496 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:17,496 - resetting layer weights
2023-12-09 17:17:17,496 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:17.496631', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:17,497 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:17.497073', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:18,515 - EPOCH 0 - PROGRESS: at 56.25% examples, 443367 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:19,089 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 503381 effective words/s
2023-12-09 17:17:19,089 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 502295 effective words/s', 'datetime': '2023-12-09T17:17:19.089833', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:19,090 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:19.090497', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:23,159 - Processed run 7 for mu=0.0 on cuda:1. Elapsed time: 6.64 seconds
2023-12-09 17:17:24,048 - collecting all words and their counts
2023-12-09 17:17:24,048 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:24,108 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:24,108 - Creating a fresh vocabulary
2023-12-09 17:17:24,110 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:24.110291', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:24,110 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:24.110361', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:24,113 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:24,113 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:24,113 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:24.113227', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:24,118 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:24,118 - resetting layer weights
2023-12-09 17:17:24,118 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:24.118427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:24,118 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:24.118909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:25,161 - EPOCH 0 - PROGRESS: at 46.25% examples, 355882 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:26,190 - EPOCH 0 - PROGRESS: at 96.25% examples, 372249 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:26,203 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384348 effective words/s
2023-12-09 17:17:26,203 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383736 effective words/s', 'datetime': '2023-12-09T17:17:26.203749', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:26,203 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:26.203923', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:30,564 - Processed run 7 for mu=0.05 on cuda:2. Elapsed time: 7.40 seconds
2023-12-09 17:17:31,324 - collecting all words and their counts
2023-12-09 17:17:31,325 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:31,385 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:31,385 - Creating a fresh vocabulary
2023-12-09 17:17:31,387 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:31.387848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:31,387 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:31.387914', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:31,390 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:31,390 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:31,390 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:31.390885', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:31,395 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:31,395 - resetting layer weights
2023-12-09 17:17:31,396 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:31.396091', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:31,396 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:31.396539', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:32,446 - EPOCH 0 - PROGRESS: at 46.25% examples, 353292 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:33,482 - EPOCH 0 - PROGRESS: at 96.25% examples, 369687 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:33,504 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380113 effective words/s
2023-12-09 17:17:33,504 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379536 effective words/s', 'datetime': '2023-12-09T17:17:33.504456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:33,504 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:33.504657', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:38,064 - Processed run 7 for mu=0.1 on cuda:3. Elapsed time: 7.50 seconds
2023-12-09 17:17:38,985 - collecting all words and their counts
2023-12-09 17:17:38,985 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:39,045 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:39,045 - Creating a fresh vocabulary
2023-12-09 17:17:39,047 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:39.047863', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:39,047 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:39.047934', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:39,050 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:39,050 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:39,050 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:39.050847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:39,055 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:39,055 - resetting layer weights
2023-12-09 17:17:39,055 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:39.055896', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:39,056 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:39.056376', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:40,101 - EPOCH 0 - PROGRESS: at 46.25% examples, 355068 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:41,133 - EPOCH 0 - PROGRESS: at 96.25% examples, 371326 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:41,160 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380765 effective words/s
2023-12-09 17:17:41,160 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380164 effective words/s', 'datetime': '2023-12-09T17:17:41.160811', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:41,161 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:41.160981', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:45,730 - Processed run 7 for mu=0.15 on cuda:4. Elapsed time: 7.66 seconds
2023-12-09 17:17:46,664 - collecting all words and their counts
2023-12-09 17:17:46,664 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:46,724 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:46,724 - Creating a fresh vocabulary
2023-12-09 17:17:46,726 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:46.726572', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:46,726 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:46.726642', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:46,729 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:46,729 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:46,729 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:46.729480', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:46,734 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:46,734 - resetting layer weights
2023-12-09 17:17:46,734 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:46.734597', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:46,735 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:46.735027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:47,781 - EPOCH 0 - PROGRESS: at 46.25% examples, 354502 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:48,808 - EPOCH 0 - PROGRESS: at 96.25% examples, 372017 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:48,821 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384095 effective words/s
2023-12-09 17:17:48,821 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383481 effective words/s', 'datetime': '2023-12-09T17:17:48.821251', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:48,821 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:48.821433', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:17:53,936 - Processed run 7 for mu=0.2 on cuda:1. Elapsed time: 8.21 seconds
2023-12-09 17:17:54,821 - collecting all words and their counts
2023-12-09 17:17:54,821 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:17:54,882 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:17:54,882 - Creating a fresh vocabulary
2023-12-09 17:17:54,884 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:17:54.884728', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:54,884 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:17:54.884797', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:54,887 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:17:54,887 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:17:54,887 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:17:54.887659', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:17:54,892 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:17:54,892 - resetting layer weights
2023-12-09 17:17:54,892 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:17:54.892676', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:17:54,893 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:17:54.893172', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:55,942 - EPOCH 0 - PROGRESS: at 46.25% examples, 353669 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:17:56,967 - EPOCH 0 - PROGRESS: at 96.25% examples, 371870 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:17:57,004 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 379486 effective words/s
2023-12-09 17:17:57,004 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378879 effective words/s', 'datetime': '2023-12-09T17:17:57.004740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:17:57,004 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:17:57.004912', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:02,132 - Processed run 7 for mu=0.25 on cuda:2. Elapsed time: 8.20 seconds
2023-12-09 17:18:02,979 - collecting all words and their counts
2023-12-09 17:18:02,979 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:03,038 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:03,039 - Creating a fresh vocabulary
2023-12-09 17:18:03,040 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:03.040967', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:03,041 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:03.041047', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:03,043 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:03,043 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:03,043 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:03.043918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:03,048 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:03,048 - resetting layer weights
2023-12-09 17:18:03,049 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:03.048992', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:03,049 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:03.049313', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:04,092 - EPOCH 0 - PROGRESS: at 46.25% examples, 355882 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:18:05,115 - EPOCH 0 - PROGRESS: at 96.25% examples, 373191 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:18:05,148 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381707 effective words/s
2023-12-09 17:18:05,148 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381061 effective words/s', 'datetime': '2023-12-09T17:18:05.148790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:05,148 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:05.148965', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:10,555 - Processed run 7 for mu=0.3 on cuda:3. Elapsed time: 8.42 seconds
2023-12-09 17:18:11,526 - collecting all words and their counts
2023-12-09 17:18:11,526 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:11,586 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:11,586 - Creating a fresh vocabulary
2023-12-09 17:18:11,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:11.588823', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:11,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:11.588900', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:11,591 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:11,591 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:11,591 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:11.591818', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:11,596 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:11,596 - resetting layer weights
2023-12-09 17:18:11,596 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:11.596876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:11,597 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:11.597382', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:12,603 - EPOCH 0 - PROGRESS: at 41.25% examples, 328975 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:18:13,605 - EPOCH 0 - PROGRESS: at 87.50% examples, 349158 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:18:13,825 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359471 effective words/s
2023-12-09 17:18:13,826 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358941 effective words/s', 'datetime': '2023-12-09T17:18:13.826231', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:13,826 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:13.826406', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:18,817 - Processed run 7 for mu=0.35 on cuda:4. Elapsed time: 8.26 seconds
2023-12-09 17:18:19,862 - collecting all words and their counts
2023-12-09 17:18:19,862 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:19,923 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:19,923 - Creating a fresh vocabulary
2023-12-09 17:18:19,925 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:19.925334', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:19,925 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:19.925411', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:19,928 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:19,928 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:19,928 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:19.928270', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:19,932 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:19,933 - resetting layer weights
2023-12-09 17:18:19,933 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:19.933368', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:19,933 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:19.933724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:20,974 - EPOCH 0 - PROGRESS: at 46.25% examples, 356503 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:18:22,002 - EPOCH 0 - PROGRESS: at 96.25% examples, 372829 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:18:22,042 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380013 effective words/s
2023-12-09 17:18:22,042 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379412 effective words/s', 'datetime': '2023-12-09T17:18:22.042322', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:22,042 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:22.042498', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:27,842 - Processed run 7 for mu=0.4 on cuda:1. Elapsed time: 9.02 seconds
2023-12-09 17:18:28,914 - collecting all words and their counts
2023-12-09 17:18:28,914 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:28,975 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:28,975 - Creating a fresh vocabulary
2023-12-09 17:18:28,977 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:28.977316', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:28,977 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:28.977387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:28,980 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:28,980 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:28,980 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:28.980375', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:28,985 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:28,985 - resetting layer weights
2023-12-09 17:18:28,985 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:28.985530', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:28,986 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:28.986176', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:30,025 - EPOCH 0 - PROGRESS: at 46.25% examples, 357171 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:18:31,060 - EPOCH 0 - PROGRESS: at 96.25% examples, 371698 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:18:31,075 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383561 effective words/s
2023-12-09 17:18:31,075 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382944 effective words/s', 'datetime': '2023-12-09T17:18:31.075322', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:31,075 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:31.075491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:37,105 - Processed run 7 for mu=0.45 on cuda:2. Elapsed time: 9.26 seconds
2023-12-09 17:18:38,287 - collecting all words and their counts
2023-12-09 17:18:38,287 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:38,348 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:38,348 - Creating a fresh vocabulary
2023-12-09 17:18:38,350 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:38.350164', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:38,350 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:38.350229', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:38,353 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:38,353 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:38,353 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:38.353111', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:38,357 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:38,357 - resetting layer weights
2023-12-09 17:18:38,358 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:38.358215', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:38,358 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:38.358654', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:39,409 - EPOCH 0 - PROGRESS: at 46.25% examples, 353220 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:18:40,431 - EPOCH 0 - PROGRESS: at 96.25% examples, 372065 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:18:40,447 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383591 effective words/s
2023-12-09 17:18:40,447 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382966 effective words/s', 'datetime': '2023-12-09T17:18:40.447686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:40,447 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:40.447857', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:46,923 - Processed run 7 for mu=0.5 on cuda:3. Elapsed time: 9.82 seconds
2023-12-09 17:18:48,233 - collecting all words and their counts
2023-12-09 17:18:48,233 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:48,294 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:48,294 - Creating a fresh vocabulary
2023-12-09 17:18:48,296 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:48.296858', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:48,296 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:48.296955', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:48,299 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:48,299 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:48,299 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:48.299866', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:48,304 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:48,304 - resetting layer weights
2023-12-09 17:18:48,305 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:48.305266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:48,305 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:48.305691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:49,350 - EPOCH 0 - PROGRESS: at 46.25% examples, 355101 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:18:50,377 - EPOCH 0 - PROGRESS: at 96.25% examples, 372247 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:18:50,392 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383903 effective words/s
2023-12-09 17:18:50,393 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383284 effective words/s', 'datetime': '2023-12-09T17:18:50.392988', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:50,393 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:18:50.393166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:18:56,882 - Processed run 7 for mu=0.55 on cuda:4. Elapsed time: 9.96 seconds
2023-12-09 17:18:58,316 - collecting all words and their counts
2023-12-09 17:18:58,316 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:18:58,377 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:18:58,377 - Creating a fresh vocabulary
2023-12-09 17:18:58,379 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:18:58.379492', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:58,379 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:18:58.379559', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:58,382 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:18:58,382 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:18:58,382 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:18:58.382456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:18:58,387 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:18:58,387 - resetting layer weights
2023-12-09 17:18:58,387 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:18:58.387541', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:18:58,388 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:18:58.388012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:18:59,435 - EPOCH 0 - PROGRESS: at 46.25% examples, 354292 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:00,466 - EPOCH 0 - PROGRESS: at 96.25% examples, 371032 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:19:00,473 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384201 effective words/s
2023-12-09 17:19:00,473 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383581 effective words/s', 'datetime': '2023-12-09T17:19:00.473687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:00,473 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:19:00.473854', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:19:07,261 - Processed run 7 for mu=0.6 on cuda:1. Elapsed time: 10.38 seconds
2023-12-09 17:19:08,659 - collecting all words and their counts
2023-12-09 17:19:08,659 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:19:08,720 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:19:08,720 - Creating a fresh vocabulary
2023-12-09 17:19:08,722 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:19:08.722410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:08,722 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:19:08.722489', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:08,725 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:19:08,725 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:19:08,725 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:19:08.725437', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:08,730 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:19:08,730 - resetting layer weights
2023-12-09 17:19:08,730 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:19:08.730611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:19:08,731 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:19:08.731049', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:09,744 - EPOCH 0 - PROGRESS: at 42.50% examples, 336457 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:10,787 - EPOCH 0 - PROGRESS: at 90.00% examples, 350605 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:10,997 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353510 effective words/s
2023-12-09 17:19:10,997 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352966 effective words/s', 'datetime': '2023-12-09T17:19:10.997636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:10,997 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:19:10.997821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:19:19,077 - Processed run 7 for mu=0.65 on cuda:2. Elapsed time: 11.81 seconds
2023-12-09 17:19:20,727 - collecting all words and their counts
2023-12-09 17:19:20,727 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:19:20,789 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:19:20,789 - Creating a fresh vocabulary
2023-12-09 17:19:20,791 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:19:20.791378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:20,791 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:19:20.791449', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:20,794 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:19:20,794 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:19:20,794 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:19:20.794292', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:20,799 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:19:20,799 - resetting layer weights
2023-12-09 17:19:20,799 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:19:20.799496', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:19:20,799 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:19:20.799970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:21,815 - EPOCH 0 - PROGRESS: at 42.50% examples, 335893 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:22,820 - EPOCH 0 - PROGRESS: at 88.75% examples, 351939 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:23,047 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356461 effective words/s
2023-12-09 17:19:23,047 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355922 effective words/s', 'datetime': '2023-12-09T17:19:23.047724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:23,047 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:19:23.047897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:19:42,383 - Processed run 7 for mu=0.7 on cuda:3. Elapsed time: 23.30 seconds
2023-12-09 17:19:44,030 - collecting all words and their counts
2023-12-09 17:19:44,031 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:19:44,091 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:19:44,091 - Creating a fresh vocabulary
2023-12-09 17:19:44,093 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:19:44.093662', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:44,093 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:19:44.093742', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:44,096 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:19:44,096 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:19:44,096 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:19:44.096646', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:44,101 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:19:44,101 - resetting layer weights
2023-12-09 17:19:44,101 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:19:44.101731', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:19:44,102 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:19:44.102162', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:45,126 - EPOCH 0 - PROGRESS: at 41.25% examples, 323225 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:19:46,134 - EPOCH 0 - PROGRESS: at 86.25% examples, 340128 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:19:46,390 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350094 effective words/s
2023-12-09 17:19:46,390 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349571 effective words/s', 'datetime': '2023-12-09T17:19:46.390742', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:46,390 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:19:46.390879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:19:56,924 - Processed run 7 for mu=0.75 on cuda:4. Elapsed time: 14.54 seconds
2023-12-09 17:19:58,744 - collecting all words and their counts
2023-12-09 17:19:58,744 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:19:58,805 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:19:58,805 - Creating a fresh vocabulary
2023-12-09 17:19:58,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:19:58.807761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:58,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:19:58.807830', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:58,810 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:19:58,810 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:19:58,810 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:19:58.810721', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:19:58,815 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:19:58,815 - resetting layer weights
2023-12-09 17:19:58,815 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:19:58.815808', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:19:58,816 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:19:58.816295', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:19:59,868 - EPOCH 0 - PROGRESS: at 46.25% examples, 352613 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:20:00,896 - EPOCH 0 - PROGRESS: at 96.25% examples, 370798 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:20:00,915 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381653 effective words/s
2023-12-09 17:20:00,915 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381042 effective words/s', 'datetime': '2023-12-09T17:20:00.915871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:00,916 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:20:00.916038', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:20:12,132 - Processed run 7 for mu=0.8 on cuda:1. Elapsed time: 15.21 seconds
2023-12-09 17:20:14,013 - collecting all words and their counts
2023-12-09 17:20:14,013 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:20:14,074 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:20:14,074 - Creating a fresh vocabulary
2023-12-09 17:20:14,076 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:20:14.076270', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:14,076 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:20:14.076337', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:14,079 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:20:14,079 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:20:14,079 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:20:14.079176', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:14,083 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:20:14,083 - resetting layer weights
2023-12-09 17:20:14,084 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:20:14.084209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:20:14,084 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:20:14.084631', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:15,125 - EPOCH 0 - PROGRESS: at 46.25% examples, 356546 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:20:16,146 - EPOCH 0 - PROGRESS: at 96.25% examples, 374016 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:20:16,177 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382749 effective words/s
2023-12-09 17:20:16,178 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382143 effective words/s', 'datetime': '2023-12-09T17:20:16.178163', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:16,178 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:20:16.178330', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:20:27,038 - Processed run 7 for mu=0.85 on cuda:2. Elapsed time: 14.90 seconds
2023-12-09 17:20:29,041 - collecting all words and their counts
2023-12-09 17:20:29,041 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:20:29,103 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:20:29,103 - Creating a fresh vocabulary
2023-12-09 17:20:29,105 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:20:29.105034', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:29,105 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:20:29.105104', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:29,107 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:20:29,107 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:20:29,107 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:20:29.107926', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:29,112 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:20:29,112 - resetting layer weights
2023-12-09 17:20:29,113 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:20:29.112991', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:20:29,113 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:20:29.113449', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:30,166 - EPOCH 0 - PROGRESS: at 46.25% examples, 352340 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:20:31,201 - EPOCH 0 - PROGRESS: at 96.25% examples, 369318 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:20:31,208 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382461 effective words/s
2023-12-09 17:20:31,208 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381840 effective words/s', 'datetime': '2023-12-09T17:20:31.208638', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:31,208 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:20:31.208817', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:20:42,942 - Processed run 7 for mu=0.9 on cuda:3. Elapsed time: 15.90 seconds
2023-12-09 17:20:45,129 - collecting all words and their counts
2023-12-09 17:20:45,129 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:20:45,190 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:20:45,190 - Creating a fresh vocabulary
2023-12-09 17:20:45,192 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:20:45.192398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:45,192 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:20:45.192466', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:45,195 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:20:45,195 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:20:45,195 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:20:45.195301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:20:45,199 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:20:45,200 - resetting layer weights
2023-12-09 17:20:45,200 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:20:45.200365', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:20:45,200 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:20:45.200829', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:46,212 - EPOCH 0 - PROGRESS: at 41.25% examples, 327353 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:20:47,220 - EPOCH 0 - PROGRESS: at 90.00% examples, 357023 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:20:47,436 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358413 effective words/s
2023-12-09 17:20:47,436 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357872 effective words/s', 'datetime': '2023-12-09T17:20:47.436336', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:20:47,436 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:20:47.436512', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:20:59,928 - Processed run 7 for mu=0.95 on cuda:4. Elapsed time: 16.98 seconds
2023-12-09 17:21:02,604 - collecting all words and their counts
2023-12-09 17:21:02,604 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:02,665 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:02,665 - Creating a fresh vocabulary
2023-12-09 17:21:02,667 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:02.667802', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:02,667 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:02.667874', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:02,670 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:02,670 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:02,670 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:02.670742', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:02,675 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:02,675 - resetting layer weights
2023-12-09 17:21:02,675 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:02.675793', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:02,676 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:02.676232', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:03,697 - EPOCH 0 - PROGRESS: at 42.50% examples, 333821 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:21:04,706 - EPOCH 0 - PROGRESS: at 90.00% examples, 355131 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:04,919 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357145 effective words/s
2023-12-09 17:21:04,919 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356626 effective words/s', 'datetime': '2023-12-09T17:21:04.919547', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:04,919 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:04.919717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:17,262 - Processed run 7 for mu=1.0 on cuda:1. Elapsed time: 17.33 seconds
2023-12-09 17:21:18,388 - collecting all words and their counts
2023-12-09 17:21:18,388 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:18,448 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:18,448 - Creating a fresh vocabulary
2023-12-09 17:21:18,450 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:18.450868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:18,450 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:18.450936', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:18,453 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:18,453 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:18,453 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:18.453842', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:18,458 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:18,458 - resetting layer weights
2023-12-09 17:21:18,459 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:18.459048', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:18,459 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:18.459500', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:19,484 - EPOCH 0 - PROGRESS: at 56.25% examples, 440405 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:20,051 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 503600 effective words/s
2023-12-09 17:21:20,051 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 502543 effective words/s', 'datetime': '2023-12-09T17:21:20.051486', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:20,051 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:20.051728', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:24,155 - Processed run 8 for mu=0.0 on cuda:1. Elapsed time: 6.89 seconds
2023-12-09 17:21:25,024 - collecting all words and their counts
2023-12-09 17:21:25,024 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:25,085 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:25,085 - Creating a fresh vocabulary
2023-12-09 17:21:25,087 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:25.087359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:25,087 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:25.087450', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:25,090 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:25,090 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:25,090 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:25.090540', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:25,095 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:25,095 - resetting layer weights
2023-12-09 17:21:25,095 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:25.095856', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:25,096 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:25.096087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:26,119 - EPOCH 0 - PROGRESS: at 41.25% examples, 323342 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:27,128 - EPOCH 0 - PROGRESS: at 86.25% examples, 339973 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:21:27,362 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353527 effective words/s
2023-12-09 17:21:27,362 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353005 effective words/s', 'datetime': '2023-12-09T17:21:27.362440', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:27,362 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:27.362675', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:31,750 - Processed run 8 for mu=0.05 on cuda:2. Elapsed time: 7.59 seconds
2023-12-09 17:21:32,728 - collecting all words and their counts
2023-12-09 17:21:32,728 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:32,789 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:32,789 - Creating a fresh vocabulary
2023-12-09 17:21:32,791 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:32.791915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:32,792 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:32.792010', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:32,795 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:32,795 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:32,795 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:32.795339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:32,800 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:32,800 - resetting layer weights
2023-12-09 17:21:32,801 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:32.801255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:32,801 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:32.801372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:33,847 - EPOCH 0 - PROGRESS: at 46.25% examples, 354821 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:34,872 - EPOCH 0 - PROGRESS: at 96.25% examples, 372396 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:21:34,878 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385659 effective words/s
2023-12-09 17:21:34,879 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385037 effective words/s', 'datetime': '2023-12-09T17:21:34.879194', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:34,879 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:34.879421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:39,601 - Processed run 8 for mu=0.1 on cuda:3. Elapsed time: 7.85 seconds
2023-12-09 17:21:40,525 - collecting all words and their counts
2023-12-09 17:21:40,525 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:40,586 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:40,586 - Creating a fresh vocabulary
2023-12-09 17:21:40,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:40.588261', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:40,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:40.588337', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:40,591 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:40,591 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:40,591 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:40.591219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:40,595 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:40,595 - resetting layer weights
2023-12-09 17:21:40,596 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:40.596284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:40,596 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:40.596801', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:41,650 - EPOCH 0 - PROGRESS: at 46.25% examples, 352205 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:42,680 - EPOCH 0 - PROGRESS: at 96.25% examples, 370162 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:21:42,712 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 378691 effective words/s
2023-12-09 17:21:42,712 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378098 effective words/s', 'datetime': '2023-12-09T17:21:42.712725', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:42,712 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:42.712895', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:48,112 - Processed run 8 for mu=0.15 on cuda:4. Elapsed time: 8.51 seconds
2023-12-09 17:21:48,957 - collecting all words and their counts
2023-12-09 17:21:48,957 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:49,018 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:49,018 - Creating a fresh vocabulary
2023-12-09 17:21:49,020 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:49.020226', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:49,020 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:49.020290', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:49,023 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:49,023 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:49,023 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:49.023144', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:49,027 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:49,027 - resetting layer weights
2023-12-09 17:21:49,028 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:49.028142', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:49,028 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:49.028544', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:50,074 - EPOCH 0 - PROGRESS: at 46.25% examples, 354767 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:51,102 - EPOCH 0 - PROGRESS: at 96.25% examples, 371915 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:21:51,121 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382759 effective words/s
2023-12-09 17:21:51,122 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382140 effective words/s', 'datetime': '2023-12-09T17:21:51.122098', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:51,122 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:51.122268', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:21:56,231 - Processed run 8 for mu=0.2 on cuda:1. Elapsed time: 8.12 seconds
2023-12-09 17:21:57,070 - collecting all words and their counts
2023-12-09 17:21:57,071 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:21:57,132 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:21:57,132 - Creating a fresh vocabulary
2023-12-09 17:21:57,134 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:21:57.134017', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:57,134 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:21:57.134085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:57,136 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:21:57,136 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:21:57,136 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:21:57.136920', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:21:57,141 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:21:57,141 - resetting layer weights
2023-12-09 17:21:57,142 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:21:57.142005', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:21:57,142 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:21:57.142448', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:58,183 - EPOCH 0 - PROGRESS: at 46.25% examples, 356525 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:21:59,208 - EPOCH 0 - PROGRESS: at 96.25% examples, 373226 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:21:59,230 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383730 effective words/s
2023-12-09 17:21:59,230 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383110 effective words/s', 'datetime': '2023-12-09T17:21:59.230694', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:21:59,230 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:21:59.230858', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:04,331 - Processed run 8 for mu=0.25 on cuda:2. Elapsed time: 8.10 seconds
2023-12-09 17:22:05,252 - collecting all words and their counts
2023-12-09 17:22:05,252 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:05,312 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:05,312 - Creating a fresh vocabulary
2023-12-09 17:22:05,314 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:05.314805', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:05,314 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:05.314878', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:05,317 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:05,317 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:05,317 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:05.317777', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:05,322 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:05,322 - resetting layer weights
2023-12-09 17:22:05,322 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:05.322845', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:05,323 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:05.323290', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:06,365 - EPOCH 0 - PROGRESS: at 46.25% examples, 356150 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:07,386 - EPOCH 0 - PROGRESS: at 96.25% examples, 373846 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:22:07,420 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382016 effective words/s
2023-12-09 17:22:07,420 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381403 effective words/s', 'datetime': '2023-12-09T17:22:07.420878', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:07,421 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:07.421044', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:12,930 - Processed run 8 for mu=0.3 on cuda:3. Elapsed time: 8.60 seconds
2023-12-09 17:22:13,983 - collecting all words and their counts
2023-12-09 17:22:13,983 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:14,044 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:14,044 - Creating a fresh vocabulary
2023-12-09 17:22:14,046 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:14.046549', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:14,046 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:14.046613', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:14,049 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:14,049 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:14,049 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:14.049660', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:14,054 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:14,054 - resetting layer weights
2023-12-09 17:22:14,054 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:14.054792', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:14,055 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:14.055232', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:15,077 - EPOCH 0 - PROGRESS: at 41.25% examples, 323717 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:16,077 - EPOCH 0 - PROGRESS: at 88.75% examples, 351570 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:16,312 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354867 effective words/s
2023-12-09 17:22:16,313 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354344 effective words/s', 'datetime': '2023-12-09T17:22:16.312981', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:16,313 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:16.313050', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:22,683 - Processed run 8 for mu=0.35 on cuda:4. Elapsed time: 9.75 seconds
2023-12-09 17:22:23,650 - collecting all words and their counts
2023-12-09 17:22:23,650 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:23,711 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:23,711 - Creating a fresh vocabulary
2023-12-09 17:22:23,713 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:23.713507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:23,713 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:23.713577', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:23,716 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:23,716 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:23,716 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:23.716490', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:23,721 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:23,721 - resetting layer weights
2023-12-09 17:22:23,721 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:23.721580', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:23,721 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:23.721963', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:24,758 - EPOCH 0 - PROGRESS: at 46.25% examples, 358012 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:25,773 - EPOCH 0 - PROGRESS: at 96.25% examples, 375857 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:22:25,811 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383518 effective words/s
2023-12-09 17:22:25,811 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382900 effective words/s', 'datetime': '2023-12-09T17:22:25.811351', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:25,811 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:25.811520', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:32,046 - Processed run 8 for mu=0.4 on cuda:1. Elapsed time: 9.36 seconds
2023-12-09 17:22:33,169 - collecting all words and their counts
2023-12-09 17:22:33,169 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:33,230 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:33,230 - Creating a fresh vocabulary
2023-12-09 17:22:33,232 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:33.232072', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:33,232 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:33.232138', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:33,234 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:33,234 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:33,234 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:33.234985', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:33,239 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:33,239 - resetting layer weights
2023-12-09 17:22:33,240 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:33.240045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:33,240 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:33.240551', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:34,279 - EPOCH 0 - PROGRESS: at 46.25% examples, 357069 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:35,303 - EPOCH 0 - PROGRESS: at 96.25% examples, 373863 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:22:35,325 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384241 effective words/s
2023-12-09 17:22:35,326 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383626 effective words/s', 'datetime': '2023-12-09T17:22:35.325994', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:35,326 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:35.326162', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:42,109 - Processed run 8 for mu=0.45 on cuda:2. Elapsed time: 10.06 seconds
2023-12-09 17:22:43,354 - collecting all words and their counts
2023-12-09 17:22:43,354 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:43,416 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:43,416 - Creating a fresh vocabulary
2023-12-09 17:22:43,418 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:43.418528', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:43,418 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:43.418593', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:43,421 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:43,421 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:43,421 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:43.421445', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:43,426 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:43,426 - resetting layer weights
2023-12-09 17:22:43,426 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:43.426531', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:43,426 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:43.426966', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:44,476 - EPOCH 0 - PROGRESS: at 46.25% examples, 353778 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:22:45,502 - EPOCH 0 - PROGRESS: at 96.25% examples, 371472 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:22:45,522 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382381 effective words/s
2023-12-09 17:22:45,522 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381774 effective words/s', 'datetime': '2023-12-09T17:22:45.522517', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:45,522 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:45.522686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:22:52,148 - Processed run 8 for mu=0.5 on cuda:3. Elapsed time: 10.04 seconds
2023-12-09 17:22:53,398 - collecting all words and their counts
2023-12-09 17:22:53,398 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:22:53,460 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:22:53,460 - Creating a fresh vocabulary
2023-12-09 17:22:53,462 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:22:53.462837', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:53,462 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:22:53.462930', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:53,465 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:22:53,465 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:22:53,465 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:22:53.465877', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:22:53,470 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:22:53,470 - resetting layer weights
2023-12-09 17:22:53,470 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:22:53.470926', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:22:53,471 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:22:53.471465', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:54,513 - EPOCH 0 - PROGRESS: at 46.25% examples, 356249 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:22:55,536 - EPOCH 0 - PROGRESS: at 96.25% examples, 373557 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:22:55,587 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 378591 effective words/s
2023-12-09 17:22:55,588 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 377980 effective words/s', 'datetime': '2023-12-09T17:22:55.588050', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:22:55,588 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:22:55.588217', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:23:01,716 - Processed run 8 for mu=0.55 on cuda:4. Elapsed time: 9.57 seconds
2023-12-09 17:23:03,075 - collecting all words and their counts
2023-12-09 17:23:03,075 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:23:03,137 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:23:03,137 - Creating a fresh vocabulary
2023-12-09 17:23:03,139 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:23:03.139234', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:03,139 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:23:03.139317', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:03,142 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:23:03,142 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:23:03,142 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:23:03.142206', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:03,146 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:23:03,146 - resetting layer weights
2023-12-09 17:23:03,147 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:23:03.147331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:23:03,147 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:23:03.147740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:04,188 - EPOCH 0 - PROGRESS: at 46.25% examples, 356763 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:05,204 - EPOCH 0 - PROGRESS: at 96.25% examples, 375039 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:23:05,241 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382715 effective words/s
2023-12-09 17:23:05,241 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382095 effective words/s', 'datetime': '2023-12-09T17:23:05.241539', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:05,241 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:23:05.241709', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:23:12,667 - Processed run 8 for mu=0.6 on cuda:1. Elapsed time: 10.95 seconds
2023-12-09 17:23:14,126 - collecting all words and their counts
2023-12-09 17:23:14,126 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:23:14,188 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:23:14,188 - Creating a fresh vocabulary
2023-12-09 17:23:14,190 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:23:14.190364', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:14,190 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:23:14.190450', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:14,193 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:23:14,193 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:23:14,193 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:23:14.193340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:14,198 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:23:14,198 - resetting layer weights
2023-12-09 17:23:14,198 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:23:14.198509', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:23:14,198 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:23:14.198904', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:15,242 - EPOCH 0 - PROGRESS: at 46.25% examples, 355755 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:16,267 - EPOCH 0 - PROGRESS: at 96.25% examples, 372859 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:23:16,293 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382599 effective words/s
2023-12-09 17:23:16,293 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381964 effective words/s', 'datetime': '2023-12-09T17:23:16.293415', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:16,293 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:23:16.293584', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:23:25,488 - Processed run 8 for mu=0.65 on cuda:2. Elapsed time: 12.82 seconds
2023-12-09 17:23:27,148 - collecting all words and their counts
2023-12-09 17:23:27,148 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:23:27,209 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:23:27,209 - Creating a fresh vocabulary
2023-12-09 17:23:27,212 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:23:27.212321', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:27,212 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:23:27.212406', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:27,215 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:23:27,215 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:23:27,216 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:23:27.215992', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:27,221 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:23:27,221 - resetting layer weights
2023-12-09 17:23:27,221 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:23:27.221745', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:23:27,221 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:23:27.221979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:28,266 - EPOCH 0 - PROGRESS: at 46.25% examples, 355338 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:29,294 - EPOCH 0 - PROGRESS: at 96.25% examples, 372192 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:23:29,299 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385636 effective words/s
2023-12-09 17:23:29,299 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385014 effective words/s', 'datetime': '2023-12-09T17:23:29.299923', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:29,300 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:23:29.300151', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:23:37,971 - Processed run 8 for mu=0.7 on cuda:3. Elapsed time: 12.48 seconds
2023-12-09 17:23:39,613 - collecting all words and their counts
2023-12-09 17:23:39,613 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:23:39,675 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:23:39,675 - Creating a fresh vocabulary
2023-12-09 17:23:39,677 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:23:39.677875', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:39,677 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:23:39.677940', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:39,680 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:23:39,680 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:23:39,680 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:23:39.680843', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:39,685 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:23:39,685 - resetting layer weights
2023-12-09 17:23:39,685 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:23:39.685919', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:23:39,686 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:23:39.686410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:40,736 - EPOCH 0 - PROGRESS: at 46.25% examples, 353399 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:41,765 - EPOCH 0 - PROGRESS: at 96.25% examples, 370976 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:23:41,783 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382159 effective words/s
2023-12-09 17:23:41,783 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381539 effective words/s', 'datetime': '2023-12-09T17:23:41.783258', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:41,783 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:23:41.783482', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:23:51,366 - Processed run 8 for mu=0.75 on cuda:4. Elapsed time: 13.39 seconds
2023-12-09 17:23:53,305 - collecting all words and their counts
2023-12-09 17:23:53,305 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:23:53,366 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:23:53,366 - Creating a fresh vocabulary
2023-12-09 17:23:53,368 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:23:53.368204', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:53,368 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:23:53.368271', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:53,371 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:23:53,371 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:23:53,371 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:23:53.371135', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:23:53,375 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:23:53,375 - resetting layer weights
2023-12-09 17:23:53,376 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:23:53.376118', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:23:53,376 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:23:53.376641', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:54,399 - EPOCH 0 - PROGRESS: at 41.25% examples, 323577 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:55,401 - EPOCH 0 - PROGRESS: at 87.50% examples, 346184 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:23:55,667 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349752 effective words/s
2023-12-09 17:23:55,667 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349237 effective words/s', 'datetime': '2023-12-09T17:23:55.667428', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:23:55,667 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:23:55.667616', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:24:06,401 - Processed run 8 for mu=0.8 on cuda:1. Elapsed time: 15.03 seconds
2023-12-09 17:24:08,278 - collecting all words and their counts
2023-12-09 17:24:08,279 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:24:08,339 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:24:08,340 - Creating a fresh vocabulary
2023-12-09 17:24:08,341 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:24:08.341924', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:08,341 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:24:08.341988', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:08,344 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:24:08,344 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:24:08,344 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:24:08.344904', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:08,349 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:24:08,349 - resetting layer weights
2023-12-09 17:24:08,350 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:24:08.350120', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:24:08,350 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:24:08.350392', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:09,389 - EPOCH 0 - PROGRESS: at 46.25% examples, 357351 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:24:10,390 - EPOCH 0 - PROGRESS: at 95.00% examples, 373166 words/s, in_qsize 4, out_qsize 0
2023-12-09 17:24:10,480 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 376094 effective words/s
2023-12-09 17:24:10,480 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 375502 effective words/s', 'datetime': '2023-12-09T17:24:10.480945', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:10,481 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:24:10.481123', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:24:21,746 - Processed run 8 for mu=0.85 on cuda:2. Elapsed time: 15.34 seconds
2023-12-09 17:24:23,787 - collecting all words and their counts
2023-12-09 17:24:23,787 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:24:23,848 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:24:23,848 - Creating a fresh vocabulary
2023-12-09 17:24:23,850 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:24:23.850381', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:23,850 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:24:23.850460', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:23,853 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:24:23,853 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:24:23,853 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:24:23.853359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:23,858 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:24:23,858 - resetting layer weights
2023-12-09 17:24:23,858 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:24:23.858427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:24:23,858 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:24:23.858870', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:24,898 - EPOCH 0 - PROGRESS: at 46.25% examples, 357038 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:24:25,916 - EPOCH 0 - PROGRESS: at 96.25% examples, 374828 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:24:25,942 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384595 effective words/s
2023-12-09 17:24:25,942 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383973 effective words/s', 'datetime': '2023-12-09T17:24:25.942421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:25,942 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:24:25.942592', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:24:40,893 - Processed run 8 for mu=0.9 on cuda:3. Elapsed time: 19.15 seconds
2023-12-09 17:24:43,204 - collecting all words and their counts
2023-12-09 17:24:43,204 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:24:43,265 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:24:43,265 - Creating a fresh vocabulary
2023-12-09 17:24:43,267 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:24:43.267390', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:43,267 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:24:43.267467', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:43,270 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:24:43,270 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:24:43,270 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:24:43.270312', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:43,275 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:24:43,275 - resetting layer weights
2023-12-09 17:24:43,275 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:24:43.275518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:24:43,275 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:24:43.275756', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:44,318 - EPOCH 0 - PROGRESS: at 46.25% examples, 355812 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:24:45,347 - EPOCH 0 - PROGRESS: at 96.25% examples, 372217 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:24:45,388 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 379325 effective words/s
2023-12-09 17:24:45,388 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378712 effective words/s', 'datetime': '2023-12-09T17:24:45.388251', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:24:45,388 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:24:45.388789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:24:57,299 - Processed run 8 for mu=0.95 on cuda:4. Elapsed time: 16.40 seconds
2023-12-09 17:24:59,832 - collecting all words and their counts
2023-12-09 17:24:59,832 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:24:59,894 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:24:59,894 - Creating a fresh vocabulary
2023-12-09 17:24:59,896 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:24:59.896827', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:59,896 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:24:59.896902', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:59,899 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:24:59,899 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:24:59,899 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:24:59.899761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:24:59,904 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:24:59,904 - resetting layer weights
2023-12-09 17:24:59,904 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:24:59.904826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:24:59,905 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:24:59.905213', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:00,926 - EPOCH 0 - PROGRESS: at 41.25% examples, 324120 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:25:01,936 - EPOCH 0 - PROGRESS: at 90.00% examples, 354969 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:02,151 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356600 effective words/s
2023-12-09 17:25:02,152 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356073 effective words/s', 'datetime': '2023-12-09T17:25:02.152020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:02,152 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:02.152200', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:13,576 - Processed run 8 for mu=1.0 on cuda:1. Elapsed time: 16.28 seconds
2023-12-09 17:25:14,648 - collecting all words and their counts
2023-12-09 17:25:14,648 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:14,708 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:14,708 - Creating a fresh vocabulary
2023-12-09 17:25:14,710 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:14.710387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:14,710 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:14.710453', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:14,713 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:14,713 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:14,713 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:14.713372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:14,718 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:14,718 - resetting layer weights
2023-12-09 17:25:14,718 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:14.718499', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:14,718 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:14.718965', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:15,755 - EPOCH 0 - PROGRESS: at 61.25% examples, 474184 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:16,230 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 530357 effective words/s
2023-12-09 17:25:16,230 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 529152 effective words/s', 'datetime': '2023-12-09T17:25:16.230891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:16,231 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:16.231068', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:20,178 - Processed run 9 for mu=0.0 on cuda:1. Elapsed time: 6.60 seconds
2023-12-09 17:25:21,033 - collecting all words and their counts
2023-12-09 17:25:21,034 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:21,094 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:21,094 - Creating a fresh vocabulary
2023-12-09 17:25:21,096 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:21.096837', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:21,096 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:21.096908', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:21,099 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:21,099 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:21,099 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:21.099729', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:21,104 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:21,104 - resetting layer weights
2023-12-09 17:25:21,104 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:21.104875', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:21,105 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:21.105283', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:22,129 - EPOCH 0 - PROGRESS: at 41.25% examples, 323161 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:25:23,138 - EPOCH 0 - PROGRESS: at 87.50% examples, 344877 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:25:23,360 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355231 effective words/s
2023-12-09 17:25:23,360 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354692 effective words/s', 'datetime': '2023-12-09T17:25:23.360830', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:23,361 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:23.360999', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:27,759 - Processed run 9 for mu=0.05 on cuda:2. Elapsed time: 7.58 seconds
2023-12-09 17:25:28,665 - collecting all words and their counts
2023-12-09 17:25:28,666 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:28,725 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:28,725 - Creating a fresh vocabulary
2023-12-09 17:25:28,727 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:28.727773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:28,727 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:28.727838', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:28,730 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:28,730 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:28,730 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:28.730733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:28,735 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:28,735 - resetting layer weights
2023-12-09 17:25:28,735 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:28.735760', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:28,736 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:28.736252', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:29,755 - EPOCH 0 - PROGRESS: at 41.25% examples, 324705 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:30,763 - EPOCH 0 - PROGRESS: at 87.50% examples, 345799 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:30,994 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354771 effective words/s
2023-12-09 17:25:30,994 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354261 effective words/s', 'datetime': '2023-12-09T17:25:30.994527', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:30,994 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:30.994606', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:36,065 - Processed run 9 for mu=0.1 on cuda:3. Elapsed time: 8.31 seconds
2023-12-09 17:25:36,950 - collecting all words and their counts
2023-12-09 17:25:36,950 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:37,011 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:37,011 - Creating a fresh vocabulary
2023-12-09 17:25:37,013 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:37.013785', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:37,013 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:37.013855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:37,016 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:37,016 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:37,016 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:37.016764', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:37,021 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:37,021 - resetting layer weights
2023-12-09 17:25:37,021 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:37.021867', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:37,022 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:37.022316', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:38,036 - EPOCH 0 - PROGRESS: at 42.50% examples, 336277 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:39,057 - EPOCH 0 - PROGRESS: at 88.75% examples, 349390 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:25:39,275 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355513 effective words/s
2023-12-09 17:25:39,276 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354971 effective words/s', 'datetime': '2023-12-09T17:25:39.276093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:39,276 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:39.276278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:44,428 - Processed run 9 for mu=0.15 on cuda:4. Elapsed time: 8.36 seconds
2023-12-09 17:25:45,412 - collecting all words and their counts
2023-12-09 17:25:45,413 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:45,475 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:45,475 - Creating a fresh vocabulary
2023-12-09 17:25:45,477 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:45.477902', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:45,478 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:45.477978', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:45,480 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:45,480 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:45,480 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:45.480907', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:45,485 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:45,485 - resetting layer weights
2023-12-09 17:25:45,486 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:45.486001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:45,486 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:45.486424', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:46,502 - EPOCH 0 - PROGRESS: at 41.25% examples, 325907 words/s, in_qsize 8, out_qsize 0
2023-12-09 17:25:47,586 - EPOCH 0 - PROGRESS: at 91.25% examples, 348137 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:47,713 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359735 effective words/s
2023-12-09 17:25:47,713 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359177 effective words/s', 'datetime': '2023-12-09T17:25:47.713811', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:47,714 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:47.713982', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:25:52,953 - Processed run 9 for mu=0.2 on cuda:1. Elapsed time: 8.52 seconds
2023-12-09 17:25:53,779 - collecting all words and their counts
2023-12-09 17:25:53,779 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:25:53,841 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:25:53,841 - Creating a fresh vocabulary
2023-12-09 17:25:53,843 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:25:53.843116', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:53,843 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:25:53.843181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:53,845 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:25:53,845 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:25:53,846 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:25:53.846012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:25:53,850 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:25:53,850 - resetting layer weights
2023-12-09 17:25:53,851 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:25:53.851201', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:25:53,851 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:25:53.851680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:54,902 - EPOCH 0 - PROGRESS: at 46.25% examples, 353120 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:25:55,928 - EPOCH 0 - PROGRESS: at 96.25% examples, 371295 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:25:55,938 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383966 effective words/s
2023-12-09 17:25:55,938 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383363 effective words/s', 'datetime': '2023-12-09T17:25:55.938540', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:25:55,938 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:25:55.938673', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:00,987 - Processed run 9 for mu=0.25 on cuda:2. Elapsed time: 8.03 seconds
2023-12-09 17:26:01,892 - collecting all words and their counts
2023-12-09 17:26:01,892 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:01,953 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:01,953 - Creating a fresh vocabulary
2023-12-09 17:26:01,955 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:01.955739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:01,955 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:01.955804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:01,958 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:01,958 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:01,958 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:01.958684', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:01,963 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:01,963 - resetting layer weights
2023-12-09 17:26:01,963 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:01.963798', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:01,964 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:01.964268', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:03,013 - EPOCH 0 - PROGRESS: at 46.25% examples, 353785 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:04,035 - EPOCH 0 - PROGRESS: at 96.25% examples, 372297 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:04,045 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384883 effective words/s
2023-12-09 17:26:04,046 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384274 effective words/s', 'datetime': '2023-12-09T17:26:04.046186', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:04,046 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:04.046354', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:09,594 - Processed run 9 for mu=0.3 on cuda:3. Elapsed time: 8.61 seconds
2023-12-09 17:26:10,576 - collecting all words and their counts
2023-12-09 17:26:10,576 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:10,637 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:10,637 - Creating a fresh vocabulary
2023-12-09 17:26:10,639 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:10.639786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:10,639 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:10.639853', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:10,642 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:10,642 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:10,642 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:10.642773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:10,647 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:10,647 - resetting layer weights
2023-12-09 17:26:10,647 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:10.647856', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:10,648 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:10.648323', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:11,686 - EPOCH 0 - PROGRESS: at 46.25% examples, 357487 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:12,711 - EPOCH 0 - PROGRESS: at 96.25% examples, 373854 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:12,730 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384758 effective words/s
2023-12-09 17:26:12,730 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384144 effective words/s', 'datetime': '2023-12-09T17:26:12.730932', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:12,731 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:12.731013', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:17,988 - Processed run 9 for mu=0.35 on cuda:4. Elapsed time: 8.39 seconds
2023-12-09 17:26:19,047 - collecting all words and their counts
2023-12-09 17:26:19,047 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:19,108 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:19,108 - Creating a fresh vocabulary
2023-12-09 17:26:19,110 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:19.110723', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:19,110 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:19.110797', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:19,113 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:19,113 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:19,113 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:19.113715', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:19,118 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:19,118 - resetting layer weights
2023-12-09 17:26:19,118 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:19.118855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:19,119 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:19.119311', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:20,155 - EPOCH 0 - PROGRESS: at 46.25% examples, 358179 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:21,173 - EPOCH 0 - PROGRESS: at 96.25% examples, 375463 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:21,204 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384185 effective words/s
2023-12-09 17:26:21,205 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383571 effective words/s', 'datetime': '2023-12-09T17:26:21.205046', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:21,205 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:21.205212', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:26,993 - Processed run 9 for mu=0.4 on cuda:1. Elapsed time: 9.00 seconds
2023-12-09 17:26:28,113 - collecting all words and their counts
2023-12-09 17:26:28,113 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:28,176 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:28,176 - Creating a fresh vocabulary
2023-12-09 17:26:28,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:28.178185', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:28,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:28.178253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:28,181 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:28,181 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:28,181 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:28.181234', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:28,186 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:28,186 - resetting layer weights
2023-12-09 17:26:28,186 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:28.186400', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:28,186 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:28.186849', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:29,237 - EPOCH 0 - PROGRESS: at 46.25% examples, 353418 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:30,268 - EPOCH 0 - PROGRESS: at 96.25% examples, 370502 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:30,292 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380429 effective words/s
2023-12-09 17:26:30,293 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379814 effective words/s', 'datetime': '2023-12-09T17:26:30.293210', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:30,293 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:30.293378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:37,520 - Processed run 9 for mu=0.45 on cuda:2. Elapsed time: 10.53 seconds
2023-12-09 17:26:38,634 - collecting all words and their counts
2023-12-09 17:26:38,634 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:38,699 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:38,699 - Creating a fresh vocabulary
2023-12-09 17:26:38,701 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:38.701627', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:38,701 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:38.701714', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:38,704 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:38,704 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:38,704 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:38.704566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:38,709 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:38,709 - resetting layer weights
2023-12-09 17:26:38,709 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:38.709607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:38,709 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:38.709953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:39,745 - EPOCH 0 - PROGRESS: at 46.25% examples, 358420 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:40,763 - EPOCH 0 - PROGRESS: at 96.25% examples, 375599 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:40,825 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 378808 effective words/s
2023-12-09 17:26:40,825 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378191 effective words/s', 'datetime': '2023-12-09T17:26:40.825356', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:40,825 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:40.825534', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:46,935 - Processed run 9 for mu=0.5 on cuda:3. Elapsed time: 9.41 seconds
2023-12-09 17:26:48,235 - collecting all words and their counts
2023-12-09 17:26:48,236 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:48,297 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:48,298 - Creating a fresh vocabulary
2023-12-09 17:26:48,299 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:48.299976', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:48,300 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:48.300043', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:48,302 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:48,302 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:48,303 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:48.303006', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:48,307 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:48,307 - resetting layer weights
2023-12-09 17:26:48,308 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:48.308011', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:48,308 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:48.308478', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:49,363 - EPOCH 0 - PROGRESS: at 46.25% examples, 351642 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:26:50,392 - EPOCH 0 - PROGRESS: at 96.25% examples, 370013 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:26:50,416 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380126 effective words/s
2023-12-09 17:26:50,416 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379531 effective words/s', 'datetime': '2023-12-09T17:26:50.416416', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:50,416 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:26:50.416628', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:26:56,664 - Processed run 9 for mu=0.55 on cuda:4. Elapsed time: 9.73 seconds
2023-12-09 17:26:58,078 - collecting all words and their counts
2023-12-09 17:26:58,078 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:26:58,139 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:26:58,139 - Creating a fresh vocabulary
2023-12-09 17:26:58,141 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:26:58.141864', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:58,141 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:26:58.141930', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:58,144 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:26:58,144 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:26:58,144 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:26:58.144838', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:26:58,149 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:26:58,149 - resetting layer weights
2023-12-09 17:26:58,149 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:26:58.149950', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:26:58,150 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:26:58.150282', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:26:59,196 - EPOCH 0 - PROGRESS: at 46.25% examples, 354762 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:27:00,217 - EPOCH 0 - PROGRESS: at 96.25% examples, 373068 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:27:00,236 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384060 effective words/s
2023-12-09 17:27:00,236 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383432 effective words/s', 'datetime': '2023-12-09T17:27:00.236773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:00,236 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:27:00.236949', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:27:07,808 - Processed run 9 for mu=0.6 on cuda:1. Elapsed time: 11.14 seconds
2023-12-09 17:27:09,284 - collecting all words and their counts
2023-12-09 17:27:09,284 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:27:09,346 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:27:09,346 - Creating a fresh vocabulary
2023-12-09 17:27:09,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:27:09.348012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:09,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:27:09.348085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:09,350 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:27:09,350 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:27:09,351 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:27:09.351001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:09,355 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:27:09,355 - resetting layer weights
2023-12-09 17:27:09,356 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:27:09.356144', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:27:09,356 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:27:09.356659', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:10,394 - EPOCH 0 - PROGRESS: at 46.25% examples, 357672 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:27:11,413 - EPOCH 0 - PROGRESS: at 96.25% examples, 374954 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:27:11,443 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383952 effective words/s
2023-12-09 17:27:11,443 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383335 effective words/s', 'datetime': '2023-12-09T17:27:11.443683', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:11,443 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:27:11.443860', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:27:18,743 - Processed run 9 for mu=0.65 on cuda:2. Elapsed time: 10.93 seconds
2023-12-09 17:27:20,271 - collecting all words and their counts
2023-12-09 17:27:20,271 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:27:20,333 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:27:20,333 - Creating a fresh vocabulary
2023-12-09 17:27:20,335 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:27:20.335304', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:20,335 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:27:20.335380', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:20,338 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:27:20,338 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:27:20,338 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:27:20.338269', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:20,343 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:27:20,343 - resetting layer weights
2023-12-09 17:27:20,343 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:27:20.343427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:27:20,343 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:27:20.343855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:21,403 - EPOCH 0 - PROGRESS: at 46.25% examples, 350143 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:27:22,436 - EPOCH 0 - PROGRESS: at 96.25% examples, 368544 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:27:22,458 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 378888 effective words/s
2023-12-09 17:27:22,458 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378294 effective words/s', 'datetime': '2023-12-09T17:27:22.458684', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:22,458 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:27:22.458853', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:27:30,959 - Processed run 9 for mu=0.7 on cuda:3. Elapsed time: 12.21 seconds
2023-12-09 17:27:32,635 - collecting all words and their counts
2023-12-09 17:27:32,635 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:27:32,696 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:27:32,696 - Creating a fresh vocabulary
2023-12-09 17:27:32,698 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:27:32.698914', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:32,698 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:27:32.698986', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:32,701 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:27:32,701 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:27:32,701 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:27:32.701909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:32,706 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:27:32,706 - resetting layer weights
2023-12-09 17:27:32,707 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:27:32.707090', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:27:32,707 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:27:32.707643', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:33,752 - EPOCH 0 - PROGRESS: at 46.25% examples, 355123 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:27:34,768 - EPOCH 0 - PROGRESS: at 96.25% examples, 374162 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:27:34,779 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386657 effective words/s
2023-12-09 17:27:34,780 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 386020 effective words/s', 'datetime': '2023-12-09T17:27:34.780147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:34,780 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:27:34.780313', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:27:43,980 - Processed run 9 for mu=0.75 on cuda:4. Elapsed time: 13.02 seconds
2023-12-09 17:27:45,830 - collecting all words and their counts
2023-12-09 17:27:45,830 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:27:45,892 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:27:45,892 - Creating a fresh vocabulary
2023-12-09 17:27:45,894 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:27:45.894740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:45,894 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:27:45.894802', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:45,897 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:27:45,897 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:27:45,897 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:27:45.897680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:27:45,902 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:27:45,902 - resetting layer weights
2023-12-09 17:27:45,902 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:27:45.902850', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:27:45,903 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:27:45.903338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:46,951 - EPOCH 0 - PROGRESS: at 46.25% examples, 354043 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:27:47,972 - EPOCH 0 - PROGRESS: at 96.25% examples, 372708 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:27:47,991 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383722 effective words/s
2023-12-09 17:27:47,991 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383095 effective words/s', 'datetime': '2023-12-09T17:27:47.991666', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:27:47,991 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:27:47.991835', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:28:00,356 - Processed run 9 for mu=0.8 on cuda:1. Elapsed time: 16.38 seconds
2023-12-09 17:28:02,370 - collecting all words and their counts
2023-12-09 17:28:02,370 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:28:02,432 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:28:02,432 - Creating a fresh vocabulary
2023-12-09 17:28:02,434 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:28:02.434315', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:02,434 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:28:02.434382', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:02,437 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:28:02,437 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:28:02,437 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:28:02.437245', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:02,442 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:28:02,442 - resetting layer weights
2023-12-09 17:28:02,442 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:28:02.442483', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:28:02,442 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:28:02.442970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:03,473 - EPOCH 0 - PROGRESS: at 46.25% examples, 360207 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:04,496 - EPOCH 0 - PROGRESS: at 96.25% examples, 375497 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:28:04,522 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385331 effective words/s
2023-12-09 17:28:04,522 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384734 effective words/s', 'datetime': '2023-12-09T17:28:04.522410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:04,522 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:28:04.522578', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:28:16,185 - Processed run 9 for mu=0.85 on cuda:2. Elapsed time: 15.83 seconds
2023-12-09 17:28:18,235 - collecting all words and their counts
2023-12-09 17:28:18,235 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:28:18,297 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:28:18,298 - Creating a fresh vocabulary
2023-12-09 17:28:18,299 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:28:18.299926', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:18,300 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:28:18.300010', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:18,302 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:28:18,302 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:28:18,302 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:28:18.302891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:18,307 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:28:18,307 - resetting layer weights
2023-12-09 17:28:18,307 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:28:18.307894', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:28:18,308 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:28:18.308399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:19,330 - EPOCH 0 - PROGRESS: at 41.25% examples, 323932 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:20,331 - EPOCH 0 - PROGRESS: at 87.50% examples, 346490 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:20,566 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354861 effective words/s
2023-12-09 17:28:20,566 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354324 effective words/s', 'datetime': '2023-12-09T17:28:20.566294', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:20,566 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:28:20.566480', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:28:33,896 - Processed run 9 for mu=0.9 on cuda:3. Elapsed time: 17.71 seconds
2023-12-09 17:28:36,067 - collecting all words and their counts
2023-12-09 17:28:36,068 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:28:36,133 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:28:36,133 - Creating a fresh vocabulary
2023-12-09 17:28:36,135 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:28:36.135243', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:36,135 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:28:36.135327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:36,138 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:28:36,138 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:28:36,138 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:28:36.138205', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:36,143 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:28:36,143 - resetting layer weights
2023-12-09 17:28:36,143 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:28:36.143446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:28:36,143 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:28:36.143944', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:37,164 - EPOCH 0 - PROGRESS: at 42.50% examples, 334152 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:38,169 - EPOCH 0 - PROGRESS: at 87.50% examples, 346126 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:38,393 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356145 effective words/s
2023-12-09 17:28:38,393 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355619 effective words/s', 'datetime': '2023-12-09T17:28:38.393614', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:38,393 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:28:38.393789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:28:49,578 - Processed run 9 for mu=0.95 on cuda:4. Elapsed time: 15.68 seconds
2023-12-09 17:28:51,990 - collecting all words and their counts
2023-12-09 17:28:51,990 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:28:52,051 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:28:52,051 - Creating a fresh vocabulary
2023-12-09 17:28:52,053 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:28:52.053230', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:52,053 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:28:52.053296', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:52,056 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:28:52,056 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:28:52,056 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:28:52.056098', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:28:52,060 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:28:52,060 - resetting layer weights
2023-12-09 17:28:52,061 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:28:52.061161', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:28:52,061 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:28:52.061518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:53,108 - EPOCH 0 - PROGRESS: at 46.25% examples, 354464 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:28:54,128 - EPOCH 0 - PROGRESS: at 96.25% examples, 373092 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:28:54,181 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 377844 effective words/s
2023-12-09 17:28:54,182 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 377250 effective words/s', 'datetime': '2023-12-09T17:28:54.182197', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:28:54,182 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:28:54.182367', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:06,095 - Processed run 9 for mu=1.0 on cuda:1. Elapsed time: 16.52 seconds
2023-12-09 17:29:07,195 - collecting all words and their counts
2023-12-09 17:29:07,195 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:07,255 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:07,255 - Creating a fresh vocabulary
2023-12-09 17:29:07,257 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:07.257079', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:07,257 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:07.257152', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:07,259 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:07,259 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:07,260 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:07.260024', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:07,264 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:07,264 - resetting layer weights
2023-12-09 17:29:07,265 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:07.265195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:07,265 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:07.265744', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:08,271 - EPOCH 0 - PROGRESS: at 58.75% examples, 468957 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:08,803 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 521276 effective words/s
2023-12-09 17:29:08,803 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 520140 effective words/s', 'datetime': '2023-12-09T17:29:08.803864', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:08,804 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:08.804045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:13,696 - Processed run 10 for mu=0.0 on cuda:1. Elapsed time: 7.60 seconds
2023-12-09 17:29:14,834 - collecting all words and their counts
2023-12-09 17:29:14,834 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:14,896 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:14,896 - Creating a fresh vocabulary
2023-12-09 17:29:14,898 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:14.898142', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:14,898 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:14.898209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:14,900 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:14,900 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:14,901 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:14.901028', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:14,905 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:14,905 - resetting layer weights
2023-12-09 17:29:14,906 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:14.906114', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:14,906 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:14.906568', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:15,916 - EPOCH 0 - PROGRESS: at 41.25% examples, 327960 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:16,932 - EPOCH 0 - PROGRESS: at 87.50% examples, 346137 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:17,167 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354306 effective words/s
2023-12-09 17:29:17,168 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353774 effective words/s', 'datetime': '2023-12-09T17:29:17.167971', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:17,168 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:17.168151', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:22,408 - Processed run 10 for mu=0.05 on cuda:2. Elapsed time: 8.71 seconds
2023-12-09 17:29:23,243 - collecting all words and their counts
2023-12-09 17:29:23,243 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:23,303 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:23,304 - Creating a fresh vocabulary
2023-12-09 17:29:23,305 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:23.305975', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:23,306 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:23.306039', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:23,308 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:23,308 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:23,309 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:23.308997', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:23,313 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:23,313 - resetting layer weights
2023-12-09 17:29:23,314 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:23.314120', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:23,314 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:23.314571', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:24,325 - EPOCH 0 - PROGRESS: at 41.25% examples, 327378 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:25,343 - EPOCH 0 - PROGRESS: at 87.50% examples, 345624 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:25,568 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355473 effective words/s
2023-12-09 17:29:25,568 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354936 effective words/s', 'datetime': '2023-12-09T17:29:25.568588', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:25,568 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:25.568790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:31,122 - Processed run 10 for mu=0.1 on cuda:3. Elapsed time: 8.71 seconds
2023-12-09 17:29:31,874 - collecting all words and their counts
2023-12-09 17:29:31,874 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:31,936 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:31,936 - Creating a fresh vocabulary
2023-12-09 17:29:31,938 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:31.938900', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:31,938 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:31.938976', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:31,941 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:31,941 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:31,941 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:31.941855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:31,946 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:31,946 - resetting layer weights
2023-12-09 17:29:31,946 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:31.946980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:31,947 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:31.947418', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:32,993 - EPOCH 0 - PROGRESS: at 46.25% examples, 354829 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:34,019 - EPOCH 0 - PROGRESS: at 96.25% examples, 372239 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:29:34,035 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383780 effective words/s
2023-12-09 17:29:34,035 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383165 effective words/s', 'datetime': '2023-12-09T17:29:34.035360', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:34,035 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:34.035531', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:38,414 - Processed run 10 for mu=0.15 on cuda:4. Elapsed time: 7.29 seconds
2023-12-09 17:29:39,392 - collecting all words and their counts
2023-12-09 17:29:39,392 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:39,454 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:39,455 - Creating a fresh vocabulary
2023-12-09 17:29:39,457 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:39.457004', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:39,457 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:39.457074', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:39,459 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:39,459 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:39,459 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:39.459898', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:39,464 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:39,464 - resetting layer weights
2023-12-09 17:29:39,464 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:39.464970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:39,465 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:39.465301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:40,516 - EPOCH 0 - PROGRESS: at 46.25% examples, 353178 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:41,552 - EPOCH 0 - PROGRESS: at 96.25% examples, 369473 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:29:41,570 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380535 effective words/s
2023-12-09 17:29:41,571 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379927 effective words/s', 'datetime': '2023-12-09T17:29:41.571044', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:41,571 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:41.571216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:46,892 - Processed run 10 for mu=0.2 on cuda:1. Elapsed time: 8.48 seconds
2023-12-09 17:29:47,750 - collecting all words and their counts
2023-12-09 17:29:47,750 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:47,811 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:47,811 - Creating a fresh vocabulary
2023-12-09 17:29:47,813 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:47.813863', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:47,813 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:47.813935', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:47,816 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:47,816 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:47,816 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:47.816885', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:47,821 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:47,821 - resetting layer weights
2023-12-09 17:29:47,821 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:47.821970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:47,822 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:47.822406', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:48,858 - EPOCH 0 - PROGRESS: at 46.25% examples, 358170 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:49,874 - EPOCH 0 - PROGRESS: at 96.25% examples, 375725 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:29:49,912 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383395 effective words/s
2023-12-09 17:29:49,912 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382786 effective words/s', 'datetime': '2023-12-09T17:29:49.912422', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:49,912 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:49.912606', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:29:55,369 - Processed run 10 for mu=0.25 on cuda:2. Elapsed time: 8.48 seconds
2023-12-09 17:29:56,313 - collecting all words and their counts
2023-12-09 17:29:56,314 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:29:56,376 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:29:56,376 - Creating a fresh vocabulary
2023-12-09 17:29:56,378 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:29:56.378400', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:56,378 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:29:56.378476', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:56,381 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:29:56,381 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:29:56,381 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:29:56.381486', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:29:56,386 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:29:56,386 - resetting layer weights
2023-12-09 17:29:56,386 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:29:56.386771', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:29:56,387 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:29:56.387070', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:57,431 - EPOCH 0 - PROGRESS: at 46.25% examples, 355492 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:29:58,452 - EPOCH 0 - PROGRESS: at 96.25% examples, 373339 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:29:58,489 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381164 effective words/s
2023-12-09 17:29:58,489 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380553 effective words/s', 'datetime': '2023-12-09T17:29:58.489350', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:29:58,489 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:29:58.489517', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:04,121 - Processed run 10 for mu=0.3 on cuda:3. Elapsed time: 8.75 seconds
2023-12-09 17:30:05,045 - collecting all words and their counts
2023-12-09 17:30:05,045 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:05,107 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:05,107 - Creating a fresh vocabulary
2023-12-09 17:30:05,109 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:05.109421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:05,109 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:05.109493', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:05,112 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:05,112 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:05,112 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:05.112448', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:05,117 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:05,117 - resetting layer weights
2023-12-09 17:30:05,117 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:05.117730', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:05,118 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:05.118232', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:06,162 - EPOCH 0 - PROGRESS: at 46.25% examples, 355459 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:07,185 - EPOCH 0 - PROGRESS: at 96.25% examples, 373060 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:07,219 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381345 effective words/s
2023-12-09 17:30:07,219 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380747 effective words/s', 'datetime': '2023-12-09T17:30:07.219441', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:07,219 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:07.219611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:12,509 - Processed run 10 for mu=0.35 on cuda:4. Elapsed time: 8.39 seconds
2023-12-09 17:30:13,732 - collecting all words and their counts
2023-12-09 17:30:13,732 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:13,793 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:13,794 - Creating a fresh vocabulary
2023-12-09 17:30:13,796 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:13.796022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:13,796 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:13.796095', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:13,798 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:13,798 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:13,798 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:13.798954', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:13,803 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:13,803 - resetting layer weights
2023-12-09 17:30:13,804 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:13.804099', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:13,804 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:13.804548', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:14,851 - EPOCH 0 - PROGRESS: at 46.25% examples, 354546 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:15,873 - EPOCH 0 - PROGRESS: at 96.25% examples, 372720 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:15,912 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380011 effective words/s
2023-12-09 17:30:15,913 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379425 effective words/s', 'datetime': '2023-12-09T17:30:15.913081', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:15,913 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:15.913248', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:23,270 - Processed run 10 for mu=0.4 on cuda:1. Elapsed time: 10.76 seconds
2023-12-09 17:30:24,337 - collecting all words and their counts
2023-12-09 17:30:24,337 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:24,399 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:24,399 - Creating a fresh vocabulary
2023-12-09 17:30:24,401 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:24.401140', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:24,401 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:24.401228', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:24,404 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:24,404 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:24,404 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:24.404126', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:24,408 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:24,408 - resetting layer weights
2023-12-09 17:30:24,409 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:24.409285', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:24,409 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:24.409589', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:25,459 - EPOCH 0 - PROGRESS: at 46.25% examples, 353575 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:26,474 - EPOCH 0 - PROGRESS: at 96.25% examples, 373509 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:26,496 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383909 effective words/s
2023-12-09 17:30:26,496 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383295 effective words/s', 'datetime': '2023-12-09T17:30:26.496832', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:26,497 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:26.497014', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:32,439 - Processed run 10 for mu=0.45 on cuda:2. Elapsed time: 9.17 seconds
2023-12-09 17:30:33,660 - collecting all words and their counts
2023-12-09 17:30:33,660 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:33,722 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:33,722 - Creating a fresh vocabulary
2023-12-09 17:30:33,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:33.724608', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:33,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:33.724678', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:33,727 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:33,727 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:33,727 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:33.727554', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:33,732 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:33,732 - resetting layer weights
2023-12-09 17:30:33,732 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:33.732635', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:33,733 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:33.733091', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:34,788 - EPOCH 0 - PROGRESS: at 46.25% examples, 351783 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:35,808 - EPOCH 0 - PROGRESS: at 96.25% examples, 371679 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:35,826 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382675 effective words/s
2023-12-09 17:30:35,827 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382061 effective words/s', 'datetime': '2023-12-09T17:30:35.827068', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:35,827 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:35.827236', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:42,164 - Processed run 10 for mu=0.5 on cuda:3. Elapsed time: 9.72 seconds
2023-12-09 17:30:43,453 - collecting all words and their counts
2023-12-09 17:30:43,453 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:43,515 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:43,515 - Creating a fresh vocabulary
2023-12-09 17:30:43,517 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:43.517778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:43,517 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:43.517855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:43,520 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:43,520 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:43,520 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:43.520759', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:43,525 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:43,525 - resetting layer weights
2023-12-09 17:30:43,525 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:43.525875', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:43,526 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:43.526293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:44,569 - EPOCH 0 - PROGRESS: at 46.25% examples, 355850 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:45,604 - EPOCH 0 - PROGRESS: at 96.25% examples, 371049 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:45,622 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382221 effective words/s
2023-12-09 17:30:45,622 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381594 effective words/s', 'datetime': '2023-12-09T17:30:45.622830', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:45,623 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:45.622998', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:30:52,342 - Processed run 10 for mu=0.55 on cuda:4. Elapsed time: 10.18 seconds
2023-12-09 17:30:53,681 - collecting all words and their counts
2023-12-09 17:30:53,681 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:30:53,743 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:30:53,744 - Creating a fresh vocabulary
2023-12-09 17:30:53,745 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:30:53.745891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:53,745 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:30:53.745968', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:53,748 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:30:53,748 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:30:53,748 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:30:53.748855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:30:53,753 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:30:53,753 - resetting layer weights
2023-12-09 17:30:53,753 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:30:53.753928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:30:53,754 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:30:53.754340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:54,805 - EPOCH 0 - PROGRESS: at 46.25% examples, 353179 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:30:55,827 - EPOCH 0 - PROGRESS: at 96.25% examples, 371992 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:30:55,855 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381258 effective words/s
2023-12-09 17:30:55,856 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380654 effective words/s', 'datetime': '2023-12-09T17:30:55.856066', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:30:55,856 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:30:55.856293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:31:02,980 - Processed run 10 for mu=0.6 on cuda:1. Elapsed time: 10.64 seconds
2023-12-09 17:31:04,431 - collecting all words and their counts
2023-12-09 17:31:04,432 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:31:04,494 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:31:04,494 - Creating a fresh vocabulary
2023-12-09 17:31:04,496 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:31:04.496248', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:04,496 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:31:04.496315', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:04,499 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:31:04,499 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:31:04,499 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:31:04.499199', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:04,503 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:31:04,503 - resetting layer weights
2023-12-09 17:31:04,504 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:31:04.504294', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:31:04,504 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:31:04.504806', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:05,550 - EPOCH 0 - PROGRESS: at 46.25% examples, 355012 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:31:06,571 - EPOCH 0 - PROGRESS: at 96.25% examples, 373079 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:31:06,612 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380138 effective words/s
2023-12-09 17:31:06,612 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379538 effective words/s', 'datetime': '2023-12-09T17:31:06.612707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:06,612 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:31:06.612878', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:31:14,219 - Processed run 10 for mu=0.65 on cuda:2. Elapsed time: 11.24 seconds
2023-12-09 17:31:15,726 - collecting all words and their counts
2023-12-09 17:31:15,726 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:31:15,788 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:31:15,788 - Creating a fresh vocabulary
2023-12-09 17:31:15,790 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:31:15.790676', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:15,790 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:31:15.790741', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:15,793 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:31:15,793 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:31:15,793 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:31:15.793725', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:15,798 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:31:15,798 - resetting layer weights
2023-12-09 17:31:15,798 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:31:15.798909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:31:15,799 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:31:15.799349', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:16,851 - EPOCH 0 - PROGRESS: at 46.25% examples, 352627 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:31:17,880 - EPOCH 0 - PROGRESS: at 96.25% examples, 370595 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:31:17,890 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383246 effective words/s
2023-12-09 17:31:17,890 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382629 effective words/s', 'datetime': '2023-12-09T17:31:17.890223', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:17,890 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:31:17.890393', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:31:27,512 - Processed run 10 for mu=0.7 on cuda:3. Elapsed time: 13.29 seconds
2023-12-09 17:31:29,133 - collecting all words and their counts
2023-12-09 17:31:29,133 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:31:29,195 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:31:29,196 - Creating a fresh vocabulary
2023-12-09 17:31:29,197 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:31:29.197891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:29,197 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:31:29.197959', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:29,200 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:31:29,200 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:31:29,200 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:31:29.200845', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:29,205 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:31:29,205 - resetting layer weights
2023-12-09 17:31:29,206 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:31:29.206024', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:31:29,206 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:31:29.206320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:30,247 - EPOCH 0 - PROGRESS: at 46.25% examples, 356438 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:31:31,267 - EPOCH 0 - PROGRESS: at 96.25% examples, 374128 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:31:31,299 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382699 effective words/s
2023-12-09 17:31:31,300 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382086 effective words/s', 'datetime': '2023-12-09T17:31:31.300158', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:31,300 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:31:31.300327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:31:40,213 - Processed run 10 for mu=0.75 on cuda:4. Elapsed time: 12.70 seconds
2023-12-09 17:31:42,035 - collecting all words and their counts
2023-12-09 17:31:42,035 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:31:42,097 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:31:42,097 - Creating a fresh vocabulary
2023-12-09 17:31:42,099 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:31:42.099055', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:42,099 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:31:42.099127', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:42,102 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:31:42,102 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:31:42,102 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:31:42.102092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:42,106 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:31:42,106 - resetting layer weights
2023-12-09 17:31:42,107 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:31:42.107271', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:31:42,107 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:31:42.107745', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:43,148 - EPOCH 0 - PROGRESS: at 46.25% examples, 356782 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:31:44,167 - EPOCH 0 - PROGRESS: at 96.25% examples, 374393 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:31:44,188 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385075 effective words/s
2023-12-09 17:31:44,188 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384416 effective words/s', 'datetime': '2023-12-09T17:31:44.188897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:44,189 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:31:44.189067', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:31:55,319 - Processed run 10 for mu=0.8 on cuda:1. Elapsed time: 15.10 seconds
2023-12-09 17:31:57,287 - collecting all words and their counts
2023-12-09 17:31:57,287 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:31:57,349 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:31:57,349 - Creating a fresh vocabulary
2023-12-09 17:31:57,351 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:31:57.351016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:57,351 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:31:57.351087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:57,353 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:31:57,353 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:31:57,353 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:31:57.353967', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:31:57,358 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:31:57,358 - resetting layer weights
2023-12-09 17:31:57,359 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:31:57.359175', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:31:57,359 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:31:57.359694', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:58,415 - EPOCH 0 - PROGRESS: at 46.25% examples, 351426 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:31:59,445 - EPOCH 0 - PROGRESS: at 96.25% examples, 369827 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:31:59,462 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381119 effective words/s
2023-12-09 17:31:59,462 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380498 effective words/s', 'datetime': '2023-12-09T17:31:59.462278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:31:59,462 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:31:59.462452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:32:11,118 - Processed run 10 for mu=0.85 on cuda:2. Elapsed time: 15.80 seconds
2023-12-09 17:32:13,248 - collecting all words and their counts
2023-12-09 17:32:13,248 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:32:13,310 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:32:13,310 - Creating a fresh vocabulary
2023-12-09 17:32:13,312 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:32:13.312719', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:13,312 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:32:13.312804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:13,315 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:32:13,315 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:32:13,315 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:32:13.315664', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:13,320 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:32:13,320 - resetting layer weights
2023-12-09 17:32:13,320 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:32:13.320786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:32:13,321 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:32:13.321187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:14,372 - EPOCH 0 - PROGRESS: at 46.25% examples, 352979 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:32:15,396 - EPOCH 0 - PROGRESS: at 96.25% examples, 371656 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:32:15,407 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384098 effective words/s
2023-12-09 17:32:15,407 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383490 effective words/s', 'datetime': '2023-12-09T17:32:15.407365', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:15,407 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:32:15.407534', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:32:28,445 - Processed run 10 for mu=0.9 on cuda:3. Elapsed time: 17.33 seconds
2023-12-09 17:32:30,629 - collecting all words and their counts
2023-12-09 17:32:30,629 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:32:30,692 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:32:30,692 - Creating a fresh vocabulary
2023-12-09 17:32:30,694 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:32:30.694350', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:30,694 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:32:30.694424', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:30,697 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:32:30,697 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:32:30,697 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:32:30.697373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:30,702 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:32:30,702 - resetting layer weights
2023-12-09 17:32:30,702 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:32:30.702555', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:32:30,703 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:32:30.702996', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:31,735 - EPOCH 0 - PROGRESS: at 46.25% examples, 359548 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:32:32,750 - EPOCH 0 - PROGRESS: at 96.25% examples, 376632 words/s, in_qsize 3, out_qsize 1
2023-12-09 17:32:32,788 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384103 effective words/s
2023-12-09 17:32:32,789 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383481 effective words/s', 'datetime': '2023-12-09T17:32:32.789220', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:32,789 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:32:32.789392', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:32:43,799 - Processed run 10 for mu=0.95 on cuda:4. Elapsed time: 15.35 seconds
2023-12-09 17:32:46,317 - collecting all words and their counts
2023-12-09 17:32:46,317 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 17:32:46,379 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 17:32:46,379 - Creating a fresh vocabulary
2023-12-09 17:32:46,381 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T17:32:46.381872', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:46,381 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T17:32:46.381953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:46,384 - deleting the raw counts dictionary of 1000 items
2023-12-09 17:32:46,384 - sample=0.001 downsamples 0 most-common words
2023-12-09 17:32:46,384 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T17:32:46.384885', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 17:32:46,389 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 17:32:46,389 - resetting layer weights
2023-12-09 17:32:46,390 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T17:32:46.390042', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 17:32:46,390 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T17:32:46.390433', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:47,408 - EPOCH 0 - PROGRESS: at 41.25% examples, 325188 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:32:48,412 - EPOCH 0 - PROGRESS: at 87.50% examples, 346729 words/s, in_qsize 7, out_qsize 0
2023-12-09 17:32:48,641 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355797 effective words/s
2023-12-09 17:32:48,642 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355278 effective words/s', 'datetime': '2023-12-09T17:32:48.642263', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 17:32:48,642 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T17:32:48.642446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 17:32:59,897 - Processed run 10 for mu=1.0 on cuda:1. Elapsed time: 16.10 seconds
2023-12-09 18:41:19,350 - collecting all words and their counts
2023-12-09 18:41:19,350 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:19,408 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:19,408 - Creating a fresh vocabulary
2023-12-09 18:41:19,410 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:19.410648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:19,410 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:19.410730', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:19,413 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:19,413 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:19,413 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:19.413680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:19,418 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:19,418 - resetting layer weights
2023-12-09 18:41:19,418 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:19.418897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:19,419 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:19.419287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:20,471 - EPOCH 0 - PROGRESS: at 61.25% examples, 467183 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:20,942 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 526306 effective words/s
2023-12-09 18:41:20,942 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 525109 effective words/s', 'datetime': '2023-12-09T18:41:20.942858', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:20,943 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:41:20.943042', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:41:25,090 - Processed run 1 for mu=0.0 on cuda:1. Elapsed time: 6.73 seconds
2023-12-09 18:41:25,778 - collecting all words and their counts
2023-12-09 18:41:25,778 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:25,835 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:25,835 - Creating a fresh vocabulary
2023-12-09 18:41:25,837 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:25.837268', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:25,837 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:25.837336', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:25,840 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:25,840 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:25,840 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:25.840213', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:25,844 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:25,844 - resetting layer weights
2023-12-09 18:41:25,845 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:25.845287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:25,845 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:25.845684', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:26,877 - EPOCH 0 - PROGRESS: at 41.25% examples, 320880 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:41:27,895 - EPOCH 0 - PROGRESS: at 86.25% examples, 337168 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:28,133 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350180 effective words/s
2023-12-09 18:41:28,133 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349664 effective words/s', 'datetime': '2023-12-09T18:41:28.133670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:28,134 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:41:28.134316', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:41:33,838 - Processed run 1 for mu=0.05 on cuda:2. Elapsed time: 8.75 seconds
2023-12-09 18:41:34,590 - collecting all words and their counts
2023-12-09 18:41:34,590 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:34,648 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:34,648 - Creating a fresh vocabulary
2023-12-09 18:41:34,650 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:34.650124', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:34,650 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:34.650194', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:34,653 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:34,653 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:34,653 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:34.653076', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:34,657 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:34,657 - resetting layer weights
2023-12-09 18:41:34,658 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:34.658083', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:34,658 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:34.658517', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:35,681 - EPOCH 0 - PROGRESS: at 41.25% examples, 323491 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:36,691 - EPOCH 0 - PROGRESS: at 86.25% examples, 339935 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:36,929 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352759 effective words/s
2023-12-09 18:41:36,929 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352235 effective words/s', 'datetime': '2023-12-09T18:41:36.929788', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:36,929 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:41:36.929889', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:41:41,840 - Processed run 1 for mu=0.1 on cuda:3. Elapsed time: 8.00 seconds
2023-12-09 18:41:42,756 - collecting all words and their counts
2023-12-09 18:41:42,757 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:42,816 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:42,816 - Creating a fresh vocabulary
2023-12-09 18:41:42,818 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:42.818668', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:42,818 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:42.818748', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:42,821 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:42,821 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:42,821 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:42.821635', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:42,826 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:42,826 - resetting layer weights
2023-12-09 18:41:42,826 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:42.826803', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:42,827 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:42.827289', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:43,851 - EPOCH 0 - PROGRESS: at 41.25% examples, 323067 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:44,856 - EPOCH 0 - PROGRESS: at 86.25% examples, 340611 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:45,084 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354847 effective words/s
2023-12-09 18:41:45,085 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354321 effective words/s', 'datetime': '2023-12-09T18:41:45.085205', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:45,085 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:41:45.085395', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:41:49,591 - Processed run 1 for mu=0.15 on cuda:4. Elapsed time: 7.75 seconds
2023-12-09 18:41:50,463 - collecting all words and their counts
2023-12-09 18:41:50,464 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:50,523 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:50,523 - Creating a fresh vocabulary
2023-12-09 18:41:50,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:50.525441', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:50,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:50.525518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:50,528 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:50,528 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:50,528 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:50.528409', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:50,533 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:50,533 - resetting layer weights
2023-12-09 18:41:50,533 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:50.533455', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:50,533 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:50.533932', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:51,556 - EPOCH 0 - PROGRESS: at 41.25% examples, 323709 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:41:52,564 - EPOCH 0 - PROGRESS: at 86.25% examples, 340398 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:41:52,820 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350377 effective words/s
2023-12-09 18:41:52,820 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349853 effective words/s', 'datetime': '2023-12-09T18:41:52.820688', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:52,820 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:41:52.820876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:41:57,700 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 8.11 seconds
2023-12-09 18:41:58,551 - collecting all words and their counts
2023-12-09 18:41:58,551 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:41:58,609 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:41:58,609 - Creating a fresh vocabulary
2023-12-09 18:41:58,611 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:41:58.611795', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:58,611 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:41:58.611890', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:58,614 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:41:58,614 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:41:58,614 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:41:58.614837', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:41:58,619 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:41:58,619 - resetting layer weights
2023-12-09 18:41:58,619 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:41:58.619927', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:41:58,620 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:41:58.620424', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:41:59,632 - EPOCH 0 - PROGRESS: at 41.25% examples, 326969 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:00,664 - EPOCH 0 - PROGRESS: at 87.50% examples, 342990 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:00,888 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353185 effective words/s
2023-12-09 18:42:00,888 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352678 effective words/s', 'datetime': '2023-12-09T18:42:00.888858', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:00,889 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:00.889027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:06,311 - Processed run 1 for mu=0.25 on cuda:2. Elapsed time: 8.61 seconds
2023-12-09 18:42:07,194 - collecting all words and their counts
2023-12-09 18:42:07,194 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:07,253 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:07,253 - Creating a fresh vocabulary
2023-12-09 18:42:07,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:07.255426', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:07,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:07.255507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:07,258 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:07,258 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:07,258 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:07.258412', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:07,263 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:07,263 - resetting layer weights
2023-12-09 18:42:07,263 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:07.263557', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:07,264 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:07.264098', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:08,273 - EPOCH 0 - PROGRESS: at 41.25% examples, 327872 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:09,275 - EPOCH 0 - PROGRESS: at 86.25% examples, 343616 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:09,515 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355760 effective words/s
2023-12-09 18:42:09,516 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355223 effective words/s', 'datetime': '2023-12-09T18:42:09.516277', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:09,516 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:09.516465', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:14,949 - Processed run 1 for mu=0.3 on cuda:3. Elapsed time: 8.64 seconds
2023-12-09 18:42:15,977 - collecting all words and their counts
2023-12-09 18:42:15,977 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:16,037 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:16,037 - Creating a fresh vocabulary
2023-12-09 18:42:16,039 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:16.039353', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:16,039 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:16.039451', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:16,042 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:16,042 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:16,042 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:16.042386', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:16,047 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:16,047 - resetting layer weights
2023-12-09 18:42:16,047 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:16.047565', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:16,048 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:16.048080', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:17,063 - EPOCH 0 - PROGRESS: at 46.25% examples, 365524 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:18,065 - EPOCH 0 - PROGRESS: at 97.50% examples, 387320 words/s, in_qsize 2, out_qsize 1
2023-12-09 18:42:18,071 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 396010 effective words/s
2023-12-09 18:42:18,071 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 395362 effective words/s', 'datetime': '2023-12-09T18:42:18.071618', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:18,071 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:18.071790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:23,444 - Processed run 1 for mu=0.35 on cuda:4. Elapsed time: 8.49 seconds
2023-12-09 18:42:24,506 - collecting all words and their counts
2023-12-09 18:42:24,506 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:24,566 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:24,566 - Creating a fresh vocabulary
2023-12-09 18:42:24,568 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:24.568268', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:24,568 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:24.568339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:24,571 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:24,571 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:24,571 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:24.571233', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:24,575 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:24,576 - resetting layer weights
2023-12-09 18:42:24,576 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:24.576339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:24,576 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:24.576815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:25,595 - EPOCH 0 - PROGRESS: at 41.25% examples, 325111 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:26,608 - EPOCH 0 - PROGRESS: at 88.75% examples, 350098 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:42:26,825 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356262 effective words/s
2023-12-09 18:42:26,825 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355729 effective words/s', 'datetime': '2023-12-09T18:42:26.825812', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:26,826 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:26.826007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:32,314 - Processed run 1 for mu=0.4 on cuda:1. Elapsed time: 8.87 seconds
2023-12-09 18:42:33,384 - collecting all words and their counts
2023-12-09 18:42:33,385 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:33,444 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:33,444 - Creating a fresh vocabulary
2023-12-09 18:42:33,446 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:33.446570', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:33,446 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:33.446639', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:33,449 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:33,449 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:33,449 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:33.449535', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:33,454 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:33,454 - resetting layer weights
2023-12-09 18:42:33,454 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:33.454607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:33,455 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:33.455025', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:34,476 - EPOCH 0 - PROGRESS: at 41.25% examples, 324189 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:42:35,478 - EPOCH 0 - PROGRESS: at 86.25% examples, 341490 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:35,713 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354774 effective words/s
2023-12-09 18:42:35,713 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354229 effective words/s', 'datetime': '2023-12-09T18:42:35.713523', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:35,713 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:35.713713', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:41,622 - Processed run 1 for mu=0.45 on cuda:2. Elapsed time: 9.31 seconds
2023-12-09 18:42:42,814 - collecting all words and their counts
2023-12-09 18:42:42,814 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:42,873 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:42,873 - Creating a fresh vocabulary
2023-12-09 18:42:42,875 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:42.875736', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:42,875 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:42.875827', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:42,878 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:42,878 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:42,878 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:42.878795', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:42,883 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:42,883 - resetting layer weights
2023-12-09 18:42:42,883 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:42.883914', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:42,884 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:42.884432', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:43,933 - EPOCH 0 - PROGRESS: at 41.25% examples, 315534 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:44,953 - EPOCH 0 - PROGRESS: at 86.25% examples, 334024 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:45,200 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 345860 effective words/s
2023-12-09 18:42:45,200 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 345362 effective words/s', 'datetime': '2023-12-09T18:42:45.200918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:45,201 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:45.201101', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:42:51,515 - Processed run 1 for mu=0.5 on cuda:3. Elapsed time: 9.89 seconds
2023-12-09 18:42:52,759 - collecting all words and their counts
2023-12-09 18:42:52,759 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:42:52,817 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:42:52,818 - Creating a fresh vocabulary
2023-12-09 18:42:52,820 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:42:52.820032', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:52,820 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:42:52.820109', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:52,822 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:42:52,823 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:42:52,823 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:42:52.823054', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:42:52,827 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:42:52,827 - resetting layer weights
2023-12-09 18:42:52,828 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:42:52.828142', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:42:52,828 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:42:52.828606', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:53,851 - EPOCH 0 - PROGRESS: at 46.25% examples, 362868 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:42:54,859 - EPOCH 0 - PROGRESS: at 96.25% examples, 379768 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:42:54,876 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 391206 effective words/s
2023-12-09 18:42:54,877 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 390566 effective words/s', 'datetime': '2023-12-09T18:42:54.876995', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:42:54,877 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:42:54.877165', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:43:01,217 - Processed run 1 for mu=0.55 on cuda:4. Elapsed time: 9.70 seconds
2023-12-09 18:43:02,592 - collecting all words and their counts
2023-12-09 18:43:02,592 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:43:02,652 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:43:02,652 - Creating a fresh vocabulary
2023-12-09 18:43:02,654 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:43:02.654188', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:02,654 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:43:02.654256', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:02,657 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:43:02,657 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:43:02,657 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:43:02.657130', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:02,661 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:43:02,662 - resetting layer weights
2023-12-09 18:43:02,662 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:43:02.662358', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:43:02,662 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:43:02.662743', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:03,679 - EPOCH 0 - PROGRESS: at 41.25% examples, 325569 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:04,683 - EPOCH 0 - PROGRESS: at 86.25% examples, 342035 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:04,920 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354796 effective words/s
2023-12-09 18:43:04,921 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354268 effective words/s', 'datetime': '2023-12-09T18:43:04.920993', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:04,921 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:43:04.921178', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:43:12,184 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 10.97 seconds
2023-12-09 18:43:13,589 - collecting all words and their counts
2023-12-09 18:43:13,590 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:43:13,649 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:43:13,650 - Creating a fresh vocabulary
2023-12-09 18:43:13,651 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:43:13.651933', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:13,652 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:43:13.652012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:13,654 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:43:13,654 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:43:13,654 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:43:13.654929', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:13,659 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:43:13,659 - resetting layer weights
2023-12-09 18:43:13,660 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:43:13.660108', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:43:13,660 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:43:13.660590', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:14,680 - EPOCH 0 - PROGRESS: at 41.25% examples, 324632 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:15,682 - EPOCH 0 - PROGRESS: at 86.25% examples, 341872 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:15,939 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351583 effective words/s
2023-12-09 18:43:15,939 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351058 effective words/s', 'datetime': '2023-12-09T18:43:15.939493', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:15,939 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:43:15.939670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:43:32,574 - Processed run 1 for mu=0.65 on cuda:2. Elapsed time: 20.39 seconds
2023-12-09 18:43:34,073 - collecting all words and their counts
2023-12-09 18:43:34,073 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:43:34,133 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:43:34,133 - Creating a fresh vocabulary
2023-12-09 18:43:34,135 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:43:34.135870', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:34,135 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:43:34.135938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:34,138 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:43:34,138 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:43:34,138 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:43:34.138844', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:34,143 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:43:34,143 - resetting layer weights
2023-12-09 18:43:34,143 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:43:34.143887', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:43:34,144 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:43:34.144445', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:35,184 - EPOCH 0 - PROGRESS: at 46.25% examples, 356779 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:36,210 - EPOCH 0 - PROGRESS: at 96.25% examples, 373244 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:43:36,245 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381395 effective words/s
2023-12-09 18:43:36,245 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380783 effective words/s', 'datetime': '2023-12-09T18:43:36.245454', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:36,245 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:43:36.245856', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:43:46,063 - Processed run 1 for mu=0.7 on cuda:3. Elapsed time: 13.49 seconds
2023-12-09 18:43:47,707 - collecting all words and their counts
2023-12-09 18:43:47,707 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:43:47,793 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:43:47,793 - Creating a fresh vocabulary
2023-12-09 18:43:47,795 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:43:47.795648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:47,795 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:43:47.795718', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:47,798 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:43:47,798 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:43:47,798 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:43:47.798573', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:43:47,803 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:43:47,803 - resetting layer weights
2023-12-09 18:43:47,803 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:43:47.803632', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:43:47,804 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:43:47.804193', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:48,835 - EPOCH 0 - PROGRESS: at 46.25% examples, 359472 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:43:49,848 - EPOCH 0 - PROGRESS: at 96.25% examples, 377067 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:43:49,865 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 388504 effective words/s
2023-12-09 18:43:49,865 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 388062 effective words/s', 'datetime': '2023-12-09T18:43:49.865796', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:43:49,866 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:43:49.866372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:43:59,167 - Processed run 1 for mu=0.75 on cuda:4. Elapsed time: 13.10 seconds
2023-12-09 18:44:00,973 - collecting all words and their counts
2023-12-09 18:44:00,973 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:44:01,033 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:44:01,033 - Creating a fresh vocabulary
2023-12-09 18:44:01,035 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:44:01.035445', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:01,035 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:44:01.035515', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:01,038 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:44:01,038 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:44:01,038 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:44:01.038476', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:01,043 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:44:01,043 - resetting layer weights
2023-12-09 18:44:01,043 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:44:01.043587', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:44:01,044 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:44:01.044059', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:02,082 - EPOCH 0 - PROGRESS: at 46.25% examples, 357390 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:44:03,099 - EPOCH 0 - PROGRESS: at 96.25% examples, 375166 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:44:03,147 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380897 effective words/s
2023-12-09 18:44:03,147 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380275 effective words/s', 'datetime': '2023-12-09T18:44:03.147872', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:03,148 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:44:03.148043', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:44:13,576 - Processed run 1 for mu=0.8 on cuda:1. Elapsed time: 14.41 seconds
2023-12-09 18:44:15,401 - collecting all words and their counts
2023-12-09 18:44:15,401 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:44:15,461 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:44:15,461 - Creating a fresh vocabulary
2023-12-09 18:44:15,463 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:44:15.463813', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:15,463 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:44:15.463899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:15,466 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:44:15,466 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:44:15,466 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:44:15.466778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:15,471 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:44:15,471 - resetting layer weights
2023-12-09 18:44:15,471 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:44:15.471921', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:44:15,472 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:44:15.472382', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:16,513 - EPOCH 0 - PROGRESS: at 41.25% examples, 317802 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:44:17,523 - EPOCH 0 - PROGRESS: at 87.50% examples, 341817 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:44:17,750 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351617 effective words/s
2023-12-09 18:44:17,751 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351096 effective words/s', 'datetime': '2023-12-09T18:44:17.751034', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:17,751 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:44:17.751216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:44:30,564 - Processed run 1 for mu=0.85 on cuda:2. Elapsed time: 16.99 seconds
2023-12-09 18:44:32,615 - collecting all words and their counts
2023-12-09 18:44:32,615 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:44:32,675 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:44:32,675 - Creating a fresh vocabulary
2023-12-09 18:44:32,677 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:44:32.677225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:32,677 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:44:32.677303', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:32,680 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:44:32,680 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:44:32,680 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:44:32.680191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:32,684 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:44:32,685 - resetting layer weights
2023-12-09 18:44:32,685 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:44:32.685382', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:44:32,685 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:44:32.685734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:33,695 - EPOCH 0 - PROGRESS: at 41.25% examples, 327882 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:44:34,695 - EPOCH 0 - PROGRESS: at 86.25% examples, 343809 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:44:34,972 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350352 effective words/s
2023-12-09 18:44:34,972 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349828 effective words/s', 'datetime': '2023-12-09T18:44:34.972649', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:34,972 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:44:34.972833', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:44:47,211 - Processed run 1 for mu=0.9 on cuda:3. Elapsed time: 16.65 seconds
2023-12-09 18:44:49,497 - collecting all words and their counts
2023-12-09 18:44:49,498 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:44:49,557 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:44:49,557 - Creating a fresh vocabulary
2023-12-09 18:44:49,559 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:44:49.559496', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:49,559 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:44:49.559574', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:49,562 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:44:49,562 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:44:49,562 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:44:49.562427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:44:49,567 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:44:49,567 - resetting layer weights
2023-12-09 18:44:49,567 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:44:49.567606', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:44:49,568 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:44:49.568106', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:50,590 - EPOCH 0 - PROGRESS: at 42.50% examples, 333554 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:44:51,613 - EPOCH 0 - PROGRESS: at 90.00% examples, 352574 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:44:51,821 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355505 effective words/s
2023-12-09 18:44:51,821 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354974 effective words/s', 'datetime': '2023-12-09T18:44:51.821866', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:44:51,822 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:44:51.822053', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:03,506 - Processed run 1 for mu=0.95 on cuda:4. Elapsed time: 16.29 seconds
2023-12-09 18:45:05,889 - collecting all words and their counts
2023-12-09 18:45:05,889 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:05,948 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:05,948 - Creating a fresh vocabulary
2023-12-09 18:45:05,950 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:05.950498', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:05,950 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:05.950578', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:05,953 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:05,953 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:05,953 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:05.953500', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:05,958 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:05,958 - resetting layer weights
2023-12-09 18:45:05,958 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:05.958647', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:05,959 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:05.959152', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:06,968 - EPOCH 0 - PROGRESS: at 41.25% examples, 328052 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:07,975 - EPOCH 0 - PROGRESS: at 88.75% examples, 352682 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:08,191 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358865 effective words/s
2023-12-09 18:45:08,191 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358315 effective words/s', 'datetime': '2023-12-09T18:45:08.191897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:08,192 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:08.192079', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:20,902 - Processed run 1 for mu=1.0 on cuda:1. Elapsed time: 17.39 seconds
2023-12-09 18:45:22,164 - collecting all words and their counts
2023-12-09 18:45:22,164 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:22,222 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:22,222 - Creating a fresh vocabulary
2023-12-09 18:45:22,224 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:22.224139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:22,224 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:22.224218', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:22,226 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:22,227 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:22,227 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:22.227042', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:22,231 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:22,231 - resetting layer weights
2023-12-09 18:45:22,232 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:22.232035', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:22,232 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:22.232353', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:23,256 - EPOCH 0 - PROGRESS: at 56.25% examples, 440796 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:23,818 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 505361 effective words/s
2023-12-09 18:45:23,819 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 504210 effective words/s', 'datetime': '2023-12-09T18:45:23.819065', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:23,819 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:23.819784', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:27,765 - Processed run 2 for mu=0.0 on cuda:1. Elapsed time: 6.86 seconds
2023-12-09 18:45:28,745 - collecting all words and their counts
2023-12-09 18:45:28,745 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:28,805 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:28,805 - Creating a fresh vocabulary
2023-12-09 18:45:28,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:28.807247', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:28,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:28.807312', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:28,810 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:28,810 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:28,810 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:28.810172', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:28,814 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:28,815 - resetting layer weights
2023-12-09 18:45:28,815 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:28.815346', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:28,815 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:28.815884', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:29,830 - EPOCH 0 - PROGRESS: at 41.25% examples, 326255 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:30,834 - EPOCH 0 - PROGRESS: at 86.25% examples, 342332 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:31,081 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353659 effective words/s
2023-12-09 18:45:31,081 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353127 effective words/s', 'datetime': '2023-12-09T18:45:31.081435', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:31,081 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:31.081626', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:36,447 - Processed run 2 for mu=0.05 on cuda:2. Elapsed time: 8.68 seconds
2023-12-09 18:45:37,141 - collecting all words and their counts
2023-12-09 18:45:37,141 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:37,199 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:37,200 - Creating a fresh vocabulary
2023-12-09 18:45:37,201 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:37.201954', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:37,202 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:37.202020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:37,204 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:37,204 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:37,204 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:37.204916', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:37,209 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:37,209 - resetting layer weights
2023-12-09 18:45:37,210 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:37.210045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:37,210 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:37.210446', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:38,229 - EPOCH 0 - PROGRESS: at 41.25% examples, 324883 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:39,238 - EPOCH 0 - PROGRESS: at 86.25% examples, 340791 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:39,469 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354605 effective words/s
2023-12-09 18:45:39,469 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354079 effective words/s', 'datetime': '2023-12-09T18:45:39.469901', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:39,470 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:39.470467', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:44,960 - Processed run 2 for mu=0.1 on cuda:3. Elapsed time: 8.51 seconds
2023-12-09 18:45:45,800 - collecting all words and their counts
2023-12-09 18:45:45,801 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:45,860 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:45,860 - Creating a fresh vocabulary
2023-12-09 18:45:45,862 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:45.862219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:45,862 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:45.862286', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:45,865 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:45,865 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:45,865 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:45.865126', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:45,869 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:45,869 - resetting layer weights
2023-12-09 18:45:45,870 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:45.870250', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:45,870 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:45.870489', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:46,894 - EPOCH 0 - PROGRESS: at 42.50% examples, 332950 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:45:47,958 - EPOCH 0 - PROGRESS: at 91.25% examples, 350156 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:48,100 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 359333 effective words/s
2023-12-09 18:45:48,100 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358785 effective words/s', 'datetime': '2023-12-09T18:45:48.100308', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:48,100 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:48.100813', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:45:53,419 - Processed run 2 for mu=0.15 on cuda:4. Elapsed time: 8.46 seconds
2023-12-09 18:45:54,363 - collecting all words and their counts
2023-12-09 18:45:54,363 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:45:54,428 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:45:54,428 - Creating a fresh vocabulary
2023-12-09 18:45:54,430 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:45:54.430257', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:54,430 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:45:54.430325', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:54,433 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:45:54,433 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:45:54,433 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:45:54.433197', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:45:54,437 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:45:54,437 - resetting layer weights
2023-12-09 18:45:54,438 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:45:54.438299', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:45:54,438 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:45:54.438566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:55,455 - EPOCH 0 - PROGRESS: at 41.25% examples, 325527 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:56,460 - EPOCH 0 - PROGRESS: at 86.25% examples, 341827 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:45:56,703 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353673 effective words/s
2023-12-09 18:45:56,704 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353127 effective words/s', 'datetime': '2023-12-09T18:45:56.704112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:45:56,704 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:45:56.704298', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:01,902 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 8.48 seconds
2023-12-09 18:46:02,752 - collecting all words and their counts
2023-12-09 18:46:02,752 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:02,829 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:02,829 - Creating a fresh vocabulary
2023-12-09 18:46:02,831 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:02.831745', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:02,831 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:02.831829', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:02,834 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:02,834 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:02,834 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:02.834769', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:02,839 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:02,839 - resetting layer weights
2023-12-09 18:46:02,839 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:02.839887', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:02,840 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:02.840323', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:03,877 - EPOCH 0 - PROGRESS: at 41.25% examples, 319092 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:04,888 - EPOCH 0 - PROGRESS: at 86.25% examples, 337451 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:05,118 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351622 effective words/s
2023-12-09 18:46:05,118 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351125 effective words/s', 'datetime': '2023-12-09T18:46:05.118773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:05,118 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:05.118843', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:10,351 - Processed run 2 for mu=0.25 on cuda:2. Elapsed time: 8.45 seconds
2023-12-09 18:46:11,231 - collecting all words and their counts
2023-12-09 18:46:11,231 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:11,290 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:11,290 - Creating a fresh vocabulary
2023-12-09 18:46:11,292 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:11.292618', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:11,292 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:11.292685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:11,295 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:11,295 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:11,295 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:11.295637', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:11,300 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:11,300 - resetting layer weights
2023-12-09 18:46:11,300 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:11.300823', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:11,301 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:11.301237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:12,312 - EPOCH 0 - PROGRESS: at 41.25% examples, 327337 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:13,316 - EPOCH 0 - PROGRESS: at 86.25% examples, 342918 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:13,551 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356004 effective words/s
2023-12-09 18:46:13,551 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355464 effective words/s', 'datetime': '2023-12-09T18:46:13.551899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:13,552 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:13.552075', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:20,148 - Processed run 2 for mu=0.3 on cuda:3. Elapsed time: 9.80 seconds
2023-12-09 18:46:21,109 - collecting all words and their counts
2023-12-09 18:46:21,109 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:21,187 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:21,188 - Creating a fresh vocabulary
2023-12-09 18:46:21,189 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:21.189902', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:21,189 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:21.189973', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:21,192 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:21,193 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:21,193 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:21.193085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:21,197 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:21,197 - resetting layer weights
2023-12-09 18:46:21,198 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:21.198191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:21,198 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:21.198624', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:22,210 - EPOCH 0 - PROGRESS: at 41.25% examples, 327106 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:46:23,211 - EPOCH 0 - PROGRESS: at 86.25% examples, 343303 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:23,458 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354571 effective words/s
2023-12-09 18:46:23,458 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354046 effective words/s', 'datetime': '2023-12-09T18:46:23.458287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:23,458 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:23.458467', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:29,360 - Processed run 2 for mu=0.35 on cuda:4. Elapsed time: 9.21 seconds
2023-12-09 18:46:30,425 - collecting all words and their counts
2023-12-09 18:46:30,425 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:30,486 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:30,486 - Creating a fresh vocabulary
2023-12-09 18:46:30,488 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:30.488084', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:30,488 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:30.488150', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:30,490 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:30,490 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:30,491 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:30.491040', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:30,495 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:30,495 - resetting layer weights
2023-12-09 18:46:30,496 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:30.496060', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:30,496 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:30.496561', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:31,534 - EPOCH 0 - PROGRESS: at 42.50% examples, 328572 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:32,535 - EPOCH 0 - PROGRESS: at 88.75% examples, 348821 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:46:32,749 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355594 effective words/s
2023-12-09 18:46:32,749 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355067 effective words/s', 'datetime': '2023-12-09T18:46:32.749733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:32,750 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:32.750312', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:38,327 - Processed run 2 for mu=0.4 on cuda:1. Elapsed time: 8.97 seconds
2023-12-09 18:46:39,405 - collecting all words and their counts
2023-12-09 18:46:39,406 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:39,466 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:39,466 - Creating a fresh vocabulary
2023-12-09 18:46:39,468 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:39.468093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:39,468 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:39.468168', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:39,470 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:39,470 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:39,471 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:39.471015', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:39,475 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:39,475 - resetting layer weights
2023-12-09 18:46:39,476 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:39.476194', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:39,476 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:39.476613', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:40,489 - EPOCH 0 - PROGRESS: at 41.25% examples, 326652 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:41,500 - EPOCH 0 - PROGRESS: at 86.25% examples, 341441 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:41,741 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353732 effective words/s
2023-12-09 18:46:41,741 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353220 effective words/s', 'datetime': '2023-12-09T18:46:41.741566', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:41,742 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:41.742165', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:48,675 - Processed run 2 for mu=0.45 on cuda:2. Elapsed time: 10.35 seconds
2023-12-09 18:46:49,785 - collecting all words and their counts
2023-12-09 18:46:49,785 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:46:49,847 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:46:49,847 - Creating a fresh vocabulary
2023-12-09 18:46:49,849 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:46:49.849692', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:49,849 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:46:49.849764', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:49,852 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:46:49,852 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:46:49,852 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:46:49.852644', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:46:49,857 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:46:49,857 - resetting layer weights
2023-12-09 18:46:49,857 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:46:49.857747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:46:49,857 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:46:49.857965', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:50,874 - EPOCH 0 - PROGRESS: at 42.50% examples, 335472 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:51,917 - EPOCH 0 - PROGRESS: at 90.00% examples, 350146 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:46:52,114 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355020 effective words/s
2023-12-09 18:46:52,115 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354509 effective words/s', 'datetime': '2023-12-09T18:46:52.115013', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:46:52,115 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:46:52.115190', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:46:59,204 - Processed run 2 for mu=0.5 on cuda:3. Elapsed time: 10.53 seconds
2023-12-09 18:47:00,449 - collecting all words and their counts
2023-12-09 18:47:00,449 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:47:00,509 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:47:00,509 - Creating a fresh vocabulary
2023-12-09 18:47:00,511 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:47:00.511789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:00,511 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:47:00.511868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:00,514 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:47:00,514 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:47:00,514 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:47:00.514808', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:00,519 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:47:00,519 - resetting layer weights
2023-12-09 18:47:00,520 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:47:00.520014', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:47:00,520 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:47:00.520421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:01,531 - EPOCH 0 - PROGRESS: at 42.50% examples, 337208 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:47:02,538 - EPOCH 0 - PROGRESS: at 88.75% examples, 352394 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:02,778 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354805 effective words/s
2023-12-09 18:47:02,778 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354284 effective words/s', 'datetime': '2023-12-09T18:47:02.778582', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:02,778 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:47:02.778838', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:47:09,897 - Processed run 2 for mu=0.55 on cuda:4. Elapsed time: 10.69 seconds
2023-12-09 18:47:11,293 - collecting all words and their counts
2023-12-09 18:47:11,293 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:47:11,353 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:47:11,353 - Creating a fresh vocabulary
2023-12-09 18:47:11,355 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:47:11.355910', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:11,355 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:47:11.355972', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:11,358 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:47:11,358 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:47:11,358 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:47:11.358814', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:11,363 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:47:11,363 - resetting layer weights
2023-12-09 18:47:11,363 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:47:11.363848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:47:11,364 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:47:11.364466', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:12,373 - EPOCH 0 - PROGRESS: at 41.25% examples, 328234 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:47:13,375 - EPOCH 0 - PROGRESS: at 88.75% examples, 353678 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:13,626 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354233 effective words/s
2023-12-09 18:47:13,626 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353702 effective words/s', 'datetime': '2023-12-09T18:47:13.626334', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:13,626 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:47:13.626511', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:47:20,981 - Processed run 2 for mu=0.6 on cuda:1. Elapsed time: 11.08 seconds
2023-12-09 18:47:22,382 - collecting all words and their counts
2023-12-09 18:47:22,382 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:47:22,446 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:47:22,446 - Creating a fresh vocabulary
2023-12-09 18:47:22,448 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:47:22.448281', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:22,448 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:47:22.448357', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:22,451 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:47:22,451 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:47:22,451 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:47:22.451223', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:22,455 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:47:22,455 - resetting layer weights
2023-12-09 18:47:22,456 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:47:22.456307', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:47:22,456 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:47:22.456754', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:23,474 - EPOCH 0 - PROGRESS: at 41.25% examples, 325412 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:47:24,478 - EPOCH 0 - PROGRESS: at 86.25% examples, 341859 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:24,735 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351569 effective words/s
2023-12-09 18:47:24,735 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351044 effective words/s', 'datetime': '2023-12-09T18:47:24.735761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:24,736 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:47:24.735998', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:47:41,135 - Processed run 2 for mu=0.65 on cuda:2. Elapsed time: 20.15 seconds
2023-12-09 18:47:42,646 - collecting all words and their counts
2023-12-09 18:47:42,646 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:47:42,706 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:47:42,706 - Creating a fresh vocabulary
2023-12-09 18:47:42,708 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:47:42.708214', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:42,708 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:47:42.708296', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:42,711 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:47:42,711 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:47:42,711 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:47:42.711125', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:42,715 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:47:42,715 - resetting layer weights
2023-12-09 18:47:42,716 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:47:42.716257', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:47:42,716 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:47:42.716789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:43,752 - EPOCH 0 - PROGRESS: at 41.25% examples, 319680 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:44,763 - EPOCH 0 - PROGRESS: at 87.50% examples, 342598 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:45,012 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348930 effective words/s
2023-12-09 18:47:45,012 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348418 effective words/s', 'datetime': '2023-12-09T18:47:45.012953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:45,013 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:47:45.013139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:47:53,575 - Processed run 2 for mu=0.7 on cuda:3. Elapsed time: 12.44 seconds
2023-12-09 18:47:55,225 - collecting all words and their counts
2023-12-09 18:47:55,225 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:47:55,286 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:47:55,286 - Creating a fresh vocabulary
2023-12-09 18:47:55,288 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:47:55.288435', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:55,288 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:47:55.288518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:55,291 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:47:55,291 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:47:55,291 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:47:55.291432', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:47:55,296 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:47:55,296 - resetting layer weights
2023-12-09 18:47:55,296 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:47:55.296448', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:47:55,296 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:47:55.296909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:56,322 - EPOCH 0 - PROGRESS: at 41.25% examples, 322888 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:57,324 - EPOCH 0 - PROGRESS: at 87.50% examples, 345733 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:47:57,579 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351030 effective words/s
2023-12-09 18:47:57,579 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350497 effective words/s', 'datetime': '2023-12-09T18:47:57.579452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:47:57,579 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:47:57.579629', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:48:06,730 - Processed run 2 for mu=0.75 on cuda:4. Elapsed time: 13.15 seconds
2023-12-09 18:48:08,516 - collecting all words and their counts
2023-12-09 18:48:08,516 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:48:08,576 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:48:08,576 - Creating a fresh vocabulary
2023-12-09 18:48:08,578 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:48:08.578833', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:08,578 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:48:08.578913', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:08,581 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:48:08,581 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:48:08,581 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:48:08.581855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:08,586 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:48:08,586 - resetting layer weights
2023-12-09 18:48:08,586 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:48:08.586899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:48:08,587 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:48:08.587305', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:09,623 - EPOCH 0 - PROGRESS: at 41.25% examples, 319401 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:48:10,630 - EPOCH 0 - PROGRESS: at 90.00% examples, 352987 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:48:10,842 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355271 effective words/s
2023-12-09 18:48:10,842 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354723 effective words/s', 'datetime': '2023-12-09T18:48:10.842665', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:10,842 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:48:10.842844', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:48:22,240 - Processed run 2 for mu=0.8 on cuda:1. Elapsed time: 15.51 seconds
2023-12-09 18:48:24,167 - collecting all words and their counts
2023-12-09 18:48:24,167 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:48:24,227 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:48:24,227 - Creating a fresh vocabulary
2023-12-09 18:48:24,229 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:48:24.229511', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:24,229 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:48:24.229598', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:24,232 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:48:24,232 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:48:24,232 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:48:24.232507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:24,237 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:48:24,237 - resetting layer weights
2023-12-09 18:48:24,237 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:48:24.237635', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:48:24,238 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:48:24.238052', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:25,241 - EPOCH 0 - PROGRESS: at 41.25% examples, 329755 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:48:26,265 - EPOCH 0 - PROGRESS: at 87.50% examples, 345814 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:48:26,512 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352153 effective words/s
2023-12-09 18:48:26,513 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351640 effective words/s', 'datetime': '2023-12-09T18:48:26.513183', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:26,513 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:48:26.513375', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:48:38,784 - Processed run 2 for mu=0.85 on cuda:2. Elapsed time: 16.54 seconds
2023-12-09 18:48:40,875 - collecting all words and their counts
2023-12-09 18:48:40,875 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:48:40,935 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:48:40,935 - Creating a fresh vocabulary
2023-12-09 18:48:40,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:48:40.937227', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:40,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:48:40.937302', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:40,940 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:48:40,940 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:48:40,940 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:48:40.940234', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:40,944 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:48:40,945 - resetting layer weights
2023-12-09 18:48:40,945 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:48:40.945321', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:48:40,945 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:48:40.945692', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:41,967 - EPOCH 0 - PROGRESS: at 41.25% examples, 323995 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:48:42,977 - EPOCH 0 - PROGRESS: at 88.75% examples, 350019 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:48:43,207 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354161 effective words/s
2023-12-09 18:48:43,208 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353619 effective words/s', 'datetime': '2023-12-09T18:48:43.208089', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:43,208 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:48:43.208282', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:48:55,348 - Processed run 2 for mu=0.9 on cuda:3. Elapsed time: 16.56 seconds
2023-12-09 18:48:57,583 - collecting all words and their counts
2023-12-09 18:48:57,583 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:48:57,643 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:48:57,643 - Creating a fresh vocabulary
2023-12-09 18:48:57,645 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:48:57.645658', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:57,645 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:48:57.645734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:57,648 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:48:57,648 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:48:57,648 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:48:57.648595', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:48:57,653 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:48:57,653 - resetting layer weights
2023-12-09 18:48:57,653 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:48:57.653728', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:48:57,654 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:48:57.654089', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:58,681 - EPOCH 0 - PROGRESS: at 41.25% examples, 322213 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:48:59,685 - EPOCH 0 - PROGRESS: at 87.50% examples, 345093 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:48:59,940 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350313 effective words/s
2023-12-09 18:48:59,941 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349806 effective words/s', 'datetime': '2023-12-09T18:48:59.941147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:48:59,941 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:48:59.941287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:49:12,968 - Processed run 2 for mu=0.95 on cuda:4. Elapsed time: 17.62 seconds
2023-12-09 18:49:15,352 - collecting all words and their counts
2023-12-09 18:49:15,352 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:49:15,412 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:49:15,412 - Creating a fresh vocabulary
2023-12-09 18:49:15,414 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:49:15.414915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:15,415 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:49:15.415002', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:15,418 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:49:15,418 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:49:15,418 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:49:15.418105', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:15,424 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:49:15,424 - resetting layer weights
2023-12-09 18:49:15,424 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:49:15.424501', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:49:15,424 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:49:15.424716', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:16,434 - EPOCH 0 - PROGRESS: at 42.50% examples, 337763 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:17,435 - EPOCH 0 - PROGRESS: at 88.75% examples, 353744 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:49:17,690 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353609 effective words/s
2023-12-09 18:49:17,690 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353070 effective words/s', 'datetime': '2023-12-09T18:49:17.690669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:17,690 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:49:17.690916', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:49:31,533 - Processed run 2 for mu=1.0 on cuda:1. Elapsed time: 18.56 seconds
2023-12-09 18:49:32,415 - collecting all words and their counts
2023-12-09 18:49:32,415 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:49:32,474 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:49:32,474 - Creating a fresh vocabulary
2023-12-09 18:49:32,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:49:32.476763', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:32,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:49:32.476846', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:32,479 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:49:32,479 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:49:32,479 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:49:32.479741', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:32,484 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:49:32,484 - resetting layer weights
2023-12-09 18:49:32,484 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:49:32.484891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:49:32,485 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:49:32.485246', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:33,504 - EPOCH 0 - PROGRESS: at 56.25% examples, 442761 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:34,075 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 503993 effective words/s
2023-12-09 18:49:34,076 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 502911 effective words/s', 'datetime': '2023-12-09T18:49:34.076062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:34,076 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:49:34.076250', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:49:38,017 - Processed run 3 for mu=0.0 on cuda:1. Elapsed time: 6.48 seconds
2023-12-09 18:49:38,974 - collecting all words and their counts
2023-12-09 18:49:38,975 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:49:39,034 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:49:39,034 - Creating a fresh vocabulary
2023-12-09 18:49:39,036 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:49:39.036151', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:39,036 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:49:39.036216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:39,039 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:49:39,039 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:49:39,039 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:49:39.039100', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:39,043 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:49:39,043 - resetting layer weights
2023-12-09 18:49:39,044 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:49:39.044247', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:49:39,044 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:49:39.044676', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:40,082 - EPOCH 0 - PROGRESS: at 41.25% examples, 318982 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:49:41,087 - EPOCH 0 - PROGRESS: at 86.25% examples, 338251 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:41,341 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348863 effective words/s
2023-12-09 18:49:41,341 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348338 effective words/s', 'datetime': '2023-12-09T18:49:41.341373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:41,341 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:49:41.341551', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:49:45,804 - Processed run 3 for mu=0.05 on cuda:2. Elapsed time: 7.79 seconds
2023-12-09 18:49:46,714 - collecting all words and their counts
2023-12-09 18:49:46,714 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:49:46,773 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:49:46,773 - Creating a fresh vocabulary
2023-12-09 18:49:46,776 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:49:46.776200', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:46,776 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:49:46.776289', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:46,779 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:49:46,779 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:49:46,779 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:49:46.779414', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:46,784 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:49:46,784 - resetting layer weights
2023-12-09 18:49:46,784 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:49:46.784790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:49:46,785 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:49:46.785053', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:47,790 - EPOCH 0 - PROGRESS: at 41.25% examples, 329363 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:48,795 - EPOCH 0 - PROGRESS: at 88.75% examples, 353786 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:49,018 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358635 effective words/s
2023-12-09 18:49:49,019 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 358097 effective words/s', 'datetime': '2023-12-09T18:49:49.019189', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:49,019 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:49:49.019431', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:49:53,852 - Processed run 3 for mu=0.1 on cuda:3. Elapsed time: 8.05 seconds
2023-12-09 18:49:54,748 - collecting all words and their counts
2023-12-09 18:49:54,748 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:49:54,807 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:49:54,807 - Creating a fresh vocabulary
2023-12-09 18:49:54,809 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:49:54.809815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:54,809 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:49:54.809899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:54,812 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:49:54,812 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:49:54,812 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:49:54.812786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:49:54,817 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:49:54,817 - resetting layer weights
2023-12-09 18:49:54,817 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:49:54.817875', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:49:54,818 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:49:54.818349', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:55,849 - EPOCH 0 - PROGRESS: at 41.25% examples, 321114 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:56,861 - EPOCH 0 - PROGRESS: at 88.75% examples, 348026 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:49:57,085 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353437 effective words/s
2023-12-09 18:49:57,085 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352906 effective words/s', 'datetime': '2023-12-09T18:49:57.085320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:49:57,085 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:49:57.085503', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:01,551 - Processed run 3 for mu=0.15 on cuda:4. Elapsed time: 7.70 seconds
2023-12-09 18:50:02,448 - collecting all words and their counts
2023-12-09 18:50:02,448 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:02,508 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:02,508 - Creating a fresh vocabulary
2023-12-09 18:50:02,510 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:02.510488', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:02,510 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:02.510554', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:02,513 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:02,513 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:02,513 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:02.513463', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:02,518 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:02,518 - resetting layer weights
2023-12-09 18:50:02,518 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:02.518590', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:02,519 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:02.519052', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:03,535 - EPOCH 0 - PROGRESS: at 41.25% examples, 325880 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:04,536 - EPOCH 0 - PROGRESS: at 88.75% examples, 352535 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:04,758 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357781 effective words/s
2023-12-09 18:50:04,758 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357220 effective words/s', 'datetime': '2023-12-09T18:50:04.758643', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:04,758 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:04.758836', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:10,702 - Processed run 3 for mu=0.2 on cuda:1. Elapsed time: 9.15 seconds
2023-12-09 18:50:11,532 - collecting all words and their counts
2023-12-09 18:50:11,532 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:11,592 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:11,592 - Creating a fresh vocabulary
2023-12-09 18:50:11,594 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:11.594871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:11,594 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:11.594938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:11,597 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:11,597 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:11,597 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:11.597834', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:11,602 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:11,602 - resetting layer weights
2023-12-09 18:50:11,602 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:11.602931', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:11,603 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:11.603378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:12,628 - EPOCH 0 - PROGRESS: at 42.50% examples, 332595 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:13,636 - EPOCH 0 - PROGRESS: at 88.75% examples, 349843 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:13,857 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355398 effective words/s
2023-12-09 18:50:13,857 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354859 effective words/s', 'datetime': '2023-12-09T18:50:13.857863', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:13,858 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:13.858046', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:19,319 - Processed run 3 for mu=0.25 on cuda:2. Elapsed time: 8.62 seconds
2023-12-09 18:50:20,220 - collecting all words and their counts
2023-12-09 18:50:20,220 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:20,280 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:20,281 - Creating a fresh vocabulary
2023-12-09 18:50:20,282 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:20.282893', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:20,282 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:20.282960', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:20,285 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:20,285 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:20,285 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:20.285842', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:20,290 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:20,290 - resetting layer weights
2023-12-09 18:50:20,291 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:20.291041', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:20,291 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:20.291463', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:21,317 - EPOCH 0 - PROGRESS: at 41.25% examples, 322676 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:22,318 - EPOCH 0 - PROGRESS: at 85.00% examples, 336071 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:22,622 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 343679 effective words/s
2023-12-09 18:50:22,622 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 343174 effective words/s', 'datetime': '2023-12-09T18:50:22.622711', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:22,622 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:22.622891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:28,852 - Processed run 3 for mu=0.3 on cuda:3. Elapsed time: 9.53 seconds
2023-12-09 18:50:29,739 - collecting all words and their counts
2023-12-09 18:50:29,739 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:29,799 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:29,799 - Creating a fresh vocabulary
2023-12-09 18:50:29,801 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:29.801895', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:29,801 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:29.801973', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:29,804 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:29,804 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:29,804 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:29.804879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:29,809 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:29,809 - resetting layer weights
2023-12-09 18:50:29,809 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:29.809967', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:29,810 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:29.810402', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:30,844 - EPOCH 0 - PROGRESS: at 41.25% examples, 320260 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:31,845 - EPOCH 0 - PROGRESS: at 86.25% examples, 339575 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:32,092 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351080 effective words/s
2023-12-09 18:50:32,092 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350556 effective words/s', 'datetime': '2023-12-09T18:50:32.092565', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:32,092 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:32.092816', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:39,201 - Processed run 3 for mu=0.35 on cuda:4. Elapsed time: 10.35 seconds
2023-12-09 18:50:40,206 - collecting all words and their counts
2023-12-09 18:50:40,206 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:40,266 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:40,266 - Creating a fresh vocabulary
2023-12-09 18:50:40,268 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:40.268226', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:40,268 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:40.268309', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:40,271 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:40,271 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:40,271 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:40.271200', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:40,275 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:40,275 - resetting layer weights
2023-12-09 18:50:40,276 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:40.276266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:40,276 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:40.276669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:41,302 - EPOCH 0 - PROGRESS: at 41.25% examples, 322850 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:50:42,305 - EPOCH 0 - PROGRESS: at 87.50% examples, 345623 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:42,551 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352105 effective words/s
2023-12-09 18:50:42,552 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351566 effective words/s', 'datetime': '2023-12-09T18:50:42.552284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:42,552 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:42.552536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:48,207 - Processed run 3 for mu=0.4 on cuda:1. Elapsed time: 9.00 seconds
2023-12-09 18:50:49,285 - collecting all words and their counts
2023-12-09 18:50:49,286 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:49,346 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:49,346 - Creating a fresh vocabulary
2023-12-09 18:50:49,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:49.348660', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:49,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:49.348771', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:49,351 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:49,351 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:49,351 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:49.351836', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:49,356 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:49,356 - resetting layer weights
2023-12-09 18:50:49,357 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:49.357478', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:49,357 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:49.357596', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:50,383 - EPOCH 0 - PROGRESS: at 41.25% examples, 322884 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:51,391 - EPOCH 0 - PROGRESS: at 86.25% examples, 339892 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:50:51,662 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 347589 effective words/s
2023-12-09 18:50:51,663 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347055 effective words/s', 'datetime': '2023-12-09T18:50:51.663071', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:50:51,663 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:50:51.663325', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:50:58,030 - Processed run 3 for mu=0.45 on cuda:2. Elapsed time: 9.82 seconds
2023-12-09 18:50:59,296 - collecting all words and their counts
2023-12-09 18:50:59,296 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:50:59,355 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:50:59,355 - Creating a fresh vocabulary
2023-12-09 18:50:59,357 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:50:59.357777', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:59,357 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:50:59.357847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:59,360 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:50:59,360 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:50:59,360 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:50:59.360807', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:50:59,365 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:50:59,365 - resetting layer weights
2023-12-09 18:50:59,365 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:50:59.365851', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:50:59,366 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:50:59.366253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:00,390 - EPOCH 0 - PROGRESS: at 41.25% examples, 323146 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:01,391 - EPOCH 0 - PROGRESS: at 86.25% examples, 341312 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:01,650 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350659 effective words/s
2023-12-09 18:51:01,651 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350139 effective words/s', 'datetime': '2023-12-09T18:51:01.651134', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:01,651 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:01.651325', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:51:08,063 - Processed run 3 for mu=0.5 on cuda:3. Elapsed time: 10.03 seconds
2023-12-09 18:51:09,239 - collecting all words and their counts
2023-12-09 18:51:09,239 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:51:09,299 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:51:09,299 - Creating a fresh vocabulary
2023-12-09 18:51:09,301 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:51:09.301948', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:09,302 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:51:09.302039', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:09,305 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:51:09,305 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:51:09,305 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:51:09.305547', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:09,310 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:51:09,310 - resetting layer weights
2023-12-09 18:51:09,311 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:51:09.311636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:51:09,311 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:51:09.311750', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:10,333 - EPOCH 0 - PROGRESS: at 41.25% examples, 324071 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:11,339 - EPOCH 0 - PROGRESS: at 86.25% examples, 340959 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:11,598 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350376 effective words/s
2023-12-09 18:51:11,598 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349854 effective words/s', 'datetime': '2023-12-09T18:51:11.598746', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:11,598 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:11.598867', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:51:18,604 - Processed run 3 for mu=0.55 on cuda:4. Elapsed time: 10.54 seconds
2023-12-09 18:51:20,045 - collecting all words and their counts
2023-12-09 18:51:20,045 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:51:20,106 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:51:20,106 - Creating a fresh vocabulary
2023-12-09 18:51:20,108 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:51:20.108338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:20,108 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:51:20.108399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:20,111 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:51:20,111 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:51:20,111 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:51:20.111228', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:20,115 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:51:20,115 - resetting layer weights
2023-12-09 18:51:20,116 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:51:20.116212', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:51:20,116 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:51:20.116700', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:21,143 - EPOCH 0 - PROGRESS: at 41.25% examples, 322421 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:22,154 - EPOCH 0 - PROGRESS: at 86.25% examples, 339185 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:22,399 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350913 effective words/s
2023-12-09 18:51:22,399 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350390 effective words/s', 'datetime': '2023-12-09T18:51:22.399947', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:22,400 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:22.400121', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:51:30,546 - Processed run 3 for mu=0.6 on cuda:1. Elapsed time: 11.94 seconds
2023-12-09 18:51:32,014 - collecting all words and their counts
2023-12-09 18:51:32,014 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:51:32,075 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:51:32,075 - Creating a fresh vocabulary
2023-12-09 18:51:32,077 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:51:32.077840', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:32,077 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:51:32.077910', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:32,080 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:51:32,080 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:51:32,080 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:51:32.080897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:32,085 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:51:32,085 - resetting layer weights
2023-12-09 18:51:32,086 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:51:32.086062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:51:32,086 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:51:32.086552', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:33,109 - EPOCH 0 - PROGRESS: at 41.25% examples, 323652 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:34,124 - EPOCH 0 - PROGRESS: at 86.25% examples, 339055 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:34,381 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349096 effective words/s
2023-12-09 18:51:34,381 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348569 effective words/s', 'datetime': '2023-12-09T18:51:34.381722', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:34,381 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:34.381912', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:51:41,947 - Processed run 3 for mu=0.65 on cuda:2. Elapsed time: 11.40 seconds
2023-12-09 18:51:43,463 - collecting all words and their counts
2023-12-09 18:51:43,463 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:51:43,524 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:51:43,524 - Creating a fresh vocabulary
2023-12-09 18:51:43,526 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:51:43.526408', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:43,526 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:51:43.526481', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:43,529 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:51:43,529 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:51:43,529 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:51:43.529399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:43,534 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:51:43,534 - resetting layer weights
2023-12-09 18:51:43,534 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:51:43.534527', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:51:43,534 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:51:43.534813', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:44,590 - EPOCH 0 - PROGRESS: at 41.25% examples, 313473 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:45,605 - EPOCH 0 - PROGRESS: at 86.25% examples, 333766 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:45,839 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 347578 effective words/s
2023-12-09 18:51:45,839 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347063 effective words/s', 'datetime': '2023-12-09T18:51:45.839943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:45,840 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:45.840119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:51:54,244 - Processed run 3 for mu=0.7 on cuda:3. Elapsed time: 12.30 seconds
2023-12-09 18:51:55,866 - collecting all words and their counts
2023-12-09 18:51:55,867 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:51:55,927 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:51:55,927 - Creating a fresh vocabulary
2023-12-09 18:51:55,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:51:55.929622', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:55,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:51:55.929711', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:55,932 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:51:55,932 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:51:55,932 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:51:55.932641', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:51:55,937 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:51:55,937 - resetting layer weights
2023-12-09 18:51:55,937 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:51:55.937738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:51:55,938 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:51:55.938056', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:56,954 - EPOCH 0 - PROGRESS: at 41.25% examples, 325718 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:57,965 - EPOCH 0 - PROGRESS: at 87.50% examples, 345776 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:51:58,214 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351986 effective words/s
2023-12-09 18:51:58,214 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351463 effective words/s', 'datetime': '2023-12-09T18:51:58.214329', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:51:58,214 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:51:58.214513', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:52:07,009 - Processed run 3 for mu=0.75 on cuda:4. Elapsed time: 12.76 seconds
2023-12-09 18:52:08,828 - collecting all words and their counts
2023-12-09 18:52:08,828 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:52:08,888 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:52:08,888 - Creating a fresh vocabulary
2023-12-09 18:52:08,890 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:52:08.890698', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:08,890 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:52:08.890779', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:08,893 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:52:08,893 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:52:08,893 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:52:08.893673', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:08,898 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:52:08,898 - resetting layer weights
2023-12-09 18:52:08,898 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:52:08.898830', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:52:08,899 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:52:08.899293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:52:09,930 - EPOCH 0 - PROGRESS: at 41.25% examples, 321131 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:52:10,971 - EPOCH 0 - PROGRESS: at 87.50% examples, 338353 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:52:11,209 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 346769 effective words/s
2023-12-09 18:52:11,209 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 346260 effective words/s', 'datetime': '2023-12-09T18:52:11.209769', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:52:11,209 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:52:11.209957', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:52:28,812 - Processed run 3 for mu=0.8 on cuda:1. Elapsed time: 21.80 seconds
2023-12-09 18:52:30,683 - collecting all words and their counts
2023-12-09 18:52:30,683 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:52:30,744 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:52:30,744 - Creating a fresh vocabulary
2023-12-09 18:52:30,746 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:52:30.746189', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:30,746 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:52:30.746255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:30,749 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:52:30,749 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:52:30,749 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:52:30.749171', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:52:30,753 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:52:30,753 - resetting layer weights
2023-12-09 18:52:30,754 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:52:30.754284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:52:30,754 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:52:30.754724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:52:31,760 - EPOCH 0 - PROGRESS: at 41.25% examples, 329068 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:52:32,765 - EPOCH 0 - PROGRESS: at 86.25% examples, 343645 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:52:33,014 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354450 effective words/s
2023-12-09 18:52:33,015 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353918 effective words/s', 'datetime': '2023-12-09T18:52:33.015208', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:52:33,015 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:52:33.015387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:52:58,062 - Processed run 3 for mu=0.85 on cuda:2. Elapsed time: 29.25 seconds
2023-12-09 18:53:00,152 - collecting all words and their counts
2023-12-09 18:53:00,152 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:53:00,213 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:53:00,213 - Creating a fresh vocabulary
2023-12-09 18:53:00,215 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:53:00.215134', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:00,215 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:53:00.215218', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:00,218 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:53:00,218 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:53:00,218 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:53:00.218177', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:00,223 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:53:00,223 - resetting layer weights
2023-12-09 18:53:00,223 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:53:00.223415', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:53:00,224 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:53:00.224053', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:01,255 - EPOCH 0 - PROGRESS: at 41.25% examples, 320924 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:02,256 - EPOCH 0 - PROGRESS: at 87.50% examples, 344918 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:02,510 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350347 effective words/s
2023-12-09 18:53:02,511 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349827 effective words/s', 'datetime': '2023-12-09T18:53:02.510973', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:02,511 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:53:02.511164', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:53:24,221 - Processed run 3 for mu=0.9 on cuda:3. Elapsed time: 26.16 seconds
2023-12-09 18:53:26,406 - collecting all words and their counts
2023-12-09 18:53:26,406 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:53:26,467 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:53:26,467 - Creating a fresh vocabulary
2023-12-09 18:53:26,469 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:53:26.469918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:26,470 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:53:26.469994', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:26,472 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:53:26,472 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:53:26,472 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:53:26.472979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:26,477 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:53:26,477 - resetting layer weights
2023-12-09 18:53:26,478 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:53:26.478255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:53:26,478 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:53:26.478663', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:27,503 - EPOCH 0 - PROGRESS: at 41.25% examples, 322896 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:28,516 - EPOCH 0 - PROGRESS: at 86.25% examples, 339221 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:28,743 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353685 effective words/s
2023-12-09 18:53:28,744 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353147 effective words/s', 'datetime': '2023-12-09T18:53:28.744085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:28,744 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:53:28.744266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:53:39,818 - Processed run 3 for mu=0.95 on cuda:4. Elapsed time: 15.60 seconds
2023-12-09 18:53:42,247 - collecting all words and their counts
2023-12-09 18:53:42,247 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:53:42,307 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:53:42,307 - Creating a fresh vocabulary
2023-12-09 18:53:42,309 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:53:42.309843', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:42,309 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:53:42.309911', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:42,312 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:53:42,312 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:53:42,312 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:53:42.312852', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:42,317 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:53:42,317 - resetting layer weights
2023-12-09 18:53:42,317 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:53:42.317901', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:53:42,318 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:53:42.318355', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:43,327 - EPOCH 0 - PROGRESS: at 41.25% examples, 328198 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:44,342 - EPOCH 0 - PROGRESS: at 87.50% examples, 346363 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:44,576 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354807 effective words/s
2023-12-09 18:53:44,576 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354294 effective words/s', 'datetime': '2023-12-09T18:53:44.576423', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:44,576 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:53:44.576507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:53:55,986 - Processed run 3 for mu=1.0 on cuda:1. Elapsed time: 16.17 seconds
2023-12-09 18:53:56,902 - collecting all words and their counts
2023-12-09 18:53:56,902 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:53:56,961 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:53:56,961 - Creating a fresh vocabulary
2023-12-09 18:53:56,963 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:53:56.963273', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:56,963 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:53:56.963347', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:56,966 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:53:56,966 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:53:56,966 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:53:56.966225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:53:56,971 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:53:56,971 - resetting layer weights
2023-12-09 18:53:56,971 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:53:56.971396', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:53:56,971 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:53:56.971868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:57,979 - EPOCH 0 - PROGRESS: at 60.00% examples, 477922 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:53:58,503 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 523244 effective words/s
2023-12-09 18:53:58,504 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 522093 effective words/s', 'datetime': '2023-12-09T18:53:58.504236', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:53:58,504 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:53:58.504421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:02,547 - Processed run 4 for mu=0.0 on cuda:1. Elapsed time: 6.56 seconds
2023-12-09 18:54:03,731 - collecting all words and their counts
2023-12-09 18:54:03,731 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:03,791 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:03,791 - Creating a fresh vocabulary
2023-12-09 18:54:03,793 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:03.793648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:03,793 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:03.793728', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:03,796 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:03,796 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:03,796 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:03.796550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:03,801 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:03,801 - resetting layer weights
2023-12-09 18:54:03,801 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:03.801651', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:03,802 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:03.801998', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:04,850 - EPOCH 0 - PROGRESS: at 46.25% examples, 353926 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:05,870 - EPOCH 0 - PROGRESS: at 96.25% examples, 372908 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:05,893 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383025 effective words/s
2023-12-09 18:54:05,894 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382425 effective words/s', 'datetime': '2023-12-09T18:54:05.893980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:05,894 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:05.894149', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:10,653 - Processed run 4 for mu=0.05 on cuda:2. Elapsed time: 8.11 seconds
2023-12-09 18:54:11,424 - collecting all words and their counts
2023-12-09 18:54:11,424 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:11,484 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:11,485 - Creating a fresh vocabulary
2023-12-09 18:54:11,487 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:11.486995', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:11,487 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:11.487075', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:11,489 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:11,490 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:11,490 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:11.490062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:11,494 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:11,494 - resetting layer weights
2023-12-09 18:54:11,495 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:11.495329', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:11,495 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:11.495722', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:12,533 - EPOCH 0 - PROGRESS: at 46.25% examples, 357771 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:13,548 - EPOCH 0 - PROGRESS: at 96.25% examples, 375708 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:13,584 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383541 effective words/s
2023-12-09 18:54:13,584 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382934 effective words/s', 'datetime': '2023-12-09T18:54:13.584928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:13,585 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:13.585095', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:18,426 - Processed run 4 for mu=0.1 on cuda:3. Elapsed time: 7.77 seconds
2023-12-09 18:54:19,272 - collecting all words and their counts
2023-12-09 18:54:19,273 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:19,331 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:19,331 - Creating a fresh vocabulary
2023-12-09 18:54:19,333 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:19.333699', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:19,333 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:19.333780', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:19,336 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:19,336 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:19,336 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:19.336653', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:19,341 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:19,341 - resetting layer weights
2023-12-09 18:54:19,341 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:19.341737', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:19,342 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:19.342200', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:20,388 - EPOCH 0 - PROGRESS: at 46.25% examples, 354650 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:21,414 - EPOCH 0 - PROGRESS: at 96.25% examples, 372063 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:21,429 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383887 effective words/s
2023-12-09 18:54:21,429 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383281 effective words/s', 'datetime': '2023-12-09T18:54:21.429496', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:21,429 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:21.429575', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:26,023 - Processed run 4 for mu=0.15 on cuda:4. Elapsed time: 7.60 seconds
2023-12-09 18:54:26,912 - collecting all words and their counts
2023-12-09 18:54:26,912 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:26,970 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:26,971 - Creating a fresh vocabulary
2023-12-09 18:54:26,972 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:26.972960', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:26,973 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:26.973030', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:26,975 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:26,975 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:26,975 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:26.975888', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:26,980 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:26,980 - resetting layer weights
2023-12-09 18:54:26,981 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:26.981035', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:26,981 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:26.981473', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:28,030 - EPOCH 0 - PROGRESS: at 46.25% examples, 353679 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:29,049 - EPOCH 0 - PROGRESS: at 96.25% examples, 372926 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:29,061 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385120 effective words/s
2023-12-09 18:54:29,062 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384499 effective words/s', 'datetime': '2023-12-09T18:54:29.062174', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:29,062 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:29.062342', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:33,968 - Processed run 4 for mu=0.2 on cuda:1. Elapsed time: 7.94 seconds
2023-12-09 18:54:34,743 - collecting all words and their counts
2023-12-09 18:54:34,743 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:34,802 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:34,802 - Creating a fresh vocabulary
2023-12-09 18:54:34,804 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:34.804744', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:34,804 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:34.804814', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:34,807 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:34,807 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:34,807 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:34.807625', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:34,812 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:34,812 - resetting layer weights
2023-12-09 18:54:34,812 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:34.812672', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:34,813 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:34.813104', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:35,851 - EPOCH 0 - PROGRESS: at 46.25% examples, 357519 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:54:36,872 - EPOCH 0 - PROGRESS: at 96.25% examples, 374528 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:36,928 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 378805 effective words/s
2023-12-09 18:54:36,928 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 378199 effective words/s', 'datetime': '2023-12-09T18:54:36.928447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:36,928 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:36.928535', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:44,222 - Processed run 4 for mu=0.25 on cuda:2. Elapsed time: 10.25 seconds
2023-12-09 18:54:45,129 - collecting all words and their counts
2023-12-09 18:54:45,129 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:45,188 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:45,188 - Creating a fresh vocabulary
2023-12-09 18:54:45,190 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:45.190714', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:45,190 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:45.190781', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:45,193 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:45,193 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:45,193 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:45.193690', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:45,198 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:45,198 - resetting layer weights
2023-12-09 18:54:45,198 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:45.198778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:45,199 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:45.199294', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:46,245 - EPOCH 0 - PROGRESS: at 46.25% examples, 354833 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:47,272 - EPOCH 0 - PROGRESS: at 96.25% examples, 372036 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:47,287 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383728 effective words/s
2023-12-09 18:54:47,287 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383121 effective words/s', 'datetime': '2023-12-09T18:54:47.287480', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:47,287 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:47.287659', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:54:53,765 - Processed run 4 for mu=0.3 on cuda:3. Elapsed time: 9.54 seconds
2023-12-09 18:54:54,742 - collecting all words and their counts
2023-12-09 18:54:54,742 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:54:54,803 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:54:54,803 - Creating a fresh vocabulary
2023-12-09 18:54:54,805 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:54:54.805593', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:54,805 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:54:54.805683', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:54,808 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:54:54,808 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:54:54,808 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:54:54.808554', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:54:54,813 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:54:54,813 - resetting layer weights
2023-12-09 18:54:54,813 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:54:54.813785', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:54:54,814 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:54:54.814251', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:55,852 - EPOCH 0 - PROGRESS: at 46.25% examples, 357318 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:54:56,867 - EPOCH 0 - PROGRESS: at 96.25% examples, 375583 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:54:56,892 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385566 effective words/s
2023-12-09 18:54:56,892 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384944 effective words/s', 'datetime': '2023-12-09T18:54:56.892550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:54:56,893 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:54:56.893179', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:02,637 - Processed run 4 for mu=0.35 on cuda:4. Elapsed time: 8.87 seconds
2023-12-09 18:55:03,722 - collecting all words and their counts
2023-12-09 18:55:03,722 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:03,782 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:03,782 - Creating a fresh vocabulary
2023-12-09 18:55:03,784 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:03.784697', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:03,784 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:03.784763', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:03,787 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:03,787 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:03,787 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:03.787603', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:03,792 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:03,792 - resetting layer weights
2023-12-09 18:55:03,792 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:03.792646', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:03,793 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:03.793091', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:04,846 - EPOCH 0 - PROGRESS: at 46.25% examples, 352171 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:55:05,881 - EPOCH 0 - PROGRESS: at 96.25% examples, 369265 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:05,913 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 377883 effective words/s
2023-12-09 18:55:05,913 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 377302 effective words/s', 'datetime': '2023-12-09T18:55:05.913463', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:05,913 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:05.913542', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:11,575 - Processed run 4 for mu=0.4 on cuda:1. Elapsed time: 8.94 seconds
2023-12-09 18:55:12,662 - collecting all words and their counts
2023-12-09 18:55:12,662 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:12,723 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:12,723 - Creating a fresh vocabulary
2023-12-09 18:55:12,725 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:12.725690', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:12,725 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:12.725762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:12,728 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:12,728 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:12,728 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:12.728657', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:12,733 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:12,733 - resetting layer weights
2023-12-09 18:55:12,733 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:12.733821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:12,734 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:12.734301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:13,782 - EPOCH 0 - PROGRESS: at 46.25% examples, 354058 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:55:14,810 - EPOCH 0 - PROGRESS: at 96.25% examples, 371361 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:14,827 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382754 effective words/s
2023-12-09 18:55:14,827 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382139 effective words/s', 'datetime': '2023-12-09T18:55:14.827853', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:14,828 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:14.828020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:21,567 - Processed run 4 for mu=0.45 on cuda:2. Elapsed time: 9.99 seconds
2023-12-09 18:55:22,687 - collecting all words and their counts
2023-12-09 18:55:22,687 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:22,747 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:22,748 - Creating a fresh vocabulary
2023-12-09 18:55:22,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:22.749911', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:22,749 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:22.749975', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:22,752 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:22,752 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:22,752 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:22.752821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:22,757 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:22,757 - resetting layer weights
2023-12-09 18:55:22,757 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:22.757913', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:22,758 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:22.758399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:23,811 - EPOCH 0 - PROGRESS: at 46.25% examples, 352359 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:55:24,827 - EPOCH 0 - PROGRESS: at 96.25% examples, 372658 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:24,850 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382961 effective words/s
2023-12-09 18:55:24,850 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382375 effective words/s', 'datetime': '2023-12-09T18:55:24.850655', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:24,850 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:24.850821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:31,158 - Processed run 4 for mu=0.5 on cuda:3. Elapsed time: 9.59 seconds
2023-12-09 18:55:32,445 - collecting all words and their counts
2023-12-09 18:55:32,445 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:32,505 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:32,505 - Creating a fresh vocabulary
2023-12-09 18:55:32,507 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:32.507273', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:32,507 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:32.507352', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:32,510 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:32,510 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:32,510 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:32.510221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:32,514 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:32,514 - resetting layer weights
2023-12-09 18:55:32,515 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:32.515317', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:32,515 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:32.515815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:33,553 - EPOCH 0 - PROGRESS: at 46.25% examples, 357598 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:55:34,573 - EPOCH 0 - PROGRESS: at 96.25% examples, 374807 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:34,608 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382949 effective words/s
2023-12-09 18:55:34,608 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382331 effective words/s', 'datetime': '2023-12-09T18:55:34.608323', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:34,608 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:34.608551', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:40,699 - Processed run 4 for mu=0.55 on cuda:4. Elapsed time: 9.54 seconds
2023-12-09 18:55:42,098 - collecting all words and their counts
2023-12-09 18:55:42,098 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:42,158 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:42,158 - Creating a fresh vocabulary
2023-12-09 18:55:42,160 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:42.160736', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:42,160 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:42.160804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:42,163 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:42,163 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:42,163 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:42.163630', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:42,168 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:42,168 - resetting layer weights
2023-12-09 18:55:42,168 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:42.168664', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:42,169 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:42.169089', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:43,209 - EPOCH 0 - PROGRESS: at 46.25% examples, 356856 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:55:44,232 - EPOCH 0 - PROGRESS: at 96.25% examples, 373777 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:44,268 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381631 effective words/s
2023-12-09 18:55:44,268 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381014 effective words/s', 'datetime': '2023-12-09T18:55:44.268826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:44,269 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:44.268992', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:55:51,710 - Processed run 4 for mu=0.6 on cuda:1. Elapsed time: 11.01 seconds
2023-12-09 18:55:53,156 - collecting all words and their counts
2023-12-09 18:55:53,156 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:55:53,216 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:55:53,216 - Creating a fresh vocabulary
2023-12-09 18:55:53,218 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:55:53.218253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:53,218 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:55:53.218331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:53,221 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:55:53,221 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:55:53,221 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:55:53.221238', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:55:53,225 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:55:53,226 - resetting layer weights
2023-12-09 18:55:53,226 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:55:53.226345', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:55:53,226 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:55:53.226813', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:54,266 - EPOCH 0 - PROGRESS: at 46.25% examples, 356995 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:55:55,293 - EPOCH 0 - PROGRESS: at 96.25% examples, 373085 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:55:55,326 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381690 effective words/s
2023-12-09 18:55:55,326 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381071 effective words/s', 'datetime': '2023-12-09T18:55:55.326231', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:55:55,326 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:55:55.326799', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:56:06,703 - Processed run 4 for mu=0.65 on cuda:2. Elapsed time: 14.99 seconds
2023-12-09 18:56:08,335 - collecting all words and their counts
2023-12-09 18:56:08,335 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:56:08,396 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:56:08,396 - Creating a fresh vocabulary
2023-12-09 18:56:08,398 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:56:08.398218', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:08,398 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:56:08.398291', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:08,401 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:56:08,401 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:56:08,401 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:56:08.401225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:08,405 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:56:08,406 - resetting layer weights
2023-12-09 18:56:08,406 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:56:08.406339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:56:08,406 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:56:08.406790', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:09,450 - EPOCH 0 - PROGRESS: at 46.25% examples, 355648 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:56:10,492 - EPOCH 0 - PROGRESS: at 96.25% examples, 369818 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:56:10,513 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 380330 effective words/s
2023-12-09 18:56:10,513 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379706 effective words/s', 'datetime': '2023-12-09T18:56:10.513755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:10,513 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:56:10.513927', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:56:20,050 - Processed run 4 for mu=0.7 on cuda:3. Elapsed time: 13.35 seconds
2023-12-09 18:56:21,699 - collecting all words and their counts
2023-12-09 18:56:21,699 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:56:21,760 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:56:21,760 - Creating a fresh vocabulary
2023-12-09 18:56:21,762 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:56:21.762308', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:21,762 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:56:21.762381', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:21,765 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:56:21,765 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:56:21,765 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:56:21.765238', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:21,769 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:56:21,770 - resetting layer weights
2023-12-09 18:56:21,770 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:56:21.770368', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:56:21,770 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:56:21.770773', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:22,818 - EPOCH 0 - PROGRESS: at 46.25% examples, 354071 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:56:23,838 - EPOCH 0 - PROGRESS: at 96.25% examples, 372963 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:56:23,852 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384931 effective words/s
2023-12-09 18:56:23,852 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384312 effective words/s', 'datetime': '2023-12-09T18:56:23.852490', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:23,852 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:56:23.852737', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:56:33,542 - Processed run 4 for mu=0.75 on cuda:4. Elapsed time: 13.49 seconds
2023-12-09 18:56:35,307 - collecting all words and their counts
2023-12-09 18:56:35,308 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:56:35,367 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:56:35,367 - Creating a fresh vocabulary
2023-12-09 18:56:35,369 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:56:35.369604', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:35,369 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:56:35.369685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:35,372 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:56:35,372 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:56:35,372 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:56:35.372518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:35,377 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:56:35,377 - resetting layer weights
2023-12-09 18:56:35,377 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:56:35.377760', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:56:35,378 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:56:35.378187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:36,429 - EPOCH 0 - PROGRESS: at 46.25% examples, 352983 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:56:37,449 - EPOCH 0 - PROGRESS: at 96.25% examples, 372268 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:56:37,481 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 381018 effective words/s
2023-12-09 18:56:37,481 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 380405 effective words/s', 'datetime': '2023-12-09T18:56:37.481278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:37,481 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:56:37.481447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:56:48,698 - Processed run 4 for mu=0.8 on cuda:1. Elapsed time: 15.16 seconds
2023-12-09 18:56:50,646 - collecting all words and their counts
2023-12-09 18:56:50,646 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:56:50,706 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:56:50,706 - Creating a fresh vocabulary
2023-12-09 18:56:50,708 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:56:50.708855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:50,708 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:56:50.708925', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:50,711 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:56:50,711 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:56:50,711 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:56:50.711767', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:56:50,716 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:56:50,716 - resetting layer weights
2023-12-09 18:56:50,716 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:56:50.716880', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:56:50,717 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:56:50.717320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:51,746 - EPOCH 0 - PROGRESS: at 46.25% examples, 360517 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:56:52,766 - EPOCH 0 - PROGRESS: at 96.25% examples, 376340 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:56:52,791 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386251 effective words/s
2023-12-09 18:56:52,791 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385638 effective words/s', 'datetime': '2023-12-09T18:56:52.791885', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:56:52,792 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:56:52.792113', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:57:04,241 - Processed run 4 for mu=0.85 on cuda:2. Elapsed time: 15.54 seconds
2023-12-09 18:57:06,346 - collecting all words and their counts
2023-12-09 18:57:06,346 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:57:06,405 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:57:06,405 - Creating a fresh vocabulary
2023-12-09 18:57:06,407 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:57:06.407649', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:06,407 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:57:06.407712', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:06,410 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:57:06,410 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:57:06,410 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:57:06.410559', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:06,415 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:57:06,415 - resetting layer weights
2023-12-09 18:57:06,415 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:57:06.415719', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:57:06,416 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:57:06.416228', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:07,420 - EPOCH 0 - PROGRESS: at 45.00% examples, 359431 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:57:08,453 - EPOCH 0 - PROGRESS: at 95.00% examples, 373605 words/s, in_qsize 4, out_qsize 0
2023-12-09 18:57:08,541 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 376912 effective words/s
2023-12-09 18:57:08,542 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 376330 effective words/s', 'datetime': '2023-12-09T18:57:08.542096', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:08,542 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:57:08.542266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:57:22,052 - Processed run 4 for mu=0.9 on cuda:3. Elapsed time: 17.81 seconds
2023-12-09 18:57:24,241 - collecting all words and their counts
2023-12-09 18:57:24,241 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:57:24,301 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:57:24,301 - Creating a fresh vocabulary
2023-12-09 18:57:24,303 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:57:24.303154', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:24,303 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:57:24.303220', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:24,305 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:57:24,306 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:57:24,306 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:57:24.306062', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:24,310 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:57:24,310 - resetting layer weights
2023-12-09 18:57:24,311 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:57:24.311102', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:57:24,311 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:57:24.311525', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:25,347 - EPOCH 0 - PROGRESS: at 46.25% examples, 358320 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:57:26,366 - EPOCH 0 - PROGRESS: at 96.25% examples, 375350 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:57:26,399 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383709 effective words/s
2023-12-09 18:57:26,399 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383088 effective words/s', 'datetime': '2023-12-09T18:57:26.399888', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:26,400 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:57:26.400057', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:57:38,483 - Processed run 4 for mu=0.95 on cuda:4. Elapsed time: 16.43 seconds
2023-12-09 18:57:40,867 - collecting all words and their counts
2023-12-09 18:57:40,867 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:57:40,927 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:57:40,927 - Creating a fresh vocabulary
2023-12-09 18:57:40,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:57:40.929686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:40,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:57:40.929749', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:40,932 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:57:40,932 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:57:40,932 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:57:40.932600', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:40,937 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:57:40,937 - resetting layer weights
2023-12-09 18:57:40,937 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:57:40.937670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:57:40,938 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:57:40.938094', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:41,973 - EPOCH 0 - PROGRESS: at 46.25% examples, 358586 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:57:42,993 - EPOCH 0 - PROGRESS: at 96.25% examples, 375289 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:57:43,026 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383671 effective words/s
2023-12-09 18:57:43,026 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383053 effective words/s', 'datetime': '2023-12-09T18:57:43.026647', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:43,026 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:57:43.026815', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:57:54,029 - Processed run 4 for mu=1.0 on cuda:1. Elapsed time: 15.54 seconds
2023-12-09 18:57:54,859 - collecting all words and their counts
2023-12-09 18:57:54,859 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:57:54,917 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:57:54,918 - Creating a fresh vocabulary
2023-12-09 18:57:54,919 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:57:54.919908', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:54,919 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:57:54.919975', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:54,922 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:57:54,922 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:57:54,922 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:57:54.922847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:57:54,927 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:57:54,927 - resetting layer weights
2023-12-09 18:57:54,928 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:57:54.928032', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:57:54,928 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:57:54.928114', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:55,938 - EPOCH 0 - PROGRESS: at 61.25% examples, 486390 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:57:56,424 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 535865 effective words/s
2023-12-09 18:57:56,424 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 534636 effective words/s', 'datetime': '2023-12-09T18:57:56.424524', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:57:56,424 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:57:56.424717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:00,639 - Processed run 5 for mu=0.0 on cuda:1. Elapsed time: 6.61 seconds
2023-12-09 18:58:01,378 - collecting all words and their counts
2023-12-09 18:58:01,378 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:01,436 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:01,436 - Creating a fresh vocabulary
2023-12-09 18:58:01,438 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:01.438591', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:01,438 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:01.438664', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:01,441 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:01,441 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:01,441 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:01.441557', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:01,446 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:01,446 - resetting layer weights
2023-12-09 18:58:01,446 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:01.446725', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:01,447 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:01.447110', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:02,480 - EPOCH 0 - PROGRESS: at 46.25% examples, 359026 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:03,499 - EPOCH 0 - PROGRESS: at 96.25% examples, 375745 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:03,526 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385298 effective words/s
2023-12-09 18:58:03,526 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384677 effective words/s', 'datetime': '2023-12-09T18:58:03.526850', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:03,527 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:03.527016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:08,143 - Processed run 5 for mu=0.05 on cuda:2. Elapsed time: 7.50 seconds
2023-12-09 18:58:08,961 - collecting all words and their counts
2023-12-09 18:58:08,961 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:09,020 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:09,020 - Creating a fresh vocabulary
2023-12-09 18:58:09,022 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:09.022149', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:09,022 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:09.022227', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:09,024 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:09,025 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:09,025 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:09.025044', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:09,029 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:09,029 - resetting layer weights
2023-12-09 18:58:09,030 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:09.030089', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:09,030 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:09.030542', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:10,086 - EPOCH 0 - PROGRESS: at 46.25% examples, 351590 words/s, in_qsize 8, out_qsize 0
2023-12-09 18:58:11,111 - EPOCH 0 - PROGRESS: at 96.25% examples, 370562 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:11,119 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383567 effective words/s
2023-12-09 18:58:11,119 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382946 effective words/s', 'datetime': '2023-12-09T18:58:11.119682', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:11,119 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:11.119851', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:15,858 - Processed run 5 for mu=0.1 on cuda:3. Elapsed time: 7.71 seconds
2023-12-09 18:58:16,646 - collecting all words and their counts
2023-12-09 18:58:16,646 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:16,705 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:16,705 - Creating a fresh vocabulary
2023-12-09 18:58:16,707 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:16.707047', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:16,707 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:16.707125', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:16,709 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:16,709 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:16,710 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:16.710009', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:16,714 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:16,714 - resetting layer weights
2023-12-09 18:58:16,715 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:16.715162', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:16,715 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:16.715642', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:17,751 - EPOCH 0 - PROGRESS: at 46.25% examples, 358230 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:18,772 - EPOCH 0 - PROGRESS: at 96.25% examples, 374885 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:18,799 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 384556 effective words/s
2023-12-09 18:58:18,799 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 383924 effective words/s', 'datetime': '2023-12-09T18:58:18.799457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:18,799 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:18.799625', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:23,288 - Processed run 5 for mu=0.15 on cuda:4. Elapsed time: 7.43 seconds
2023-12-09 18:58:24,222 - collecting all words and their counts
2023-12-09 18:58:24,222 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:24,282 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:24,282 - Creating a fresh vocabulary
2023-12-09 18:58:24,284 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:24.284022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:24,284 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:24.284092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:24,286 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:24,286 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:24,286 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:24.286951', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:24,291 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:24,291 - resetting layer weights
2023-12-09 18:58:24,292 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:24.292006', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:24,292 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:24.292545', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:25,328 - EPOCH 0 - PROGRESS: at 46.25% examples, 358412 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:26,333 - EPOCH 0 - PROGRESS: at 95.00% examples, 372897 words/s, in_qsize 4, out_qsize 0
2023-12-09 18:58:26,422 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 376171 effective words/s
2023-12-09 18:58:26,422 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 375588 effective words/s', 'datetime': '2023-12-09T18:58:26.422603', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:26,422 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:26.422680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:31,293 - Processed run 5 for mu=0.2 on cuda:1. Elapsed time: 8.00 seconds
2023-12-09 18:58:32,106 - collecting all words and their counts
2023-12-09 18:58:32,106 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:32,165 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:32,166 - Creating a fresh vocabulary
2023-12-09 18:58:32,167 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:32.167956', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:32,168 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:32.168027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:32,170 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:32,170 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:32,170 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:32.170896', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:32,175 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:32,175 - resetting layer weights
2023-12-09 18:58:32,176 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:32.175998', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:32,176 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:32.176445', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:33,223 - EPOCH 0 - PROGRESS: at 46.25% examples, 354434 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:34,242 - EPOCH 0 - PROGRESS: at 96.25% examples, 373355 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:34,256 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385230 effective words/s
2023-12-09 18:58:34,256 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 384614 effective words/s', 'datetime': '2023-12-09T18:58:34.256537', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:34,256 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:34.256739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:39,309 - Processed run 5 for mu=0.25 on cuda:2. Elapsed time: 8.01 seconds
2023-12-09 18:58:40,194 - collecting all words and their counts
2023-12-09 18:58:40,194 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:40,253 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:40,253 - Creating a fresh vocabulary
2023-12-09 18:58:40,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:40.255402', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:40,255 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:40.255467', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:40,258 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:40,258 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:40,258 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:40.258327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:40,263 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:40,263 - resetting layer weights
2023-12-09 18:58:40,263 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:40.263441', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:40,263 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:40.263845', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:41,319 - EPOCH 0 - PROGRESS: at 46.25% examples, 351567 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:42,348 - EPOCH 0 - PROGRESS: at 96.25% examples, 369876 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:42,385 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 377624 effective words/s
2023-12-09 18:58:42,385 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 377021 effective words/s', 'datetime': '2023-12-09T18:58:42.385814', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:42,386 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:42.385980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:47,999 - Processed run 5 for mu=0.3 on cuda:3. Elapsed time: 8.69 seconds
2023-12-09 18:58:48,919 - collecting all words and their counts
2023-12-09 18:58:48,919 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:48,980 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:48,980 - Creating a fresh vocabulary
2023-12-09 18:58:48,982 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:48.982528', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:48,982 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:48.982599', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:48,985 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:48,985 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:48,985 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:48.985496', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:48,990 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:48,990 - resetting layer weights
2023-12-09 18:58:48,990 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:48.990753', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:48,991 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:48.991097', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:50,031 - EPOCH 0 - PROGRESS: at 46.25% examples, 356732 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:51,047 - EPOCH 0 - PROGRESS: at 96.25% examples, 374991 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:51,080 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 383381 effective words/s
2023-12-09 18:58:51,081 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382774 effective words/s', 'datetime': '2023-12-09T18:58:51.081175', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:51,081 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:51.081343', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:58:56,024 - Processed run 5 for mu=0.35 on cuda:4. Elapsed time: 8.02 seconds
2023-12-09 18:58:57,121 - collecting all words and their counts
2023-12-09 18:58:57,122 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:58:57,181 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:58:57,181 - Creating a fresh vocabulary
2023-12-09 18:58:57,183 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:58:57.183792', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:57,183 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:58:57.183873', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:57,186 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:58:57,186 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:58:57,186 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:58:57.186707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:58:57,191 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:58:57,191 - resetting layer weights
2023-12-09 18:58:57,191 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:58:57.191795', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:58:57,192 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:58:57.192269', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:58,239 - EPOCH 0 - PROGRESS: at 46.25% examples, 354368 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:58:59,263 - EPOCH 0 - PROGRESS: at 96.25% examples, 372417 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:58:59,284 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382894 effective words/s
2023-12-09 18:58:59,285 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 382286 effective words/s', 'datetime': '2023-12-09T18:58:59.285016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:58:59,285 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:58:59.285185', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:04,769 - Processed run 5 for mu=0.4 on cuda:1. Elapsed time: 8.74 seconds
2023-12-09 18:59:05,810 - collecting all words and their counts
2023-12-09 18:59:05,810 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:05,871 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:05,871 - Creating a fresh vocabulary
2023-12-09 18:59:05,873 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:05.873798', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:05,873 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:05.873883', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:05,876 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:05,876 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:05,876 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:05.876847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:05,881 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:05,881 - resetting layer weights
2023-12-09 18:59:05,882 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:05.882001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:05,882 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:05.882409', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:06,939 - EPOCH 0 - PROGRESS: at 46.25% examples, 350973 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:59:07,966 - EPOCH 0 - PROGRESS: at 96.25% examples, 369994 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:59:07,977 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 382480 effective words/s
2023-12-09 18:59:07,977 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 381854 effective words/s', 'datetime': '2023-12-09T18:59:07.977525', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:07,977 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:59:07.977693', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:13,893 - Processed run 5 for mu=0.45 on cuda:2. Elapsed time: 9.12 seconds
2023-12-09 18:59:15,046 - collecting all words and their counts
2023-12-09 18:59:15,046 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:15,106 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:15,106 - Creating a fresh vocabulary
2023-12-09 18:59:15,108 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:15.108536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:15,108 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:15.108612', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:15,111 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:15,111 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:15,111 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:15.111492', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:15,116 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:15,116 - resetting layer weights
2023-12-09 18:59:15,116 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:15.116526', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:15,117 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:15.116990', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:16,154 - EPOCH 0 - PROGRESS: at 46.25% examples, 357850 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:59:17,174 - EPOCH 0 - PROGRESS: at 96.25% examples, 374808 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:59:17,186 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 387236 effective words/s
2023-12-09 18:59:17,186 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 386631 effective words/s', 'datetime': '2023-12-09T18:59:17.186203', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:17,186 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:59:17.186267', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:23,819 - Processed run 5 for mu=0.5 on cuda:3. Elapsed time: 9.92 seconds
2023-12-09 18:59:25,060 - collecting all words and their counts
2023-12-09 18:59:25,060 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:25,120 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:25,120 - Creating a fresh vocabulary
2023-12-09 18:59:25,122 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:25.122673', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:25,122 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:25.122744', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:25,125 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:25,125 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:25,125 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:25.125617', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:25,130 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:25,130 - resetting layer weights
2023-12-09 18:59:25,130 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:25.130818', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:25,131 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:25.131255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:26,177 - EPOCH 0 - PROGRESS: at 46.25% examples, 354761 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:59:27,203 - EPOCH 0 - PROGRESS: at 96.25% examples, 372232 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:59:27,208 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 385696 effective words/s
2023-12-09 18:59:27,208 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385058 effective words/s', 'datetime': '2023-12-09T18:59:27.208942', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:27,209 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:59:27.209111', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:34,680 - Processed run 5 for mu=0.55 on cuda:4. Elapsed time: 10.86 seconds
2023-12-09 18:59:36,044 - collecting all words and their counts
2023-12-09 18:59:36,044 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:36,105 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:36,105 - Creating a fresh vocabulary
2023-12-09 18:59:36,107 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:36.107061', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:36,107 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:36.107125', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:36,109 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:36,110 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:36,110 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:36.110045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:36,114 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:36,114 - resetting layer weights
2023-12-09 18:59:36,115 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:36.115115', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:36,115 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:36.115569', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:37,153 - EPOCH 0 - PROGRESS: at 46.25% examples, 357657 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:59:38,169 - EPOCH 0 - PROGRESS: at 96.25% examples, 375557 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:59:38,190 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386090 effective words/s
2023-12-09 18:59:38,191 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385455 effective words/s', 'datetime': '2023-12-09T18:59:38.191112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:38,191 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:59:38.191290', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:45,324 - Processed run 5 for mu=0.6 on cuda:1. Elapsed time: 10.64 seconds
2023-12-09 18:59:46,778 - collecting all words and their counts
2023-12-09 18:59:46,778 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:46,838 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:46,838 - Creating a fresh vocabulary
2023-12-09 18:59:46,840 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:46.840509', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:46,840 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:46.840580', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:46,843 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:46,843 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:46,843 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:46.843432', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:46,848 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:46,848 - resetting layer weights
2023-12-09 18:59:46,848 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:46.848645', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:46,849 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:46.849098', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:47,891 - EPOCH 0 - PROGRESS: at 46.25% examples, 355994 words/s, in_qsize 7, out_qsize 0
2023-12-09 18:59:48,911 - EPOCH 0 - PROGRESS: at 96.25% examples, 374005 words/s, in_qsize 3, out_qsize 1
2023-12-09 18:59:48,921 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386554 effective words/s
2023-12-09 18:59:48,922 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385927 effective words/s', 'datetime': '2023-12-09T18:59:48.922102', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:48,922 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T18:59:48.922270', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 18:59:56,994 - Processed run 5 for mu=0.65 on cuda:2. Elapsed time: 11.67 seconds
2023-12-09 18:59:58,532 - collecting all words and their counts
2023-12-09 18:59:58,532 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 18:59:58,593 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 18:59:58,593 - Creating a fresh vocabulary
2023-12-09 18:59:58,595 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T18:59:58.595341', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:58,595 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T18:59:58.595410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:58,598 - deleting the raw counts dictionary of 1000 items
2023-12-09 18:59:58,598 - sample=0.001 downsamples 0 most-common words
2023-12-09 18:59:58,598 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T18:59:58.598351', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 18:59:58,603 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 18:59:58,603 - resetting layer weights
2023-12-09 18:59:58,603 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T18:59:58.603423', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 18:59:58,603 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T18:59:58.603976', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 18:59:59,651 - EPOCH 0 - PROGRESS: at 46.25% examples, 354276 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:00:00,675 - EPOCH 0 - PROGRESS: at 96.25% examples, 372342 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:00:00,713 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 379716 effective words/s
2023-12-09 19:00:00,714 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379117 effective words/s', 'datetime': '2023-12-09T19:00:00.714211', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:00,714 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:00:00.714380', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:00:09,274 - Processed run 5 for mu=0.7 on cuda:3. Elapsed time: 12.28 seconds
2023-12-09 19:00:10,878 - collecting all words and their counts
2023-12-09 19:00:10,878 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:00:10,938 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:00:10,938 - Creating a fresh vocabulary
2023-12-09 19:00:10,940 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:00:10.940707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:10,940 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:00:10.940779', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:10,943 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:00:10,943 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:00:10,943 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:00:10.943670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:10,948 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:00:10,948 - resetting layer weights
2023-12-09 19:00:10,948 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:00:10.948808', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:00:10,949 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:00:10.949306', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:11,992 - EPOCH 0 - PROGRESS: at 46.25% examples, 355830 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:00:13,015 - EPOCH 0 - PROGRESS: at 96.25% examples, 373283 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:00:13,058 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 379944 effective words/s
2023-12-09 19:00:13,058 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 379337 effective words/s', 'datetime': '2023-12-09T19:00:13.058322', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:13,058 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:00:13.058495', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:00:22,051 - Processed run 5 for mu=0.75 on cuda:4. Elapsed time: 12.78 seconds
2023-12-09 19:00:23,803 - collecting all words and their counts
2023-12-09 19:00:23,803 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:00:23,865 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:00:23,865 - Creating a fresh vocabulary
2023-12-09 19:00:23,866 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:00:23.866943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:23,867 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:00:23.867008', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:23,869 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:00:23,869 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:00:23,869 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:00:23.869886', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:23,874 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:00:23,874 - resetting layer weights
2023-12-09 19:00:23,875 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:00:23.875087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:00:23,875 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:00:23.875486', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:24,909 - EPOCH 0 - PROGRESS: at 46.25% examples, 359059 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:00:25,930 - EPOCH 0 - PROGRESS: at 96.25% examples, 375363 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:00:25,948 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386479 effective words/s
2023-12-09 19:00:25,949 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385831 effective words/s', 'datetime': '2023-12-09T19:00:25.949001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:25,949 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:00:25.949168', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:00:36,414 - Processed run 5 for mu=0.8 on cuda:1. Elapsed time: 14.36 seconds
2023-12-09 19:00:38,273 - collecting all words and their counts
2023-12-09 19:00:38,273 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:00:38,333 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:00:38,333 - Creating a fresh vocabulary
2023-12-09 19:00:38,335 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:00:38.335057', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:38,335 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:00:38.335126', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:38,337 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:00:38,337 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:00:38,337 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:00:38.337979', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:38,342 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:00:38,342 - resetting layer weights
2023-12-09 19:00:38,343 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:00:38.343161', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:00:38,343 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:00:38.343621', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:39,383 - EPOCH 0 - PROGRESS: at 46.25% examples, 356998 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:00:40,406 - EPOCH 0 - PROGRESS: at 96.25% examples, 373927 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:00:40,418 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 386142 effective words/s
2023-12-09 19:00:40,418 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 385525 effective words/s', 'datetime': '2023-12-09T19:00:40.418786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:40,418 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:00:40.418956', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:00:51,272 - Processed run 5 for mu=0.85 on cuda:2. Elapsed time: 14.86 seconds
2023-12-09 19:00:53,284 - collecting all words and their counts
2023-12-09 19:00:53,284 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:00:53,345 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:00:53,346 - Creating a fresh vocabulary
2023-12-09 19:00:53,347 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:00:53.347966', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:53,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:00:53.348042', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:53,350 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:00:53,350 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:00:53,351 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:00:53.351027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:00:53,355 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:00:53,355 - resetting layer weights
2023-12-09 19:00:53,356 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:00:53.356287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:00:53,356 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:00:53.356714', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:54,386 - EPOCH 0 - PROGRESS: at 41.25% examples, 321364 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:00:55,395 - EPOCH 0 - PROGRESS: at 86.25% examples, 338961 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:00:55,668 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 346525 effective words/s
2023-12-09 19:00:55,668 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 346027 effective words/s', 'datetime': '2023-12-09T19:00:55.668748', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:00:55,669 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:00:55.669366', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:01:07,453 - Processed run 5 for mu=0.9 on cuda:3. Elapsed time: 16.18 seconds
2023-12-09 19:01:09,640 - collecting all words and their counts
2023-12-09 19:01:09,640 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:01:09,700 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:01:09,700 - Creating a fresh vocabulary
2023-12-09 19:01:09,702 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:01:09.702303', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:09,702 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:01:09.702373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:09,705 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:01:09,705 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:01:09,705 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:01:09.705293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:09,709 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:01:09,710 - resetting layer weights
2023-12-09 19:01:09,710 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:01:09.710333', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:01:09,710 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:01:09.710784', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:10,744 - EPOCH 0 - PROGRESS: at 41.25% examples, 320368 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:11,751 - EPOCH 0 - PROGRESS: at 87.50% examples, 343542 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:11,999 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349984 effective words/s
2023-12-09 19:01:12,000 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349448 effective words/s', 'datetime': '2023-12-09T19:01:12.000181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:12,000 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:01:12.000368', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:01:23,765 - Processed run 5 for mu=0.95 on cuda:4. Elapsed time: 16.31 seconds
2023-12-09 19:01:26,160 - collecting all words and their counts
2023-12-09 19:01:26,160 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:01:26,221 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:01:26,221 - Creating a fresh vocabulary
2023-12-09 19:01:26,223 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:01:26.223119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:26,223 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:01:26.223184', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:26,226 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:01:26,226 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:01:26,226 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:01:26.226092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:26,230 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:01:26,230 - resetting layer weights
2023-12-09 19:01:26,231 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:01:26.231246', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:01:26,231 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:01:26.231666', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:27,243 - EPOCH 0 - PROGRESS: at 41.25% examples, 327205 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:28,247 - EPOCH 0 - PROGRESS: at 86.25% examples, 342862 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:28,492 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354434 effective words/s
2023-12-09 19:01:28,492 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353892 effective words/s', 'datetime': '2023-12-09T19:01:28.492320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:28,492 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:01:28.492508', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:01:41,037 - Processed run 5 for mu=1.0 on cuda:1. Elapsed time: 17.27 seconds
2023-12-09 19:01:42,009 - collecting all words and their counts
2023-12-09 19:01:42,009 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:01:42,066 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:01:42,067 - Creating a fresh vocabulary
2023-12-09 19:01:42,069 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:01:42.068991', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:42,069 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:01:42.069068', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:42,071 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:01:42,071 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:01:42,071 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:01:42.071944', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:42,076 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:01:42,076 - resetting layer weights
2023-12-09 19:01:42,077 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:01:42.077001', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:01:42,077 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:01:42.077343', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:43,092 - EPOCH 0 - PROGRESS: at 56.25% examples, 444852 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:43,667 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 504021 effective words/s
2023-12-09 19:01:43,668 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 502925 effective words/s', 'datetime': '2023-12-09T19:01:43.668111', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:43,668 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:01:43.668291', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:01:48,521 - Processed run 6 for mu=0.0 on cuda:1. Elapsed time: 7.48 seconds
2023-12-09 19:01:49,472 - collecting all words and their counts
2023-12-09 19:01:49,472 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:01:49,531 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:01:49,532 - Creating a fresh vocabulary
2023-12-09 19:01:49,534 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:01:49.533996', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:49,534 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:01:49.534064', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:49,536 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:01:49,536 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:01:49,536 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:01:49.536964', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:49,541 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:01:49,541 - resetting layer weights
2023-12-09 19:01:49,542 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:01:49.542037', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:01:49,542 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:01:49.542477', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:50,567 - EPOCH 0 - PROGRESS: at 41.25% examples, 323098 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:51,574 - EPOCH 0 - PROGRESS: at 86.25% examples, 340105 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:01:51,814 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352664 effective words/s
2023-12-09 19:01:51,814 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352115 effective words/s', 'datetime': '2023-12-09T19:01:51.814536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:51,814 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:01:51.814717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:01:57,086 - Processed run 6 for mu=0.05 on cuda:2. Elapsed time: 8.56 seconds
2023-12-09 19:01:57,854 - collecting all words and their counts
2023-12-09 19:01:57,854 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:01:57,912 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:01:57,912 - Creating a fresh vocabulary
2023-12-09 19:01:57,914 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:01:57.914755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:57,914 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:01:57.914831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:57,917 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:01:57,917 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:01:57,917 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:01:57.917850', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:01:57,922 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:01:57,922 - resetting layer weights
2023-12-09 19:01:57,922 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:01:57.922973', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:01:57,923 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:01:57.923513', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:01:58,946 - EPOCH 0 - PROGRESS: at 41.25% examples, 323472 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:01:59,963 - EPOCH 0 - PROGRESS: at 88.75% examples, 348513 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:00,190 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353432 effective words/s
2023-12-09 19:02:00,190 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352909 effective words/s', 'datetime': '2023-12-09T19:02:00.190461', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:00,190 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:00.190655', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:05,598 - Processed run 6 for mu=0.1 on cuda:3. Elapsed time: 8.51 seconds
2023-12-09 19:02:06,639 - collecting all words and their counts
2023-12-09 19:02:06,639 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:06,700 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:06,700 - Creating a fresh vocabulary
2023-12-09 19:02:06,702 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:06.702258', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:06,702 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:06.702327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:06,705 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:06,705 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:06,705 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:06.705191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:06,709 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:06,709 - resetting layer weights
2023-12-09 19:02:06,710 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:06.710300', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:06,710 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:06.710776', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:07,721 - EPOCH 0 - PROGRESS: at 41.25% examples, 327465 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:08,722 - EPOCH 0 - PROGRESS: at 86.25% examples, 343580 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:08,981 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352837 effective words/s
2023-12-09 19:02:08,981 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352309 effective words/s', 'datetime': '2023-12-09T19:02:08.981586', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:08,981 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:08.981768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:13,315 - Processed run 6 for mu=0.15 on cuda:4. Elapsed time: 7.72 seconds
2023-12-09 19:02:14,090 - collecting all words and their counts
2023-12-09 19:02:14,091 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:14,150 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:14,150 - Creating a fresh vocabulary
2023-12-09 19:02:14,152 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:14.152086', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:14,152 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:14.152167', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:14,154 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:14,155 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:14,155 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:14.155070', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:14,159 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:14,159 - resetting layer weights
2023-12-09 19:02:14,160 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:14.160195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:14,160 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:14.160669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:15,186 - EPOCH 0 - PROGRESS: at 42.50% examples, 332430 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:02:16,208 - EPOCH 0 - PROGRESS: at 88.75% examples, 347226 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:16,435 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352202 effective words/s
2023-12-09 19:02:16,435 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351678 effective words/s', 'datetime': '2023-12-09T19:02:16.435549', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:16,435 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:16.435689', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:21,158 - Processed run 6 for mu=0.2 on cuda:1. Elapsed time: 7.84 seconds
2023-12-09 19:02:22,059 - collecting all words and their counts
2023-12-09 19:02:22,059 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:22,118 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:22,118 - Creating a fresh vocabulary
2023-12-09 19:02:22,120 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:22.120766', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:22,120 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:22.120832', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:22,123 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:22,123 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:22,123 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:22.123676', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:22,128 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:22,128 - resetting layer weights
2023-12-09 19:02:22,128 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:22.128738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:22,129 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:22.129174', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:23,144 - EPOCH 0 - PROGRESS: at 41.25% examples, 326066 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:24,144 - EPOCH 0 - PROGRESS: at 86.25% examples, 342901 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:24,375 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356648 effective words/s
2023-12-09 19:02:24,375 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356112 effective words/s', 'datetime': '2023-12-09T19:02:24.375734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:24,375 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:24.375918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:29,414 - Processed run 6 for mu=0.25 on cuda:2. Elapsed time: 8.25 seconds
2023-12-09 19:02:30,287 - collecting all words and their counts
2023-12-09 19:02:30,287 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:30,346 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:30,347 - Creating a fresh vocabulary
2023-12-09 19:02:30,348 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:30.348957', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:30,349 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:30.349025', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:30,351 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:30,351 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:30,351 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:30.351918', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:30,356 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:30,356 - resetting layer weights
2023-12-09 19:02:30,357 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:30.356985', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:30,357 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:30.357326', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:31,382 - EPOCH 0 - PROGRESS: at 41.25% examples, 322853 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:32,386 - EPOCH 0 - PROGRESS: at 87.50% examples, 345570 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:32,612 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355180 effective words/s
2023-12-09 19:02:32,613 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354644 effective words/s', 'datetime': '2023-12-09T19:02:32.613183', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:32,613 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:32.613361', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:38,746 - Processed run 6 for mu=0.3 on cuda:3. Elapsed time: 9.33 seconds
2023-12-09 19:02:39,656 - collecting all words and their counts
2023-12-09 19:02:39,656 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:39,716 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:39,717 - Creating a fresh vocabulary
2023-12-09 19:02:39,718 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:39.718883', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:39,718 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:39.718951', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:39,721 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:39,721 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:39,721 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:39.721868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:39,726 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:39,726 - resetting layer weights
2023-12-09 19:02:39,727 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:39.727087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:39,727 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:39.727605', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:40,746 - EPOCH 0 - PROGRESS: at 41.25% examples, 324757 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:02:41,755 - EPOCH 0 - PROGRESS: at 86.25% examples, 340729 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:02:42,000 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352459 effective words/s
2023-12-09 19:02:42,000 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351932 effective words/s', 'datetime': '2023-12-09T19:02:42.000847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:42,001 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:42.001029', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:49,465 - Processed run 6 for mu=0.35 on cuda:4. Elapsed time: 10.72 seconds
2023-12-09 19:02:50,623 - collecting all words and their counts
2023-12-09 19:02:50,623 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:02:50,685 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:02:50,685 - Creating a fresh vocabulary
2023-12-09 19:02:50,687 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:02:50.687181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:50,687 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:02:50.687261', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:50,690 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:02:50,690 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:02:50,690 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:02:50.690137', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:02:50,694 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:02:50,695 - resetting layer weights
2023-12-09 19:02:50,695 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:02:50.695331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:02:50,695 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:02:50.695797', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:51,708 - EPOCH 0 - PROGRESS: at 41.25% examples, 326782 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:52,713 - EPOCH 0 - PROGRESS: at 87.50% examples, 347437 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:02:52,952 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355064 effective words/s
2023-12-09 19:02:52,952 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354530 effective words/s', 'datetime': '2023-12-09T19:02:52.952378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:02:52,952 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:02:52.952562', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:02:59,173 - Processed run 6 for mu=0.4 on cuda:1. Elapsed time: 9.71 seconds
2023-12-09 19:03:00,180 - collecting all words and their counts
2023-12-09 19:03:00,180 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:00,240 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:00,240 - Creating a fresh vocabulary
2023-12-09 19:03:00,242 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:00.242745', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:00,242 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:00.242855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:00,245 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:00,245 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:00,245 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:00.245783', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:00,250 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:00,250 - resetting layer weights
2023-12-09 19:03:00,250 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:00.250943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:00,251 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:00.251486', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:01,281 - EPOCH 0 - PROGRESS: at 41.25% examples, 321296 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:02,283 - EPOCH 0 - PROGRESS: at 86.25% examples, 340120 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:02,513 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354215 effective words/s
2023-12-09 19:03:02,513 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353677 effective words/s', 'datetime': '2023-12-09T19:03:02.513512', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:02,513 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:02.513687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:03:08,193 - Processed run 6 for mu=0.45 on cuda:2. Elapsed time: 9.02 seconds
2023-12-09 19:03:09,389 - collecting all words and their counts
2023-12-09 19:03:09,389 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:09,449 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:09,449 - Creating a fresh vocabulary
2023-12-09 19:03:09,451 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:09.451793', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:09,451 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:09.451861', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:09,454 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:09,454 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:09,454 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:09.454780', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:09,459 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:09,459 - resetting layer weights
2023-12-09 19:03:09,459 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:09.459812', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:09,460 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:09.460235', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:10,488 - EPOCH 0 - PROGRESS: at 41.25% examples, 321900 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:11,495 - EPOCH 0 - PROGRESS: at 86.25% examples, 339574 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:11,723 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353935 effective words/s
2023-12-09 19:03:11,723 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353418 effective words/s', 'datetime': '2023-12-09T19:03:11.723901', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:11,723 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:11.723986', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:03:17,926 - Processed run 6 for mu=0.5 on cuda:3. Elapsed time: 9.73 seconds
2023-12-09 19:03:19,116 - collecting all words and their counts
2023-12-09 19:03:19,116 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:19,176 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:19,176 - Creating a fresh vocabulary
2023-12-09 19:03:19,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:19.178401', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:19,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:19.178477', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:19,181 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:19,181 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:19,181 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:19.181398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:19,186 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:19,186 - resetting layer weights
2023-12-09 19:03:19,186 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:19.186587', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:19,187 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:19.187058', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:20,220 - EPOCH 0 - PROGRESS: at 41.25% examples, 320447 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:21,227 - EPOCH 0 - PROGRESS: at 86.25% examples, 338662 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:21,463 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351848 effective words/s
2023-12-09 19:03:21,464 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351325 effective words/s', 'datetime': '2023-12-09T19:03:21.464223', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:21,464 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:21.464855', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:03:27,408 - Processed run 6 for mu=0.55 on cuda:4. Elapsed time: 9.48 seconds
2023-12-09 19:03:28,813 - collecting all words and their counts
2023-12-09 19:03:28,813 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:28,874 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:28,874 - Creating a fresh vocabulary
2023-12-09 19:03:28,876 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:28.876178', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:28,876 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:28.876244', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:28,879 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:28,879 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:28,879 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:28.879081', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:28,883 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:28,883 - resetting layer weights
2023-12-09 19:03:28,884 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:28.884147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:28,884 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:28.884640', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:29,907 - EPOCH 0 - PROGRESS: at 41.25% examples, 323685 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:30,912 - EPOCH 0 - PROGRESS: at 87.50% examples, 345733 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:31,161 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351791 effective words/s
2023-12-09 19:03:31,162 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351257 effective words/s', 'datetime': '2023-12-09T19:03:31.162246', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:31,162 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:31.162424', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:03:38,307 - Processed run 6 for mu=0.6 on cuda:1. Elapsed time: 10.90 seconds
2023-12-09 19:03:39,695 - collecting all words and their counts
2023-12-09 19:03:39,695 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:39,755 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:39,755 - Creating a fresh vocabulary
2023-12-09 19:03:39,757 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:39.757561', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:39,757 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:39.757629', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:39,760 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:39,760 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:39,760 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:39.760545', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:39,765 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:39,765 - resetting layer weights
2023-12-09 19:03:39,765 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:39.765750', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:39,766 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:39.766110', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:40,792 - EPOCH 0 - PROGRESS: at 41.25% examples, 322480 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:41,801 - EPOCH 0 - PROGRESS: at 87.50% examples, 344475 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:42,038 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352615 effective words/s
2023-12-09 19:03:42,038 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352082 effective words/s', 'datetime': '2023-12-09T19:03:42.038378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:42,038 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:42.038561', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:03:49,931 - Processed run 6 for mu=0.65 on cuda:2. Elapsed time: 11.62 seconds
2023-12-09 19:03:51,507 - collecting all words and their counts
2023-12-09 19:03:51,507 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:03:51,571 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:03:51,571 - Creating a fresh vocabulary
2023-12-09 19:03:51,574 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:03:51.573989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:51,574 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:03:51.574084', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:51,576 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:03:51,577 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:03:51,577 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:03:51.577060', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:03:51,581 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:03:51,581 - resetting layer weights
2023-12-09 19:03:51,582 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:03:51.582243', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:03:51,582 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:03:51.582736', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:52,618 - EPOCH 0 - PROGRESS: at 41.25% examples, 319630 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:53,620 - EPOCH 0 - PROGRESS: at 86.25% examples, 339145 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:03:53,866 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350828 effective words/s
2023-12-09 19:03:53,866 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350310 effective words/s', 'datetime': '2023-12-09T19:03:53.866499', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:03:53,866 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:03:53.866685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:04:02,573 - Processed run 6 for mu=0.7 on cuda:3. Elapsed time: 12.64 seconds
2023-12-09 19:04:04,208 - collecting all words and their counts
2023-12-09 19:04:04,208 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:04:04,268 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:04:04,268 - Creating a fresh vocabulary
2023-12-09 19:04:04,270 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:04:04.270856', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:04,270 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:04:04.270920', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:04,273 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:04:04,273 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:04:04,273 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:04:04.273817', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:04,278 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:04:04,278 - resetting layer weights
2023-12-09 19:04:04,278 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:04:04.278909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:04:04,279 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:04:04.279344', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:05,296 - EPOCH 0 - PROGRESS: at 41.25% examples, 325513 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:06,300 - EPOCH 0 - PROGRESS: at 86.25% examples, 341912 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:06,573 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349140 effective words/s
2023-12-09 19:04:06,574 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348616 effective words/s', 'datetime': '2023-12-09T19:04:06.574207', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:06,574 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:04:06.574399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:04:16,342 - Processed run 6 for mu=0.75 on cuda:4. Elapsed time: 13.77 seconds
2023-12-09 19:04:18,180 - collecting all words and their counts
2023-12-09 19:04:18,180 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:04:18,240 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:04:18,240 - Creating a fresh vocabulary
2023-12-09 19:04:18,242 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:04:18.242477', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:18,242 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:04:18.242544', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:18,245 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:04:18,245 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:04:18,245 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:04:18.245462', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:18,250 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:04:18,250 - resetting layer weights
2023-12-09 19:04:18,250 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:04:18.250596', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:04:18,251 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:04:18.251069', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:19,268 - EPOCH 0 - PROGRESS: at 41.25% examples, 325472 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:20,277 - EPOCH 0 - PROGRESS: at 87.50% examples, 345928 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:20,520 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353022 effective words/s
2023-12-09 19:04:20,520 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352494 effective words/s', 'datetime': '2023-12-09T19:04:20.520682', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:20,520 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:04:20.520864', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:04:30,808 - Processed run 6 for mu=0.8 on cuda:1. Elapsed time: 14.46 seconds
2023-12-09 19:04:32,675 - collecting all words and their counts
2023-12-09 19:04:32,675 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:04:32,736 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:04:32,736 - Creating a fresh vocabulary
2023-12-09 19:04:32,738 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:04:32.738147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:32,738 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:04:32.738224', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:32,741 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:04:32,741 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:04:32,741 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:04:32.741085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:32,745 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:04:32,745 - resetting layer weights
2023-12-09 19:04:32,746 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:04:32.746180', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:04:32,746 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:04:32.746582', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:33,764 - EPOCH 0 - PROGRESS: at 41.25% examples, 325295 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:34,778 - EPOCH 0 - PROGRESS: at 87.50% examples, 345025 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:35,018 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352651 effective words/s
2023-12-09 19:04:35,018 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352120 effective words/s', 'datetime': '2023-12-09T19:04:35.018608', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:35,018 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:04:35.018799', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:04:47,479 - Processed run 6 for mu=0.85 on cuda:2. Elapsed time: 16.67 seconds
2023-12-09 19:04:49,588 - collecting all words and their counts
2023-12-09 19:04:49,589 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:04:49,648 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:04:49,648 - Creating a fresh vocabulary
2023-12-09 19:04:49,650 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:04:49.650761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:49,650 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:04:49.650827', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:49,653 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:04:49,653 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:04:49,653 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:04:49.653650', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:04:49,658 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:04:49,658 - resetting layer weights
2023-12-09 19:04:49,658 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:04:49.658747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:04:49,659 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:04:49.659221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:50,683 - EPOCH 0 - PROGRESS: at 41.25% examples, 323237 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:51,686 - EPOCH 0 - PROGRESS: at 87.50% examples, 345798 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:04:51,931 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352632 effective words/s
2023-12-09 19:04:51,931 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352098 effective words/s', 'datetime': '2023-12-09T19:04:51.931392', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:04:51,931 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:04:51.931595', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:05:04,798 - Processed run 6 for mu=0.9 on cuda:3. Elapsed time: 17.32 seconds
2023-12-09 19:05:07,022 - collecting all words and their counts
2023-12-09 19:05:07,022 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:05:07,083 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:05:07,083 - Creating a fresh vocabulary
2023-12-09 19:05:07,085 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:05:07.085330', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:07,085 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:05:07.085403', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:07,088 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:05:07,088 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:05:07,088 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:05:07.088292', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:07,092 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:05:07,093 - resetting layer weights
2023-12-09 19:05:07,093 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:05:07.093359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:05:07,093 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:05:07.093722', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:08,111 - EPOCH 0 - PROGRESS: at 41.25% examples, 325275 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:05:09,138 - EPOCH 0 - PROGRESS: at 87.50% examples, 342953 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:05:09,363 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352877 effective words/s
2023-12-09 19:05:09,364 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352352 effective words/s', 'datetime': '2023-12-09T19:05:09.364253', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:09,364 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:05:09.364429', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:05:22,189 - Processed run 6 for mu=0.95 on cuda:4. Elapsed time: 17.39 seconds
2023-12-09 19:05:24,566 - collecting all words and their counts
2023-12-09 19:05:24,567 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:05:24,626 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:05:24,626 - Creating a fresh vocabulary
2023-12-09 19:05:24,628 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:05:24.628607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:24,628 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:05:24.628687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:24,631 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:05:24,631 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:05:24,631 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:05:24.631573', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:24,636 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:05:24,636 - resetting layer weights
2023-12-09 19:05:24,636 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:05:24.636632', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:05:24,637 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:05:24.637079', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:25,658 - EPOCH 0 - PROGRESS: at 41.25% examples, 324037 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:26,680 - EPOCH 0 - PROGRESS: at 88.75% examples, 348060 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:26,906 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352954 effective words/s
2023-12-09 19:05:26,907 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352421 effective words/s', 'datetime': '2023-12-09T19:05:26.907164', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:26,907 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:05:26.907356', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:05:39,363 - Processed run 6 for mu=1.0 on cuda:1. Elapsed time: 17.17 seconds
2023-12-09 19:05:40,292 - collecting all words and their counts
2023-12-09 19:05:40,292 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:05:40,350 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:05:40,350 - Creating a fresh vocabulary
2023-12-09 19:05:40,352 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:05:40.352680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:40,352 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:05:40.352762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:40,355 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:05:40,355 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:05:40,355 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:05:40.355620', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:40,360 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:05:40,360 - resetting layer weights
2023-12-09 19:05:40,360 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:05:40.360664', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:05:40,361 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:05:40.361085', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:41,390 - EPOCH 0 - PROGRESS: at 56.25% examples, 438543 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:41,972 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 497518 effective words/s
2023-12-09 19:05:41,972 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 496474 effective words/s', 'datetime': '2023-12-09T19:05:41.972521', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:41,972 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:05:41.972719', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:05:46,031 - Processed run 7 for mu=0.0 on cuda:1. Elapsed time: 6.67 seconds
2023-12-09 19:05:47,027 - collecting all words and their counts
2023-12-09 19:05:47,027 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:05:47,086 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:05:47,087 - Creating a fresh vocabulary
2023-12-09 19:05:47,089 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:05:47.089002', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:47,089 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:05:47.089076', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:47,091 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:05:47,091 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:05:47,091 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:05:47.091942', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:47,096 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:05:47,096 - resetting layer weights
2023-12-09 19:05:47,097 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:05:47.097317', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:05:47,097 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:05:47.097704', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:48,117 - EPOCH 0 - PROGRESS: at 41.25% examples, 324485 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:49,126 - EPOCH 0 - PROGRESS: at 88.75% examples, 350581 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:49,371 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352319 effective words/s
2023-12-09 19:05:49,371 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351797 effective words/s', 'datetime': '2023-12-09T19:05:49.371826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:49,372 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:05:49.372007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:05:53,906 - Processed run 7 for mu=0.05 on cuda:2. Elapsed time: 7.87 seconds
2023-12-09 19:05:54,886 - collecting all words and their counts
2023-12-09 19:05:54,886 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:05:54,947 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:05:54,947 - Creating a fresh vocabulary
2023-12-09 19:05:54,949 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:05:54.949410', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:54,949 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:05:54.949479', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:54,952 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:05:54,952 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:05:54,952 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:05:54.952368', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:05:54,957 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:05:54,957 - resetting layer weights
2023-12-09 19:05:54,957 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:05:54.957546', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:05:54,957 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:05:54.957989', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:55,981 - EPOCH 0 - PROGRESS: at 41.25% examples, 323536 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:57,005 - EPOCH 0 - PROGRESS: at 90.00% examples, 352276 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:05:57,217 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354480 effective words/s
2023-12-09 19:05:57,218 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353965 effective words/s', 'datetime': '2023-12-09T19:05:57.218159', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:05:57,218 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:05:57.218241', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:01,924 - Processed run 7 for mu=0.1 on cuda:3. Elapsed time: 8.02 seconds
2023-12-09 19:06:02,747 - collecting all words and their counts
2023-12-09 19:06:02,747 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:02,806 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:02,806 - Creating a fresh vocabulary
2023-12-09 19:06:02,808 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:02.808751', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:02,808 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:02.808819', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:02,811 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:02,811 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:02,811 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:02.811657', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:02,816 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:02,816 - resetting layer weights
2023-12-09 19:06:02,816 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:02.816720', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:02,817 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:02.817079', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:03,830 - EPOCH 0 - PROGRESS: at 41.25% examples, 326615 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:04,831 - EPOCH 0 - PROGRESS: at 86.25% examples, 343112 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:05,089 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352510 effective words/s
2023-12-09 19:06:05,090 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351979 effective words/s', 'datetime': '2023-12-09T19:06:05.090012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:05,090 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:05.090195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:09,680 - Processed run 7 for mu=0.15 on cuda:4. Elapsed time: 7.75 seconds
2023-12-09 19:06:10,518 - collecting all words and their counts
2023-12-09 19:06:10,518 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:10,578 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:10,578 - Creating a fresh vocabulary
2023-12-09 19:06:10,580 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:10.580560', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:10,580 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:10.580636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:10,583 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:10,583 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:10,583 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:10.583458', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:10,588 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:10,588 - resetting layer weights
2023-12-09 19:06:10,588 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:10.588463', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:10,588 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:10.588902', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:11,602 - EPOCH 0 - PROGRESS: at 41.25% examples, 326738 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:12,605 - EPOCH 0 - PROGRESS: at 88.75% examples, 352587 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:12,829 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357606 effective words/s
2023-12-09 19:06:12,829 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357070 effective words/s', 'datetime': '2023-12-09T19:06:12.829434', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:12,829 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:12.829613', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:17,965 - Processed run 7 for mu=0.2 on cuda:1. Elapsed time: 8.28 seconds
2023-12-09 19:06:18,826 - collecting all words and their counts
2023-12-09 19:06:18,826 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:18,886 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:18,886 - Creating a fresh vocabulary
2023-12-09 19:06:18,888 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:18.888255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:18,888 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:18.888320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:18,891 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:18,891 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:18,891 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:18.891195', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:18,895 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:18,895 - resetting layer weights
2023-12-09 19:06:18,896 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:18.896204', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:18,896 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:18.896694', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:19,916 - EPOCH 0 - PROGRESS: at 41.25% examples, 324714 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:20,927 - EPOCH 0 - PROGRESS: at 87.50% examples, 345181 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:21,197 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348272 effective words/s
2023-12-09 19:06:21,197 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347743 effective words/s', 'datetime': '2023-12-09T19:06:21.197316', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:21,197 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:21.197497', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:26,594 - Processed run 7 for mu=0.25 on cuda:2. Elapsed time: 8.63 seconds
2023-12-09 19:06:27,398 - collecting all words and their counts
2023-12-09 19:06:27,398 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:27,458 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:27,458 - Creating a fresh vocabulary
2023-12-09 19:06:27,460 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:27.460595', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:27,460 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:27.460669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:27,463 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:27,463 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:27,463 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:27.463523', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:27,468 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:27,468 - resetting layer weights
2023-12-09 19:06:27,468 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:27.468553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:27,469 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:27.469030', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:28,495 - EPOCH 0 - PROGRESS: at 41.25% examples, 322550 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:29,504 - EPOCH 0 - PROGRESS: at 87.50% examples, 344386 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:06:29,743 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352197 effective words/s
2023-12-09 19:06:29,743 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351673 effective words/s', 'datetime': '2023-12-09T19:06:29.743947', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:29,744 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:29.744131', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:35,877 - Processed run 7 for mu=0.3 on cuda:3. Elapsed time: 9.28 seconds
2023-12-09 19:06:36,744 - collecting all words and their counts
2023-12-09 19:06:36,745 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:36,805 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:36,805 - Creating a fresh vocabulary
2023-12-09 19:06:36,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:36.807267', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:36,807 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:36.807332', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:36,810 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:36,810 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:36,810 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:36.810225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:36,814 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:36,814 - resetting layer weights
2023-12-09 19:06:36,815 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:36.815310', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:36,815 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:36.815848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:37,834 - EPOCH 0 - PROGRESS: at 41.25% examples, 324987 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:38,854 - EPOCH 0 - PROGRESS: at 86.25% examples, 338969 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:39,117 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348117 effective words/s
2023-12-09 19:06:39,117 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347613 effective words/s', 'datetime': '2023-12-09T19:06:39.117314', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:39,117 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:39.117407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:44,160 - Processed run 7 for mu=0.35 on cuda:4. Elapsed time: 8.28 seconds
2023-12-09 19:06:45,194 - collecting all words and their counts
2023-12-09 19:06:45,194 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:45,255 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:45,255 - Creating a fresh vocabulary
2023-12-09 19:06:45,257 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:45.257067', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:45,257 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:45.257138', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:45,259 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:45,259 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:45,259 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:45.259980', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:45,264 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:45,264 - resetting layer weights
2023-12-09 19:06:45,265 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:45.265107', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:45,265 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:45.265521', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:46,280 - EPOCH 0 - PROGRESS: at 41.25% examples, 326037 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:47,286 - EPOCH 0 - PROGRESS: at 86.25% examples, 341966 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:47,527 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354146 effective words/s
2023-12-09 19:06:47,527 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353619 effective words/s', 'datetime': '2023-12-09T19:06:47.527916', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:47,528 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:47.528087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:06:53,337 - Processed run 7 for mu=0.4 on cuda:1. Elapsed time: 9.18 seconds
2023-12-09 19:06:54,396 - collecting all words and their counts
2023-12-09 19:06:54,397 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:06:54,458 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:06:54,458 - Creating a fresh vocabulary
2023-12-09 19:06:54,460 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:06:54.460157', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:54,460 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:06:54.460237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:54,462 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:06:54,463 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:06:54,463 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:06:54.463080', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:06:54,467 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:06:54,467 - resetting layer weights
2023-12-09 19:06:54,468 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:06:54.468087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:06:54,468 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:06:54.468636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:55,481 - EPOCH 0 - PROGRESS: at 41.25% examples, 326785 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:56,484 - EPOCH 0 - PROGRESS: at 87.50% examples, 347709 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:06:56,718 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 356121 effective words/s
2023-12-09 19:06:56,718 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 355594 effective words/s', 'datetime': '2023-12-09T19:06:56.718473', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:06:56,718 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:06:56.718670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:07:03,389 - Processed run 7 for mu=0.45 on cuda:2. Elapsed time: 10.05 seconds
2023-12-09 19:07:04,617 - collecting all words and their counts
2023-12-09 19:07:04,617 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:07:04,678 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:07:04,678 - Creating a fresh vocabulary
2023-12-09 19:07:04,680 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:07:04.680620', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:04,680 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:07:04.680691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:04,683 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:07:04,683 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:07:04,683 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:07:04.683542', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:04,688 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:07:04,688 - resetting layer weights
2023-12-09 19:07:04,688 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:07:04.688735', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:07:04,689 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:07:04.689171', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:05,699 - EPOCH 0 - PROGRESS: at 41.25% examples, 327837 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:06,709 - EPOCH 0 - PROGRESS: at 87.50% examples, 347015 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:06,944 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355214 effective words/s
2023-12-09 19:07:06,944 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354670 effective words/s', 'datetime': '2023-12-09T19:07:06.944865', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:06,945 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:07:06.945056', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:07:14,675 - Processed run 7 for mu=0.5 on cuda:3. Elapsed time: 11.28 seconds
2023-12-09 19:07:15,923 - collecting all words and their counts
2023-12-09 19:07:15,923 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:07:15,984 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:07:15,984 - Creating a fresh vocabulary
2023-12-09 19:07:15,986 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:07:15.986622', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:15,986 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:07:15.986691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:15,989 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:07:15,989 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:07:15,989 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:07:15.989553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:15,994 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:07:15,994 - resetting layer weights
2023-12-09 19:07:15,994 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:07:15.994820', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:07:15,995 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:07:15.995240', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:17,027 - EPOCH 0 - PROGRESS: at 41.25% examples, 320686 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:18,029 - EPOCH 0 - PROGRESS: at 87.50% examples, 344751 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:18,275 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351376 effective words/s
2023-12-09 19:07:18,275 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350827 effective words/s', 'datetime': '2023-12-09T19:07:18.275639', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:18,275 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:07:18.275821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:07:24,531 - Processed run 7 for mu=0.55 on cuda:4. Elapsed time: 9.86 seconds
2023-12-09 19:07:25,866 - collecting all words and their counts
2023-12-09 19:07:25,866 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:07:25,928 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:07:25,928 - Creating a fresh vocabulary
2023-12-09 19:07:25,930 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:07:25.930501', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:25,930 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:07:25.930570', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:25,933 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:07:25,933 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:07:25,933 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:07:25.933492', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:25,938 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:07:25,938 - resetting layer weights
2023-12-09 19:07:25,938 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:07:25.938670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:07:25,939 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:07:25.939127', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:26,948 - EPOCH 0 - PROGRESS: at 41.25% examples, 327855 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:27,962 - EPOCH 0 - PROGRESS: at 88.75% examples, 351544 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:28,180 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 357407 effective words/s
2023-12-09 19:07:28,181 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 356857 effective words/s', 'datetime': '2023-12-09T19:07:28.180992', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:28,181 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:07:28.181171', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:07:36,348 - Processed run 7 for mu=0.6 on cuda:1. Elapsed time: 11.82 seconds
2023-12-09 19:07:37,768 - collecting all words and their counts
2023-12-09 19:07:37,768 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:07:37,829 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:07:37,829 - Creating a fresh vocabulary
2023-12-09 19:07:37,831 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:07:37.831456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:37,831 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:07:37.831529', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:37,834 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:07:37,834 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:07:37,834 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:07:37.834387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:37,839 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:07:37,839 - resetting layer weights
2023-12-09 19:07:37,839 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:07:37.839516', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:07:37,839 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:07:37.839940', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:38,862 - EPOCH 0 - PROGRESS: at 41.25% examples, 323711 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:39,870 - EPOCH 0 - PROGRESS: at 86.25% examples, 340387 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:40,129 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349918 effective words/s
2023-12-09 19:07:40,129 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349398 effective words/s', 'datetime': '2023-12-09T19:07:40.129669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:40,129 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:07:40.129850', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:07:49,098 - Processed run 7 for mu=0.65 on cuda:2. Elapsed time: 12.75 seconds
2023-12-09 19:07:50,639 - collecting all words and their counts
2023-12-09 19:07:50,639 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:07:50,701 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:07:50,701 - Creating a fresh vocabulary
2023-12-09 19:07:50,703 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:07:50.703581', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:50,703 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:07:50.703657', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:50,706 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:07:50,706 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:07:50,706 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:07:50.706555', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:07:50,711 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:07:50,711 - resetting layer weights
2023-12-09 19:07:50,711 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:07:50.711687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:07:50,712 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:07:50.712215', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:51,735 - EPOCH 0 - PROGRESS: at 42.50% examples, 333342 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:52,746 - EPOCH 0 - PROGRESS: at 88.75% examples, 349531 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:07:52,964 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 355778 effective words/s
2023-12-09 19:07:52,964 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 355242 effective words/s', 'datetime': '2023-12-09T19:07:52.964273', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:07:52,964 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:07:52.964456', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:08:01,532 - Processed run 7 for mu=0.7 on cuda:3. Elapsed time: 12.43 seconds
2023-12-09 19:08:03,246 - collecting all words and their counts
2023-12-09 19:08:03,246 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:08:03,307 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:08:03,307 - Creating a fresh vocabulary
2023-12-09 19:08:03,309 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:08:03.309654', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:03,309 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:08:03.309733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:03,312 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:08:03,312 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:08:03,312 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:08:03.312698', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:03,317 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:08:03,317 - resetting layer weights
2023-12-09 19:08:03,317 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:08:03.317796', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:08:03,318 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:08:03.318277', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:04,348 - EPOCH 0 - PROGRESS: at 41.25% examples, 321244 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:05,359 - EPOCH 0 - PROGRESS: at 87.50% examples, 343501 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:08:05,591 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352429 effective words/s
2023-12-09 19:08:05,591 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351900 effective words/s', 'datetime': '2023-12-09T19:08:05.591724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:05,591 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:08:05.591904', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:08:15,365 - Processed run 7 for mu=0.75 on cuda:4. Elapsed time: 13.83 seconds
2023-12-09 19:08:17,115 - collecting all words and their counts
2023-12-09 19:08:17,115 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:08:17,176 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:08:17,176 - Creating a fresh vocabulary
2023-12-09 19:08:17,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:08:17.178226', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:17,178 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:08:17.178293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:17,181 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:08:17,181 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:08:17,181 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:08:17.181237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:17,185 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:08:17,186 - resetting layer weights
2023-12-09 19:08:17,186 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:08:17.186335', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:08:17,186 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:08:17.186853', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:18,219 - EPOCH 0 - PROGRESS: at 41.25% examples, 320514 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:19,224 - EPOCH 0 - PROGRESS: at 86.25% examples, 339178 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:19,479 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349404 effective words/s
2023-12-09 19:08:19,480 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348881 effective words/s', 'datetime': '2023-12-09T19:08:19.479976', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:19,480 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:08:19.480160', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:08:30,417 - Processed run 7 for mu=0.8 on cuda:1. Elapsed time: 15.05 seconds
2023-12-09 19:08:32,333 - collecting all words and their counts
2023-12-09 19:08:32,333 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:08:32,394 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:08:32,394 - Creating a fresh vocabulary
2023-12-09 19:08:32,396 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:08:32.396289', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:32,396 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:08:32.396367', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:32,399 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:08:32,399 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:08:32,399 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:08:32.399272', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:32,403 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:08:32,403 - resetting layer weights
2023-12-09 19:08:32,404 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:08:32.404279', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:08:32,404 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:08:32.404823', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:33,422 - EPOCH 0 - PROGRESS: at 41.25% examples, 325428 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:34,431 - EPOCH 0 - PROGRESS: at 88.75% examples, 350897 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:08:34,667 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354081 effective words/s
2023-12-09 19:08:34,667 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353540 effective words/s', 'datetime': '2023-12-09T19:08:34.667731', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:34,667 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:08:34.667925', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:08:48,749 - Processed run 7 for mu=0.85 on cuda:2. Elapsed time: 18.33 seconds
2023-12-09 19:08:50,788 - collecting all words and their counts
2023-12-09 19:08:50,788 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:08:50,854 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:08:50,854 - Creating a fresh vocabulary
2023-12-09 19:08:50,856 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:08:50.856092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:50,856 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:08:50.856168', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:50,858 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:08:50,858 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:08:50,859 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:08:50.859000', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:08:50,863 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:08:50,863 - resetting layer weights
2023-12-09 19:08:50,864 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:08:50.864035', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:08:50,864 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:08:50.864476', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:51,888 - EPOCH 0 - PROGRESS: at 41.25% examples, 323315 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:52,890 - EPOCH 0 - PROGRESS: at 87.50% examples, 346035 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:08:53,126 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354212 effective words/s
2023-12-09 19:08:53,126 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353685 effective words/s', 'datetime': '2023-12-09T19:08:53.126431', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:08:53,126 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:08:53.126518', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:09:06,229 - Processed run 7 for mu=0.9 on cuda:3. Elapsed time: 17.48 seconds
2023-12-09 19:09:08,423 - collecting all words and their counts
2023-12-09 19:09:08,423 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:09:08,484 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:09:08,484 - Creating a fresh vocabulary
2023-12-09 19:09:08,486 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:09:08.486310', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:08,486 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:09:08.486379', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:08,489 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:09:08,489 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:09:08,489 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:09:08.489278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:08,493 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:09:08,494 - resetting layer weights
2023-12-09 19:09:08,494 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:09:08.494348', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:09:08,494 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:09:08.494830', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:09,508 - EPOCH 0 - PROGRESS: at 41.25% examples, 326752 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:09:10,527 - EPOCH 0 - PROGRESS: at 87.50% examples, 344991 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:09:10,779 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350737 effective words/s
2023-12-09 19:09:10,779 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350184 effective words/s', 'datetime': '2023-12-09T19:09:10.779413', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:10,779 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:09:10.779600', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:09:24,756 - Processed run 7 for mu=0.95 on cuda:4. Elapsed time: 18.53 seconds
2023-12-09 19:09:27,307 - collecting all words and their counts
2023-12-09 19:09:27,307 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:09:27,373 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:09:27,373 - Creating a fresh vocabulary
2023-12-09 19:09:27,375 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:09:27.375650', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:27,375 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:09:27.375719', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:27,378 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:09:27,378 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:09:27,378 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:09:27.378622', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:27,383 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:09:27,383 - resetting layer weights
2023-12-09 19:09:27,383 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:09:27.383682', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:09:27,384 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:09:27.384063', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:28,403 - EPOCH 0 - PROGRESS: at 41.25% examples, 324594 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:09:29,405 - EPOCH 0 - PROGRESS: at 87.50% examples, 346874 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:09:29,647 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353879 effective words/s
2023-12-09 19:09:29,648 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353352 effective words/s', 'datetime': '2023-12-09T19:09:29.648164', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:29,648 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:09:29.648349', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:09:54,840 - Processed run 7 for mu=1.0 on cuda:1. Elapsed time: 30.08 seconds
2023-12-09 19:09:55,732 - collecting all words and their counts
2023-12-09 19:09:55,732 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:09:55,792 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:09:55,792 - Creating a fresh vocabulary
2023-12-09 19:09:55,794 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:09:55.794686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:55,794 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:09:55.794761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:55,797 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:09:55,797 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:09:55,797 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:09:55.797609', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:09:55,802 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:09:55,802 - resetting layer weights
2023-12-09 19:09:55,802 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:09:55.802770', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:09:55,803 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:09:55.803219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:56,820 - EPOCH 0 - PROGRESS: at 56.25% examples, 443681 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:09:57,401 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 501448 effective words/s
2023-12-09 19:09:57,402 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 500389 effective words/s', 'datetime': '2023-12-09T19:09:57.402047', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:09:57,402 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:09:57.402225', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:01,443 - Processed run 8 for mu=0.0 on cuda:1. Elapsed time: 6.60 seconds
2023-12-09 19:10:02,413 - collecting all words and their counts
2023-12-09 19:10:02,414 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:02,475 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:02,475 - Creating a fresh vocabulary
2023-12-09 19:10:02,477 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:02.477105', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:02,477 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:02.477181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:02,480 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:02,480 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:02,480 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:02.480083', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:02,484 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:02,484 - resetting layer weights
2023-12-09 19:10:02,485 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:02.485305', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:02,485 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:02.485777', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:03,518 - EPOCH 0 - PROGRESS: at 41.25% examples, 320502 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:04,521 - EPOCH 0 - PROGRESS: at 86.25% examples, 339485 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:04,752 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353495 effective words/s
2023-12-09 19:10:04,752 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352976 effective words/s', 'datetime': '2023-12-09T19:10:04.752278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:04,752 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:04.752370', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:09,136 - Processed run 8 for mu=0.05 on cuda:2. Elapsed time: 7.69 seconds
2023-12-09 19:10:09,897 - collecting all words and their counts
2023-12-09 19:10:09,898 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:09,957 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:09,957 - Creating a fresh vocabulary
2023-12-09 19:10:09,959 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:09.959791', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:09,959 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:09.959868', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:09,962 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:09,962 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:09,962 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:09.962832', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:09,967 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:09,967 - resetting layer weights
2023-12-09 19:10:09,968 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:09.967993', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:09,968 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:09.968475', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:10,979 - EPOCH 0 - PROGRESS: at 41.25% examples, 327424 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:11,991 - EPOCH 0 - PROGRESS: at 87.50% examples, 346554 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:12,224 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355186 effective words/s
2023-12-09 19:10:12,224 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354645 effective words/s', 'datetime': '2023-12-09T19:10:12.224332', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:12,224 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:12.224519', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:17,060 - Processed run 8 for mu=0.1 on cuda:3. Elapsed time: 7.92 seconds
2023-12-09 19:10:17,894 - collecting all words and their counts
2023-12-09 19:10:17,894 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:17,955 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:17,955 - Creating a fresh vocabulary
2023-12-09 19:10:17,957 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:17.957786', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:17,957 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:17.957858', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:17,960 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:17,960 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:17,960 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:17.960738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:17,965 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:17,965 - resetting layer weights
2023-12-09 19:10:17,965 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:17.965831', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:17,966 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:17.966254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:18,993 - EPOCH 0 - PROGRESS: at 41.25% examples, 322109 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:19,999 - EPOCH 0 - PROGRESS: at 87.50% examples, 344809 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:20,224 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354790 effective words/s
2023-12-09 19:10:20,224 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354257 effective words/s', 'datetime': '2023-12-09T19:10:20.224599', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:20,224 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:20.224789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:25,512 - Processed run 8 for mu=0.15 on cuda:4. Elapsed time: 8.45 seconds
2023-12-09 19:10:26,661 - collecting all words and their counts
2023-12-09 19:10:26,661 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:26,722 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:26,722 - Creating a fresh vocabulary
2023-12-09 19:10:26,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:26.724695', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:26,724 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:26.724760', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:26,727 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:26,727 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:26,727 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:26.727580', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:26,732 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:26,732 - resetting layer weights
2023-12-09 19:10:26,732 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:26.732546', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:26,733 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:26.733081', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:27,751 - EPOCH 0 - PROGRESS: at 41.25% examples, 324996 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:28,759 - EPOCH 0 - PROGRESS: at 86.25% examples, 340993 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:29,008 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352056 effective words/s
2023-12-09 19:10:29,008 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351545 effective words/s', 'datetime': '2023-12-09T19:10:29.008824', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:29,009 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:29.009004', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:34,132 - Processed run 8 for mu=0.2 on cuda:1. Elapsed time: 8.62 seconds
2023-12-09 19:10:34,949 - collecting all words and their counts
2023-12-09 19:10:34,949 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:35,009 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:35,009 - Creating a fresh vocabulary
2023-12-09 19:10:35,011 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:35.011485', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:35,011 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:35.011553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:35,014 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:35,014 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:35,014 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:35.014490', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:35,019 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:35,019 - resetting layer weights
2023-12-09 19:10:35,019 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:35.019560', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:35,020 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:35.020024', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:36,054 - EPOCH 0 - PROGRESS: at 41.25% examples, 319951 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:37,059 - EPOCH 0 - PROGRESS: at 86.25% examples, 338879 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:37,300 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351260 effective words/s
2023-12-09 19:10:37,301 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350737 effective words/s', 'datetime': '2023-12-09T19:10:37.301006', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:37,301 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:37.301778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:42,481 - Processed run 8 for mu=0.25 on cuda:2. Elapsed time: 8.35 seconds
2023-12-09 19:10:43,306 - collecting all words and their counts
2023-12-09 19:10:43,306 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:43,368 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:43,368 - Creating a fresh vocabulary
2023-12-09 19:10:43,370 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:43.370717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:43,370 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:43.370788', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:43,373 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:43,373 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:43,373 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:43.373634', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:43,378 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:43,378 - resetting layer weights
2023-12-09 19:10:43,378 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:43.378739', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:43,379 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:43.379209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:44,401 - EPOCH 0 - PROGRESS: at 41.25% examples, 323873 words/s, in_qsize 6, out_qsize 1
2023-12-09 19:10:45,407 - EPOCH 0 - PROGRESS: at 87.50% examples, 345625 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:45,639 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354369 effective words/s
2023-12-09 19:10:45,640 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353841 effective words/s', 'datetime': '2023-12-09T19:10:45.640185', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:45,640 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:45.640365', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:10:52,767 - Processed run 8 for mu=0.3 on cuda:3. Elapsed time: 10.28 seconds
2023-12-09 19:10:53,813 - collecting all words and their counts
2023-12-09 19:10:53,813 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:10:53,875 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:10:53,875 - Creating a fresh vocabulary
2023-12-09 19:10:53,877 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:10:53.877034', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:53,877 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:10:53.877115', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:53,879 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:10:53,879 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:10:53,879 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:10:53.879982', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:10:53,884 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:10:53,884 - resetting layer weights
2023-12-09 19:10:53,885 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:10:53.885161', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:10:53,885 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:10:53.885507', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:54,926 - EPOCH 0 - PROGRESS: at 41.25% examples, 317952 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:55,942 - EPOCH 0 - PROGRESS: at 86.25% examples, 335912 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:10:56,185 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348275 effective words/s
2023-12-09 19:10:56,186 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347760 effective words/s', 'datetime': '2023-12-09T19:10:56.186016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:10:56,186 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:10:56.186198', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:01,263 - Processed run 8 for mu=0.35 on cuda:4. Elapsed time: 8.50 seconds
2023-12-09 19:11:02,401 - collecting all words and their counts
2023-12-09 19:11:02,401 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:02,463 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:02,463 - Creating a fresh vocabulary
2023-12-09 19:11:02,465 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:02.465096', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:02,465 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:02.465167', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:02,467 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:02,467 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:02,468 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:02.468023', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:02,472 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:02,472 - resetting layer weights
2023-12-09 19:11:02,473 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:02.473065', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:02,473 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:02.473457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:03,516 - EPOCH 0 - PROGRESS: at 41.25% examples, 317396 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:11:04,536 - EPOCH 0 - PROGRESS: at 86.25% examples, 334970 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:04,776 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 347793 effective words/s
2023-12-09 19:11:04,777 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 347277 effective words/s', 'datetime': '2023-12-09T19:11:04.777172', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:04,777 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:04.777345', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:10,627 - Processed run 8 for mu=0.4 on cuda:1. Elapsed time: 9.36 seconds
2023-12-09 19:11:11,775 - collecting all words and their counts
2023-12-09 19:11:11,775 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:11,838 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:11,838 - Creating a fresh vocabulary
2023-12-09 19:11:11,841 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:11.841025', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:11,841 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:11.841121', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:11,843 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:11,843 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:11,844 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:11.844003', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:11,848 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:11,848 - resetting layer weights
2023-12-09 19:11:11,849 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:11.849133', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:11,849 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:11.849535', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:12,874 - EPOCH 0 - PROGRESS: at 41.25% examples, 323076 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:13,885 - EPOCH 0 - PROGRESS: at 86.25% examples, 339414 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:11:14,134 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350593 effective words/s
2023-12-09 19:11:14,134 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350080 effective words/s', 'datetime': '2023-12-09T19:11:14.134806', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:14,135 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:14.134990', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:20,247 - Processed run 8 for mu=0.45 on cuda:2. Elapsed time: 9.62 seconds
2023-12-09 19:11:21,360 - collecting all words and their counts
2023-12-09 19:11:21,360 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:21,421 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:21,421 - Creating a fresh vocabulary
2023-12-09 19:11:21,423 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:21.423139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:21,423 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:21.423212', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:21,426 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:21,426 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:21,426 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:21.426088', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:21,430 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:21,430 - resetting layer weights
2023-12-09 19:11:21,431 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:21.431259', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:21,431 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:21.431689', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:22,444 - EPOCH 0 - PROGRESS: at 41.25% examples, 326964 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:11:23,450 - EPOCH 0 - PROGRESS: at 86.25% examples, 342365 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:23,729 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 348579 effective words/s
2023-12-09 19:11:23,730 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348055 effective words/s', 'datetime': '2023-12-09T19:11:23.730250', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:23,730 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:23.730445', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:29,894 - Processed run 8 for mu=0.5 on cuda:3. Elapsed time: 9.65 seconds
2023-12-09 19:11:31,209 - collecting all words and their counts
2023-12-09 19:11:31,209 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:31,271 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:31,271 - Creating a fresh vocabulary
2023-12-09 19:11:31,273 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:31.273832', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:31,273 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:31.273915', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:31,276 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:31,276 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:31,276 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:31.276782', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:31,281 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:31,281 - resetting layer weights
2023-12-09 19:11:31,281 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:31.281848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:31,282 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:31.282267', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:32,294 - EPOCH 0 - PROGRESS: at 41.25% examples, 326918 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:33,318 - EPOCH 0 - PROGRESS: at 87.50% examples, 344320 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:33,544 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354099 effective words/s
2023-12-09 19:11:33,544 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353576 effective words/s', 'datetime': '2023-12-09T19:11:33.544935', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:33,545 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:33.545118', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:40,496 - Processed run 8 for mu=0.55 on cuda:4. Elapsed time: 10.60 seconds
2023-12-09 19:11:41,830 - collecting all words and their counts
2023-12-09 19:11:41,830 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:41,907 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:41,907 - Creating a fresh vocabulary
2023-12-09 19:11:41,909 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:41.909723', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:41,909 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:41.909799', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:41,912 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:41,912 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:41,912 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:41.912672', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:41,917 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:41,917 - resetting layer weights
2023-12-09 19:11:41,917 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:41.917880', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:41,918 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:41.918323', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:42,956 - EPOCH 0 - PROGRESS: at 42.50% examples, 328349 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:43,959 - EPOCH 0 - PROGRESS: at 88.75% examples, 348324 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:11:44,187 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353031 effective words/s
2023-12-09 19:11:44,187 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352517 effective words/s', 'datetime': '2023-12-09T19:11:44.187789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:44,187 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:44.187966', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:11:51,631 - Processed run 8 for mu=0.6 on cuda:1. Elapsed time: 11.13 seconds
2023-12-09 19:11:53,171 - collecting all words and their counts
2023-12-09 19:11:53,171 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:11:53,233 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:11:53,233 - Creating a fresh vocabulary
2023-12-09 19:11:53,235 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:11:53.235340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:53,235 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:11:53.235406', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:53,238 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:11:53,238 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:11:53,238 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:11:53.238325', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:11:53,243 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:11:53,243 - resetting layer weights
2023-12-09 19:11:53,243 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:11:53.243461', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:11:53,243 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:11:53.243950', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:54,273 - EPOCH 0 - PROGRESS: at 41.25% examples, 321597 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:55,275 - EPOCH 0 - PROGRESS: at 87.50% examples, 345180 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:11:55,530 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350297 effective words/s
2023-12-09 19:11:55,531 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349776 effective words/s', 'datetime': '2023-12-09T19:11:55.531201', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:11:55,531 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:11:55.531782', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:12:03,619 - Processed run 8 for mu=0.65 on cuda:2. Elapsed time: 11.99 seconds
2023-12-09 19:12:05,169 - collecting all words and their counts
2023-12-09 19:12:05,169 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:12:05,230 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:12:05,230 - Creating a fresh vocabulary
2023-12-09 19:12:05,232 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:12:05.232103', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:05,232 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:12:05.232173', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:05,235 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:12:05,235 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:12:05,235 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:12:05.235088', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:05,239 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:12:05,239 - resetting layer weights
2023-12-09 19:12:05,240 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:12:05.240166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:12:05,240 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:12:05.240712', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:06,279 - EPOCH 0 - PROGRESS: at 41.25% examples, 318753 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:12:07,281 - EPOCH 0 - PROGRESS: at 87.50% examples, 343465 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:07,515 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352146 effective words/s
2023-12-09 19:12:07,515 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351636 effective words/s', 'datetime': '2023-12-09T19:12:07.515871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:07,516 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:12:07.516054', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:12:16,415 - Processed run 8 for mu=0.7 on cuda:3. Elapsed time: 12.80 seconds
2023-12-09 19:12:18,103 - collecting all words and their counts
2023-12-09 19:12:18,103 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:12:18,163 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:12:18,163 - Creating a fresh vocabulary
2023-12-09 19:12:18,165 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:12:18.165776', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:18,165 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:12:18.165847', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:18,168 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:12:18,168 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:12:18,168 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:12:18.168710', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:18,173 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:12:18,173 - resetting layer weights
2023-12-09 19:12:18,173 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:12:18.173821', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:12:18,174 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:12:18.174262', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:19,199 - EPOCH 0 - PROGRESS: at 41.25% examples, 322757 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:20,217 - EPOCH 0 - PROGRESS: at 86.25% examples, 338295 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:20,466 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349556 effective words/s
2023-12-09 19:12:20,466 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349034 effective words/s', 'datetime': '2023-12-09T19:12:20.466377', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:20,466 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:12:20.466563', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:12:29,030 - Processed run 8 for mu=0.75 on cuda:4. Elapsed time: 12.61 seconds
2023-12-09 19:12:30,838 - collecting all words and their counts
2023-12-09 19:12:30,838 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:12:30,900 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:12:30,900 - Creating a fresh vocabulary
2023-12-09 19:12:30,902 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:12:30.902180', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:30,902 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:12:30.902248', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:30,905 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:12:30,905 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:12:30,905 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:12:30.905083', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:30,909 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:12:30,909 - resetting layer weights
2023-12-09 19:12:30,910 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:12:30.910176', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:12:30,910 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:12:30.910635', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:31,931 - EPOCH 0 - PROGRESS: at 41.25% examples, 324402 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:32,960 - EPOCH 0 - PROGRESS: at 87.50% examples, 342096 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:33,186 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351991 effective words/s
2023-12-09 19:12:33,186 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351470 effective words/s', 'datetime': '2023-12-09T19:12:33.186863', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:33,187 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:12:33.187045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:12:50,247 - Processed run 8 for mu=0.8 on cuda:1. Elapsed time: 21.22 seconds
2023-12-09 19:12:52,110 - collecting all words and their counts
2023-12-09 19:12:52,110 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:12:52,171 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:12:52,171 - Creating a fresh vocabulary
2023-12-09 19:12:52,173 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:12:52.173526', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:52,173 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:12:52.173599', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:52,176 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:12:52,176 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:12:52,176 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:12:52.176454', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:12:52,181 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:12:52,181 - resetting layer weights
2023-12-09 19:12:52,181 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:12:52.181538', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:12:52,181 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:12:52.181958', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:53,195 - EPOCH 0 - PROGRESS: at 41.25% examples, 326757 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:54,202 - EPOCH 0 - PROGRESS: at 86.25% examples, 341987 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:12:54,441 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354517 effective words/s
2023-12-09 19:12:54,441 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353997 effective words/s', 'datetime': '2023-12-09T19:12:54.441926', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:12:54,442 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:12:54.442016', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:13:29,258 - Processed run 8 for mu=0.85 on cuda:2. Elapsed time: 39.01 seconds
2023-12-09 19:13:31,341 - collecting all words and their counts
2023-12-09 19:13:31,341 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:13:31,402 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:13:31,402 - Creating a fresh vocabulary
2023-12-09 19:13:31,404 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:13:31.404075', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:31,404 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:13:31.404139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:31,406 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:13:31,406 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:13:31,406 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:13:31.406959', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:31,411 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:13:31,411 - resetting layer weights
2023-12-09 19:13:31,412 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:13:31.412026', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:13:31,412 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:13:31.412432', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:13:32,444 - EPOCH 0 - PROGRESS: at 41.25% examples, 320631 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:13:33,454 - EPOCH 0 - PROGRESS: at 86.25% examples, 338395 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:13:33,698 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350408 effective words/s
2023-12-09 19:13:33,698 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349887 effective words/s', 'datetime': '2023-12-09T19:13:33.698956', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:13:33,699 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:13:33.699137', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:13:48,126 - Processed run 8 for mu=0.9 on cuda:3. Elapsed time: 18.87 seconds
2023-12-09 19:13:50,365 - collecting all words and their counts
2023-12-09 19:13:50,365 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:13:50,426 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:13:50,426 - Creating a fresh vocabulary
2023-12-09 19:13:50,428 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:13:50.428394', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:50,428 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:13:50.428470', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:50,431 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:13:50,431 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:13:50,431 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:13:50.431339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:13:50,436 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:13:50,436 - resetting layer weights
2023-12-09 19:13:50,436 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:13:50.436467', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:13:50,436 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:13:50.436961', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:13:51,453 - EPOCH 0 - PROGRESS: at 41.25% examples, 325734 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:13:52,455 - EPOCH 0 - PROGRESS: at 90.00% examples, 357210 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:13:52,672 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 358442 effective words/s
2023-12-09 19:13:52,672 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 357907 effective words/s', 'datetime': '2023-12-09T19:13:52.672237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:13:52,672 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:13:52.672336', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:04,183 - Processed run 8 for mu=0.95 on cuda:4. Elapsed time: 16.05 seconds
2023-12-09 19:14:06,543 - collecting all words and their counts
2023-12-09 19:14:06,544 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:06,606 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:06,606 - Creating a fresh vocabulary
2023-12-09 19:14:06,608 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:06.608924', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:06,609 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:06.609003', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:06,611 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:06,611 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:06,611 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:06.611860', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:06,616 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:06,616 - resetting layer weights
2023-12-09 19:14:06,617 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:06.617071', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:06,617 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:06.617395', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:07,639 - EPOCH 0 - PROGRESS: at 41.25% examples, 323999 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:08,650 - EPOCH 0 - PROGRESS: at 87.50% examples, 344804 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:08,883 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353539 effective words/s
2023-12-09 19:14:08,883 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353018 effective words/s', 'datetime': '2023-12-09T19:14:08.883640', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:08,883 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:08.883824', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:20,785 - Processed run 8 for mu=1.0 on cuda:1. Elapsed time: 16.60 seconds
2023-12-09 19:14:21,768 - collecting all words and their counts
2023-12-09 19:14:21,768 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:21,828 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:21,828 - Creating a fresh vocabulary
2023-12-09 19:14:21,830 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:21.830440', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:21,830 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:21.830514', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:21,833 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:21,833 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:21,833 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:21.833372', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:21,838 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:21,838 - resetting layer weights
2023-12-09 19:14:21,838 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:21.838576', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:21,839 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:21.839119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:22,888 - EPOCH 0 - PROGRESS: at 56.25% examples, 430219 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:14:23,465 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 492900 effective words/s
2023-12-09 19:14:23,465 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 491866 effective words/s', 'datetime': '2023-12-09T19:14:23.465651', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:23,465 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:23.465835', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:28,891 - Processed run 9 for mu=0.0 on cuda:1. Elapsed time: 8.10 seconds
2023-12-09 19:14:29,866 - collecting all words and their counts
2023-12-09 19:14:29,866 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:29,927 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:29,927 - Creating a fresh vocabulary
2023-12-09 19:14:29,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:29.929434', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:29,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:29.929501', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:29,932 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:29,932 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:29,932 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:29.932326', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:29,937 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:29,937 - resetting layer weights
2023-12-09 19:14:29,937 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:29.937490', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:29,937 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:29.937926', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:30,971 - EPOCH 0 - PROGRESS: at 41.25% examples, 320397 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:14:31,972 - EPOCH 0 - PROGRESS: at 88.75% examples, 349435 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:32,192 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 355296 effective words/s
2023-12-09 19:14:32,192 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354781 effective words/s', 'datetime': '2023-12-09T19:14:32.192894', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:32,192 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:32.192970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:37,456 - Processed run 9 for mu=0.05 on cuda:2. Elapsed time: 8.56 seconds
2023-12-09 19:14:38,249 - collecting all words and their counts
2023-12-09 19:14:38,249 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:38,308 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:38,308 - Creating a fresh vocabulary
2023-12-09 19:14:38,310 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:38.310818', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:38,310 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:38.310899', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:38,313 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:38,313 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:38,313 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:38.313770', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:38,318 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:38,318 - resetting layer weights
2023-12-09 19:14:38,318 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:38.318826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:38,319 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:38.319297', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:39,338 - EPOCH 0 - PROGRESS: at 41.25% examples, 324738 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:40,345 - EPOCH 0 - PROGRESS: at 86.25% examples, 341091 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:40,614 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349080 effective words/s
2023-12-09 19:14:40,614 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348560 effective words/s', 'datetime': '2023-12-09T19:14:40.614529', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:40,614 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:40.614719', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:46,102 - Processed run 9 for mu=0.1 on cuda:3. Elapsed time: 8.64 seconds
2023-12-09 19:14:47,067 - collecting all words and their counts
2023-12-09 19:14:47,067 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:47,128 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:47,128 - Creating a fresh vocabulary
2023-12-09 19:14:47,130 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:47.130398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:47,130 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:47.130469', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:47,133 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:47,133 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:47,133 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:47.133368', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:47,138 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:47,138 - resetting layer weights
2023-12-09 19:14:47,138 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:47.138444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:47,138 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:47.138909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:48,164 - EPOCH 0 - PROGRESS: at 41.25% examples, 322918 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:49,167 - EPOCH 0 - PROGRESS: at 86.25% examples, 340684 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:49,408 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353022 effective words/s
2023-12-09 19:14:49,408 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 352493 effective words/s', 'datetime': '2023-12-09T19:14:49.408544', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:49,408 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:49.408828', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:14:54,098 - Processed run 9 for mu=0.15 on cuda:4. Elapsed time: 7.99 seconds
2023-12-09 19:14:55,017 - collecting all words and their counts
2023-12-09 19:14:55,017 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:14:55,078 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:14:55,078 - Creating a fresh vocabulary
2023-12-09 19:14:55,080 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:14:55.080303', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:55,080 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:14:55.080373', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:55,083 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:14:55,083 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:14:55,083 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:14:55.083255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:14:55,087 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:14:55,088 - resetting layer weights
2023-12-09 19:14:55,088 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:14:55.088337', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:14:55,088 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:14:55.088611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:56,104 - EPOCH 0 - PROGRESS: at 41.25% examples, 325961 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:57,111 - EPOCH 0 - PROGRESS: at 87.50% examples, 346642 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:14:57,382 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349227 effective words/s
2023-12-09 19:14:57,382 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348718 effective words/s', 'datetime': '2023-12-09T19:14:57.382809', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:14:57,383 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:14:57.383393', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:03,358 - Processed run 9 for mu=0.2 on cuda:1. Elapsed time: 9.26 seconds
2023-12-09 19:15:04,149 - collecting all words and their counts
2023-12-09 19:15:04,149 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:04,210 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:04,210 - Creating a fresh vocabulary
2023-12-09 19:15:04,212 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:04.212070', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:04,212 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:04.212150', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:04,214 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:04,214 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:04,214 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:04.214984', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:04,219 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:04,219 - resetting layer weights
2023-12-09 19:15:04,220 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:04.220218', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:04,220 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:04.220473', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:05,235 - EPOCH 0 - PROGRESS: at 41.25% examples, 326035 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:06,261 - EPOCH 0 - PROGRESS: at 87.50% examples, 343472 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:06,507 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350251 effective words/s
2023-12-09 19:15:06,508 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349728 effective words/s', 'datetime': '2023-12-09T19:15:06.508032', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:06,508 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:06.508667', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:11,617 - Processed run 9 for mu=0.25 on cuda:2. Elapsed time: 8.26 seconds
2023-12-09 19:15:12,539 - collecting all words and their counts
2023-12-09 19:15:12,539 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:12,601 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:12,601 - Creating a fresh vocabulary
2023-12-09 19:15:12,603 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:12.603130', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:12,603 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:12.603196', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:12,605 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:12,606 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:12,606 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:12.606048', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:12,610 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:12,610 - resetting layer weights
2023-12-09 19:15:12,611 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:12.611185', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:12,611 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:12.611447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:13,630 - EPOCH 0 - PROGRESS: at 41.25% examples, 325043 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:14,630 - EPOCH 0 - PROGRESS: at 86.25% examples, 342277 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:15:14,868 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354955 effective words/s
2023-12-09 19:15:14,868 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354402 effective words/s', 'datetime': '2023-12-09T19:15:14.868841', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:14,869 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:14.869429', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:20,366 - Processed run 9 for mu=0.3 on cuda:3. Elapsed time: 8.75 seconds
2023-12-09 19:15:21,333 - collecting all words and their counts
2023-12-09 19:15:21,333 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:21,394 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:21,394 - Creating a fresh vocabulary
2023-12-09 19:15:21,396 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:21.396246', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:21,396 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:21.396320', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:21,399 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:21,399 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:21,399 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:21.399127', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:21,403 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:21,403 - resetting layer weights
2023-12-09 19:15:21,404 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:21.404183', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:21,404 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:21.404426', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:22,448 - EPOCH 0 - PROGRESS: at 41.25% examples, 317066 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:23,451 - EPOCH 0 - PROGRESS: at 86.25% examples, 337579 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:23,683 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351586 effective words/s
2023-12-09 19:15:23,683 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351059 effective words/s', 'datetime': '2023-12-09T19:15:23.683314', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:23,683 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:23.683917', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:28,776 - Processed run 9 for mu=0.35 on cuda:4. Elapsed time: 8.41 seconds
2023-12-09 19:15:29,833 - collecting all words and their counts
2023-12-09 19:15:29,833 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:29,895 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:29,895 - Creating a fresh vocabulary
2023-12-09 19:15:29,897 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:29.897553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:29,897 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:29.897621', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:29,900 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:29,900 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:29,900 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:29.900494', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:29,905 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:29,905 - resetting layer weights
2023-12-09 19:15:29,905 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:29.905536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:29,905 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:29.905924', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:30,928 - EPOCH 0 - PROGRESS: at 41.25% examples, 323856 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:15:31,939 - EPOCH 0 - PROGRESS: at 86.25% examples, 339806 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:32,198 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 349365 effective words/s
2023-12-09 19:15:32,199 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 348860 effective words/s', 'datetime': '2023-12-09T19:15:32.199181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:32,199 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:32.199363', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:39,164 - Processed run 9 for mu=0.4 on cuda:1. Elapsed time: 10.39 seconds
2023-12-09 19:15:40,266 - collecting all words and their counts
2023-12-09 19:15:40,266 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:40,327 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:40,327 - Creating a fresh vocabulary
2023-12-09 19:15:40,329 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:40.329171', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:40,329 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:40.329244', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:40,332 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:40,332 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:40,332 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:40.332122', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:40,336 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:40,336 - resetting layer weights
2023-12-09 19:15:40,337 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:40.337158', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:40,337 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:40.337499', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:41,356 - EPOCH 0 - PROGRESS: at 41.25% examples, 324813 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:42,386 - EPOCH 0 - PROGRESS: at 88.75% examples, 346990 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:42,624 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350271 effective words/s
2023-12-09 19:15:42,624 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 349746 effective words/s', 'datetime': '2023-12-09T19:15:42.624948', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:42,625 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:42.625140', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:15:49,568 - Processed run 9 for mu=0.45 on cuda:2. Elapsed time: 10.40 seconds
2023-12-09 19:15:50,854 - collecting all words and their counts
2023-12-09 19:15:50,854 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:15:50,915 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:15:50,916 - Creating a fresh vocabulary
2023-12-09 19:15:50,917 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:15:50.917904', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:50,917 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:15:50.917975', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:50,920 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:15:50,920 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:15:50,920 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:15:50.920907', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:15:50,925 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:15:50,925 - resetting layer weights
2023-12-09 19:15:50,926 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:15:50.926157', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:15:50,926 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:15:50.926646', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:51,942 - EPOCH 0 - PROGRESS: at 41.25% examples, 325805 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:15:52,944 - EPOCH 0 - PROGRESS: at 86.25% examples, 342459 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:15:53,187 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354352 effective words/s
2023-12-09 19:15:53,187 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353828 effective words/s', 'datetime': '2023-12-09T19:15:53.187687', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:15:53,187 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:15:53.187768', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:16:00,611 - Processed run 9 for mu=0.5 on cuda:3. Elapsed time: 11.04 seconds
2023-12-09 19:16:01,922 - collecting all words and their counts
2023-12-09 19:16:01,922 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:16:01,983 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:16:01,983 - Creating a fresh vocabulary
2023-12-09 19:16:01,985 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:16:01.985685', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:01,985 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:16:01.985770', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:01,988 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:16:01,988 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:16:01,988 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:16:01.988651', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:01,993 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:16:01,993 - resetting layer weights
2023-12-09 19:16:01,993 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:16:01.993698', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:16:01,994 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:16:01.994094', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:03,014 - EPOCH 0 - PROGRESS: at 41.25% examples, 324388 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:04,024 - EPOCH 0 - PROGRESS: at 86.25% examples, 340378 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:04,252 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354724 effective words/s
2023-12-09 19:16:04,253 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354144 effective words/s', 'datetime': '2023-12-09T19:16:04.253136', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:04,253 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:16:04.253748', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:16:13,487 - Processed run 9 for mu=0.55 on cuda:4. Elapsed time: 12.87 seconds
2023-12-09 19:16:14,841 - collecting all words and their counts
2023-12-09 19:16:14,841 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:16:14,903 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:16:14,903 - Creating a fresh vocabulary
2023-12-09 19:16:14,905 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:16:14.905549', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:14,905 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:16:14.905619', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:14,908 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:16:14,908 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:16:14,908 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:16:14.908457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:14,913 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:16:14,913 - resetting layer weights
2023-12-09 19:16:14,913 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:16:14.913586', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:16:14,913 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:16:14.913923', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:15,930 - EPOCH 0 - PROGRESS: at 41.25% examples, 325568 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:16,931 - EPOCH 0 - PROGRESS: at 87.50% examples, 347556 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:17,170 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354974 effective words/s
2023-12-09 19:16:17,171 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 354455 effective words/s', 'datetime': '2023-12-09T19:16:17.170983', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:17,171 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:16:17.171173', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:16:24,663 - Processed run 9 for mu=0.6 on cuda:1. Elapsed time: 11.17 seconds
2023-12-09 19:16:26,124 - collecting all words and their counts
2023-12-09 19:16:26,124 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:16:26,185 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:16:26,185 - Creating a fresh vocabulary
2023-12-09 19:16:26,187 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:16:26.187095', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:26,187 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:16:26.187167', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:26,189 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:16:26,190 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:16:26,190 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:16:26.190078', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:26,194 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:16:26,194 - resetting layer weights
2023-12-09 19:16:26,195 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:16:26.195169', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:16:26,195 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:16:26.195612', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:27,222 - EPOCH 0 - PROGRESS: at 41.25% examples, 322241 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:16:28,230 - EPOCH 0 - PROGRESS: at 87.50% examples, 344595 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:16:28,476 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351211 effective words/s
2023-12-09 19:16:28,476 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350682 effective words/s', 'datetime': '2023-12-09T19:16:28.476950', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:28,477 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:16:28.477133', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:16:37,345 - Processed run 9 for mu=0.65 on cuda:2. Elapsed time: 12.68 seconds
2023-12-09 19:16:38,874 - collecting all words and their counts
2023-12-09 19:16:38,874 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:16:38,935 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:16:38,936 - Creating a fresh vocabulary
2023-12-09 19:16:38,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:16:38.937916', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:38,937 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:16:38.937992', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:38,941 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:16:38,941 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:16:38,941 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:16:38.941114', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:38,945 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:16:38,945 - resetting layer weights
2023-12-09 19:16:38,946 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:16:38.946229', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:16:38,946 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:16:38.946727', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:39,968 - EPOCH 0 - PROGRESS: at 41.25% examples, 323904 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:40,972 - EPOCH 0 - PROGRESS: at 86.25% examples, 341159 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:41,208 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 354269 effective words/s
2023-12-09 19:16:41,208 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353716 effective words/s', 'datetime': '2023-12-09T19:16:41.208503', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:41,208 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:16:41.208695', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:16:50,329 - Processed run 9 for mu=0.7 on cuda:3. Elapsed time: 12.98 seconds
2023-12-09 19:16:52,069 - collecting all words and their counts
2023-12-09 19:16:52,069 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:16:52,131 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:16:52,131 - Creating a fresh vocabulary
2023-12-09 19:16:52,133 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:16:52.133105', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:52,133 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:16:52.133187', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:52,135 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:16:52,135 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:16:52,136 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:16:52.136027', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:16:52,140 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:16:52,140 - resetting layer weights
2023-12-09 19:16:52,141 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:16:52.141162', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:16:52,141 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:16:52.141607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:53,153 - EPOCH 0 - PROGRESS: at 41.25% examples, 327155 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:54,182 - EPOCH 0 - PROGRESS: at 87.50% examples, 343601 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:16:54,417 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 352048 effective words/s
2023-12-09 19:16:54,417 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 351518 effective words/s', 'datetime': '2023-12-09T19:16:54.417532', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:16:54,417 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:16:54.417724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:17:03,924 - Processed run 9 for mu=0.75 on cuda:4. Elapsed time: 13.59 seconds
2023-12-09 19:17:05,734 - collecting all words and their counts
2023-12-09 19:17:05,734 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:17:05,795 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:17:05,795 - Creating a fresh vocabulary
2023-12-09 19:17:05,797 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:17:05.797586', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:05,797 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:17:05.797663', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:05,800 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:17:05,800 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:17:05,800 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:17:05.800452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:05,805 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:17:05,805 - resetting layer weights
2023-12-09 19:17:05,805 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:17:05.805435', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:17:05,805 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:17:05.805832', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:06,848 - EPOCH 0 - PROGRESS: at 41.25% examples, 317559 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:07,851 - EPOCH 0 - PROGRESS: at 86.25% examples, 337841 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:08,089 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350756 effective words/s
2023-12-09 19:17:08,090 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350231 effective words/s', 'datetime': '2023-12-09T19:17:08.090114', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:08,090 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:17:08.090301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:17:19,436 - Processed run 9 for mu=0.8 on cuda:1. Elapsed time: 15.51 seconds
2023-12-09 19:17:21,305 - collecting all words and their counts
2023-12-09 19:17:21,305 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:17:21,367 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:17:21,368 - Creating a fresh vocabulary
2023-12-09 19:17:21,369 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:17:21.369928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:21,370 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:17:21.370009', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:21,372 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:17:21,372 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:17:21,372 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:17:21.372897', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:21,377 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:17:21,377 - resetting layer weights
2023-12-09 19:17:21,377 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:17:21.377947', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:17:21,378 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:17:21.378389', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:22,417 - EPOCH 0 - PROGRESS: at 41.25% examples, 318679 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:23,422 - EPOCH 0 - PROGRESS: at 86.25% examples, 338038 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:23,662 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350742 effective words/s
2023-12-09 19:17:23,662 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350237 effective words/s', 'datetime': '2023-12-09T19:17:23.662618', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:23,662 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:17:23.662703', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:17:34,393 - Processed run 9 for mu=0.85 on cuda:2. Elapsed time: 14.96 seconds
2023-12-09 19:17:36,412 - collecting all words and their counts
2023-12-09 19:17:36,412 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:17:36,474 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:17:36,474 - Creating a fresh vocabulary
2023-12-09 19:17:36,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:17:36.476598', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:36,476 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:17:36.476670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:36,479 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:17:36,479 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:17:36,479 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:17:36.479617', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:36,484 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:17:36,484 - resetting layer weights
2023-12-09 19:17:36,484 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:17:36.484617', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:17:36,485 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:17:36.485092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:37,501 - EPOCH 0 - PROGRESS: at 41.25% examples, 325840 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:38,501 - EPOCH 0 - PROGRESS: at 87.50% examples, 347675 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:38,748 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 353901 effective words/s
2023-12-09 19:17:38,749 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 353364 effective words/s', 'datetime': '2023-12-09T19:17:38.749122', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:38,749 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:17:38.749314', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:17:51,483 - Processed run 9 for mu=0.9 on cuda:3. Elapsed time: 17.09 seconds
2023-12-09 19:17:53,648 - collecting all words and their counts
2023-12-09 19:17:53,648 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:17:53,710 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:17:53,710 - Creating a fresh vocabulary
2023-12-09 19:17:53,712 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:17:53.712545', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:53,712 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:17:53.712623', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:53,715 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:17:53,715 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:17:53,715 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:17:53.715416', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:17:53,720 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:17:53,720 - resetting layer weights
2023-12-09 19:17:53,720 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:17:53.720503', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:17:53,720 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:17:53.720933', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:54,754 - EPOCH 0 - PROGRESS: at 41.25% examples, 320188 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:17:55,768 - EPOCH 0 - PROGRESS: at 86.25% examples, 337535 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:17:56,003 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 350968 effective words/s
2023-12-09 19:17:56,003 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350470 effective words/s', 'datetime': '2023-12-09T19:17:56.003636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:17:56,003 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:17:56.003724', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:06,131 - Processed run 9 for mu=0.95 on cuda:4. Elapsed time: 14.65 seconds
2023-12-09 19:18:08,504 - collecting all words and their counts
2023-12-09 19:18:08,504 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:08,565 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:08,565 - Creating a fresh vocabulary
2023-12-09 19:18:08,567 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:08.567753', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:08,567 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:08.567817', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:08,570 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:08,570 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:08,570 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:08.570667', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:08,575 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:08,575 - resetting layer weights
2023-12-09 19:18:08,575 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:08.575717', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:08,576 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:08.576166', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:09,589 - EPOCH 0 - PROGRESS: at 45.00% examples, 356444 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:10,644 - EPOCH 0 - PROGRESS: at 91.25% examples, 353554 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:10,774 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 364444 effective words/s
2023-12-09 19:18:10,774 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 363877 effective words/s', 'datetime': '2023-12-09T19:18:10.774781', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:10,774 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:10.774960', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:23,146 - Processed run 9 for mu=1.0 on cuda:1. Elapsed time: 17.01 seconds
2023-12-09 19:18:24,108 - collecting all words and their counts
2023-12-09 19:18:24,109 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:24,167 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:24,167 - Creating a fresh vocabulary
2023-12-09 19:18:24,169 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:24.169749', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:24,169 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:24.169841', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:24,172 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:24,172 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:24,172 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:24.172725', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:24,177 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:24,177 - resetting layer weights
2023-12-09 19:18:24,177 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:24.177835', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:24,178 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:24.178369', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:25,215 - EPOCH 0 - PROGRESS: at 56.25% examples, 435592 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:25,782 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.6s, 499991 effective words/s
2023-12-09 19:18:25,782 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.6s, 498862 effective words/s', 'datetime': '2023-12-09T19:18:25.782593', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:25,782 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:25.782782', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:29,721 - Processed run 10 for mu=0.0 on cuda:1. Elapsed time: 6.57 seconds
2023-12-09 19:18:30,534 - collecting all words and their counts
2023-12-09 19:18:30,534 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:30,604 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:30,604 - Creating a fresh vocabulary
2023-12-09 19:18:30,606 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:30.606347', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:30,606 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:30.606427', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:30,609 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:30,609 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:30,609 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:30.609308', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:30,614 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:30,614 - resetting layer weights
2023-12-09 19:18:30,614 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:30.614596', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:30,615 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:30.615139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:31,619 - EPOCH 0 - PROGRESS: at 45.00% examples, 359632 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:32,671 - EPOCH 0 - PROGRESS: at 91.25% examples, 355594 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:32,798 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366994 effective words/s
2023-12-09 19:18:32,798 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366421 effective words/s', 'datetime': '2023-12-09T19:18:32.798487', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:32,799 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:32.799059', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:37,071 - Processed run 10 for mu=0.05 on cuda:2. Elapsed time: 7.35 seconds
2023-12-09 19:18:37,872 - collecting all words and their counts
2023-12-09 19:18:37,872 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:37,934 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:37,934 - Creating a fresh vocabulary
2023-12-09 19:18:37,936 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:37.936194', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:37,936 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:37.936272', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:37,939 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:37,939 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:37,939 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:37.939102', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:37,943 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:37,943 - resetting layer weights
2023-12-09 19:18:37,944 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:37.944150', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:37,944 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:37.944736', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:38,949 - EPOCH 0 - PROGRESS: at 45.00% examples, 359470 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:40,015 - EPOCH 0 - PROGRESS: at 91.25% examples, 353156 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:40,131 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366344 effective words/s
2023-12-09 19:18:40,131 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 365786 effective words/s', 'datetime': '2023-12-09T19:18:40.131879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:40,132 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:40.132049', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:44,739 - Processed run 10 for mu=0.1 on cuda:3. Elapsed time: 7.67 seconds
2023-12-09 19:18:45,452 - collecting all words and their counts
2023-12-09 19:18:45,452 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:45,512 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:45,513 - Creating a fresh vocabulary
2023-12-09 19:18:45,515 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:45.514988', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:45,515 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:45.515071', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:45,517 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:45,517 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:45,517 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:45.517978', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:45,522 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:45,522 - resetting layer weights
2023-12-09 19:18:45,523 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:45.523073', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:45,524 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:45.524366', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:46,535 - EPOCH 0 - PROGRESS: at 42.50% examples, 337436 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:18:47,538 - EPOCH 0 - PROGRESS: at 90.00% examples, 358082 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:18:47,746 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360552 effective words/s
2023-12-09 19:18:47,746 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359969 effective words/s', 'datetime': '2023-12-09T19:18:47.746933', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:47,747 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:47.747123', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:18:52,114 - Processed run 10 for mu=0.15 on cuda:4. Elapsed time: 7.37 seconds
2023-12-09 19:18:52,959 - collecting all words and their counts
2023-12-09 19:18:52,959 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:18:53,019 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:18:53,019 - Creating a fresh vocabulary
2023-12-09 19:18:53,021 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:18:53.021051', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:53,021 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:18:53.021124', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:53,023 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:18:53,023 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:18:53,024 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:18:53.024007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:18:53,028 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:18:53,028 - resetting layer weights
2023-12-09 19:18:53,028 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:18:53.028977', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:18:53,029 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:18:53.029506', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:54,037 - EPOCH 0 - PROGRESS: at 45.00% examples, 358379 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:55,089 - EPOCH 0 - PROGRESS: at 91.25% examples, 354937 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:18:55,213 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366884 effective words/s
2023-12-09 19:18:55,213 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366316 effective words/s', 'datetime': '2023-12-09T19:18:55.213483', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:18:55,213 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:18:55.213662', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:00,293 - Processed run 10 for mu=0.2 on cuda:1. Elapsed time: 8.18 seconds
2023-12-09 19:19:01,232 - collecting all words and their counts
2023-12-09 19:19:01,233 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:01,293 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:01,293 - Creating a fresh vocabulary
2023-12-09 19:19:01,295 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:01.295299', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:01,295 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:01.295377', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:01,298 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:01,298 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:01,298 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:01.298255', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:01,302 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:01,303 - resetting layer weights
2023-12-09 19:19:01,303 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:01.303307', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:01,303 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:01.303827', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:02,313 - EPOCH 0 - PROGRESS: at 45.00% examples, 357801 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:03,371 - EPOCH 0 - PROGRESS: at 91.25% examples, 353552 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:03,497 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365266 effective words/s
2023-12-09 19:19:03,497 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364705 effective words/s', 'datetime': '2023-12-09T19:19:03.497454', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:03,497 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:03.497625', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:08,695 - Processed run 10 for mu=0.25 on cuda:2. Elapsed time: 8.40 seconds
2023-12-09 19:19:09,865 - collecting all words and their counts
2023-12-09 19:19:09,866 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:09,927 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:09,928 - Creating a fresh vocabulary
2023-12-09 19:19:09,929 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:09.929956', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:09,930 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:09.930040', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:09,932 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:09,932 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:09,932 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:09.932879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:09,937 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:09,937 - resetting layer weights
2023-12-09 19:19:09,937 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:09.937934', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:09,938 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:09.938443', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:10,952 - EPOCH 0 - PROGRESS: at 45.00% examples, 356644 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:11,999 - EPOCH 0 - PROGRESS: at 91.25% examples, 354839 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:12,138 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 364340 effective words/s
2023-12-09 19:19:12,138 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 363722 effective words/s', 'datetime': '2023-12-09T19:19:12.138587', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:12,139 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:12.139209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:17,703 - Processed run 10 for mu=0.3 on cuda:3. Elapsed time: 9.01 seconds
2023-12-09 19:19:18,764 - collecting all words and their counts
2023-12-09 19:19:18,764 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:18,825 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:18,825 - Creating a fresh vocabulary
2023-12-09 19:19:18,827 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:18.827030', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:18,827 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:18.827121', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:18,829 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:18,829 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:18,830 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:18.830006', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:18,834 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:18,834 - resetting layer weights
2023-12-09 19:19:18,835 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:18.835144', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:18,835 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:18.835652', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:19,841 - EPOCH 0 - PROGRESS: at 42.50% examples, 338983 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:19:20,897 - EPOCH 0 - PROGRESS: at 91.25% examples, 354525 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:21,036 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 364083 effective words/s
2023-12-09 19:19:21,036 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 363518 effective words/s', 'datetime': '2023-12-09T19:19:21.036447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:21,036 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:21.036677', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:26,114 - Processed run 10 for mu=0.35 on cuda:4. Elapsed time: 8.41 seconds
2023-12-09 19:19:27,191 - collecting all words and their counts
2023-12-09 19:19:27,191 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:27,251 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:27,251 - Creating a fresh vocabulary
2023-12-09 19:19:27,253 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:27.253811', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:27,253 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:27.253881', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:27,256 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:27,256 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:27,256 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:27.256740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:27,261 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:27,261 - resetting layer weights
2023-12-09 19:19:27,261 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:27.261772', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:27,262 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:27.262328', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:28,272 - EPOCH 0 - PROGRESS: at 45.00% examples, 357732 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:29,334 - EPOCH 0 - PROGRESS: at 91.25% examples, 352931 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:29,459 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 364762 effective words/s
2023-12-09 19:19:29,459 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364174 effective words/s', 'datetime': '2023-12-09T19:19:29.459645', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:29,459 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:29.459834', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:35,156 - Processed run 10 for mu=0.4 on cuda:1. Elapsed time: 9.04 seconds
2023-12-09 19:19:36,214 - collecting all words and their counts
2023-12-09 19:19:36,214 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:36,276 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:36,276 - Creating a fresh vocabulary
2023-12-09 19:19:36,278 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:36.278754', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:36,278 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:36.278822', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:36,281 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:36,281 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:36,281 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:36.281709', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:36,286 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:36,286 - resetting layer weights
2023-12-09 19:19:36,286 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:36.286749', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:36,287 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:36.287283', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:37,297 - EPOCH 0 - PROGRESS: at 45.00% examples, 357568 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:38,352 - EPOCH 0 - PROGRESS: at 91.25% examples, 354186 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:38,471 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366962 effective words/s
2023-12-09 19:19:38,471 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366377 effective words/s', 'datetime': '2023-12-09T19:19:38.471344', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:38,471 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:38.471514', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:44,315 - Processed run 10 for mu=0.45 on cuda:2. Elapsed time: 9.16 seconds
2023-12-09 19:19:45,485 - collecting all words and their counts
2023-12-09 19:19:45,485 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:45,546 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:45,547 - Creating a fresh vocabulary
2023-12-09 19:19:45,548 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:45.548938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:45,549 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:45.549007', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:45,551 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:45,551 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:45,551 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:45.551876', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:45,556 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:45,556 - resetting layer weights
2023-12-09 19:19:45,557 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:45.557057', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:45,557 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:45.557557', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:46,646 - EPOCH 0 - PROGRESS: at 46.25% examples, 340879 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:47,720 - EPOCH 0 - PROGRESS: at 96.25% examples, 356587 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:19:47,735 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367893 effective words/s
2023-12-09 19:19:47,735 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367329 effective words/s', 'datetime': '2023-12-09T19:19:47.735516', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:47,735 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:47.735690', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:19:53,903 - Processed run 10 for mu=0.5 on cuda:3. Elapsed time: 9.59 seconds
2023-12-09 19:19:55,243 - collecting all words and their counts
2023-12-09 19:19:55,243 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:19:55,304 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:19:55,305 - Creating a fresh vocabulary
2023-12-09 19:19:55,307 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:19:55.307008', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:55,307 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:19:55.307076', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:55,309 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:19:55,310 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:19:55,310 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:19:55.310056', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:19:55,314 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:19:55,314 - resetting layer weights
2023-12-09 19:19:55,315 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:19:55.315162', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:19:55,315 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:19:55.315623', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:56,320 - EPOCH 0 - PROGRESS: at 45.00% examples, 359535 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:57,364 - EPOCH 0 - PROGRESS: at 91.25% examples, 356907 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:19:57,508 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365326 effective words/s
2023-12-09 19:19:57,509 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364754 effective words/s', 'datetime': '2023-12-09T19:19:57.508957', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:19:57,509 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:19:57.509145', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:04,342 - Processed run 10 for mu=0.55 on cuda:4. Elapsed time: 10.44 seconds
2023-12-09 19:20:05,714 - collecting all words and their counts
2023-12-09 19:20:05,714 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:05,777 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:05,777 - Creating a fresh vocabulary
2023-12-09 19:20:05,779 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:05.779214', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:05,779 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:05.779295', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:05,782 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:05,782 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:05,782 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:05.782121', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:05,786 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:05,786 - resetting layer weights
2023-12-09 19:20:05,787 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:05.787268', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:05,787 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:05.787784', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:06,794 - EPOCH 0 - PROGRESS: at 45.00% examples, 358788 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:20:07,866 - EPOCH 0 - PROGRESS: at 91.25% examples, 351782 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:07,981 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365318 effective words/s
2023-12-09 19:20:07,981 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364723 effective words/s', 'datetime': '2023-12-09T19:20:07.981707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:07,981 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:07.981888', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:15,527 - Processed run 10 for mu=0.6 on cuda:1. Elapsed time: 11.18 seconds
2023-12-09 19:20:16,938 - collecting all words and their counts
2023-12-09 19:20:16,938 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:17,000 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:17,001 - Creating a fresh vocabulary
2023-12-09 19:20:17,003 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:17.003057', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:17,003 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:17.003124', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:17,005 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:17,005 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:17,006 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:17.006004', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:17,010 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:17,010 - resetting layer weights
2023-12-09 19:20:17,011 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:17.011204', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:17,011 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:17.011680', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:18,048 - EPOCH 0 - PROGRESS: at 41.25% examples, 319137 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:19,059 - EPOCH 0 - PROGRESS: at 86.25% examples, 337454 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:19,292 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 351221 effective words/s
2023-12-09 19:20:19,292 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 350696 effective words/s', 'datetime': '2023-12-09T19:20:19.292928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:19,293 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:19.293112', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:27,734 - Processed run 10 for mu=0.65 on cuda:2. Elapsed time: 12.21 seconds
2023-12-09 19:20:29,313 - collecting all words and their counts
2023-12-09 19:20:29,313 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:29,375 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:29,375 - Creating a fresh vocabulary
2023-12-09 19:20:29,377 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:29.377228', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:29,377 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:29.377296', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:29,380 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:29,380 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:29,380 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:29.380141', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:29,384 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:29,384 - resetting layer weights
2023-12-09 19:20:29,385 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:29.385307', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:29,385 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:29.385716', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:30,420 - EPOCH 0 - PROGRESS: at 40.00% examples, 310118 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:31,432 - EPOCH 0 - PROGRESS: at 88.75% examples, 347501 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:31,710 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.3s, 344534 effective words/s
2023-12-09 19:20:31,711 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.3s, 344022 effective words/s', 'datetime': '2023-12-09T19:20:31.711219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:31,711 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:31.711407', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:34,265 - collecting all words and their counts
2023-12-09 19:20:34,265 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:34,359 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:34,359 - Creating a fresh vocabulary
2023-12-09 19:20:34,388 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:34.363260', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:34,388 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:34.388639', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:34,393 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:34,394 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:34,394 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:34.394093', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:34,402 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:34,402 - resetting layer weights
2023-12-09 19:20:34,404 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:34.404191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:34,404 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:34.404511', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:35,437 - EPOCH 0 - PROGRESS: at 61.25% examples, 483218 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:35,929 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 531076 effective words/s
2023-12-09 19:20:35,929 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 524626 effective words/s', 'datetime': '2023-12-09T19:20:35.929904', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:35,930 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:35.930103', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:41,461 - Processed run 10 for mu=0.7 on cuda:3. Elapsed time: 13.73 seconds
2023-12-09 19:20:43,189 - collecting all words and their counts
2023-12-09 19:20:43,190 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:43,254 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:43,254 - Creating a fresh vocabulary
2023-12-09 19:20:43,256 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:43.256510', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:43,256 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:43.256593', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:43,259 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:43,259 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:43,259 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:43.259624', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:43,264 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:43,264 - resetting layer weights
2023-12-09 19:20:43,264 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:43.264970', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:43,265 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:43.265346', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:44,269 - EPOCH 0 - PROGRESS: at 42.50% examples, 339794 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:45,340 - EPOCH 0 - PROGRESS: at 91.25% examples, 352284 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:45,476 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 362280 effective words/s
2023-12-09 19:20:45,477 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 361738 effective words/s', 'datetime': '2023-12-09T19:20:45.476963', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:45,477 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:45.477136', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:20:54,532 - Processed run 10 for mu=0.75 on cuda:4. Elapsed time: 13.07 seconds
2023-12-09 19:20:56,365 - collecting all words and their counts
2023-12-09 19:20:56,365 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:20:56,426 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:20:56,426 - Creating a fresh vocabulary
2023-12-09 19:20:56,428 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:20:56.428543', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:56,428 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:20:56.428617', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:56,431 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:20:56,431 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:20:56,431 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:20:56.431447', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:20:56,436 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:20:56,436 - resetting layer weights
2023-12-09 19:20:56,436 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:20:56.436404', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:20:56,436 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:20:56.436927', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:57,532 - EPOCH 0 - PROGRESS: at 46.25% examples, 338771 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:20:58,601 - EPOCH 0 - PROGRESS: at 96.25% examples, 356444 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:20:58,609 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368808 effective words/s
2023-12-09 19:20:58,610 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368209 effective words/s', 'datetime': '2023-12-09T19:20:58.610138', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:20:58,610 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:20:58.610640', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:21:07,973 - Processed run 10 for mu=0.8 on cuda:1. Elapsed time: 13.44 seconds
2023-12-09 19:21:09,890 - collecting all words and their counts
2023-12-09 19:21:09,891 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:21:09,955 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:21:09,955 - Creating a fresh vocabulary
2023-12-09 19:21:09,957 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:21:09.957491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:09,957 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:21:09.957569', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:09,960 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:21:09,960 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:21:09,960 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:21:09.960473', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:09,965 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:21:09,965 - resetting layer weights
2023-12-09 19:21:09,965 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:21:09.965747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:21:09,966 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:21:09.966126', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:10,978 - EPOCH 0 - PROGRESS: at 45.00% examples, 356594 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:12,036 - EPOCH 0 - PROGRESS: at 91.25% examples, 353097 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:12,157 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365653 effective words/s
2023-12-09 19:21:12,157 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 365089 effective words/s', 'datetime': '2023-12-09T19:21:12.157444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:12,157 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:21:12.157626', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:21:26,275 - Processed run 10 for mu=0.85 on cuda:2. Elapsed time: 18.30 seconds
2023-12-09 19:21:28,255 - collecting all words and their counts
2023-12-09 19:21:28,255 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:21:28,316 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:21:28,317 - Creating a fresh vocabulary
2023-12-09 19:21:28,318 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:21:28.318964', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:28,319 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:21:28.319029', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:28,321 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:21:28,321 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:21:28,321 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:21:28.321889', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:28,326 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:21:28,326 - resetting layer weights
2023-12-09 19:21:28,326 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:21:28.326962', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:21:28,327 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:21:28.327419', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:29,334 - EPOCH 0 - PROGRESS: at 45.00% examples, 358460 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:30,395 - EPOCH 0 - PROGRESS: at 91.25% examples, 353582 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:30,519 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365567 effective words/s
2023-12-09 19:21:30,519 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 365000 effective words/s', 'datetime': '2023-12-09T19:21:30.519274', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:30,519 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:21:30.519444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:21:41,719 - Processed run 10 for mu=0.9 on cuda:3. Elapsed time: 15.44 seconds
2023-12-09 19:21:43,912 - collecting all words and their counts
2023-12-09 19:21:43,912 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:21:43,974 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:21:43,974 - Creating a fresh vocabulary
2023-12-09 19:21:43,976 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:21:43.976045', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:43,976 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:21:43.976123', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:43,978 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:21:43,978 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:21:43,978 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:21:43.978940', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:21:43,983 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:21:43,983 - resetting layer weights
2023-12-09 19:21:43,983 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:21:43.983887', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:21:43,984 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:21:43.984398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:44,989 - EPOCH 0 - PROGRESS: at 43.75% examples, 349217 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:46,042 - EPOCH 0 - PROGRESS: at 91.25% examples, 355290 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:21:46,176 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365442 effective words/s
2023-12-09 19:21:46,177 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364874 effective words/s', 'datetime': '2023-12-09T19:21:46.177012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:21:46,177 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:21:46.177191', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:22:09,248 - Processed run 10 for mu=0.95 on cuda:4. Elapsed time: 27.53 seconds
2023-12-09 19:22:11,509 - collecting all words and their counts
2023-12-09 19:22:11,509 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:22:11,570 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:22:11,570 - Creating a fresh vocabulary
2023-12-09 19:22:11,572 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:22:11.572891', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:22:11,572 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:22:11.572959', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:22:11,575 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:22:11,575 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:22:11,575 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:22:11.575787', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:22:11,580 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:22:11,580 - resetting layer weights
2023-12-09 19:22:11,580 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:22:11.580837', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:22:11,581 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:22:11.581340', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:22:12,667 - EPOCH 0 - PROGRESS: at 46.25% examples, 341595 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:22:13,733 - EPOCH 0 - PROGRESS: at 96.25% examples, 358356 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:22:13,739 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 371306 effective words/s
2023-12-09 19:22:13,739 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 370728 effective words/s', 'datetime': '2023-12-09T19:22:13.739421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:22:13,739 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:22:13.739590', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:22:24,304 - Processed run 10 for mu=1.0 on cuda:1. Elapsed time: 15.05 seconds
2023-12-09 19:23:27,455 - collecting all words and their counts
2023-12-09 19:23:27,455 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:23:27,512 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:23:27,512 - Creating a fresh vocabulary
2023-12-09 19:23:27,541 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:23:27.514209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:27,542 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:23:27.542221', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:27,547 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:23:27,548 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:23:27,548 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:23:27.548290', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:27,554 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:23:27,554 - resetting layer weights
2023-12-09 19:23:27,555 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:23:27.555658', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:23:27,555 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:23:27.555789', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:28,567 - EPOCH 0 - PROGRESS: at 60.00% examples, 476448 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:23:29,085 - EPOCH 0: training on 800000 raw words (800000 effective words) took 1.5s, 524602 effective words/s
2023-12-09 19:23:29,085 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 1.5s, 523071 effective words/s', 'datetime': '2023-12-09T19:23:29.085606', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:29,085 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:23:29.085807', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:23:35,774 - Processed run 1 for mu=0.0 on cuda:1. Elapsed time: 10.05 seconds
2023-12-09 19:23:36,673 - collecting all words and their counts
2023-12-09 19:23:36,674 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:23:36,731 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:23:36,731 - Creating a fresh vocabulary
2023-12-09 19:23:36,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:23:36.733487', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:36,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:23:36.733581', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:36,736 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:23:36,736 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:23:36,736 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:23:36.736453', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:36,741 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:23:36,741 - resetting layer weights
2023-12-09 19:23:36,741 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:23:36.741452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:23:36,741 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:23:36.741953', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:37,745 - EPOCH 0 - PROGRESS: at 46.25% examples, 369964 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:23:38,768 - EPOCH 0 - PROGRESS: at 100.00% examples, 395500 words/s, in_qsize 0, out_qsize 1
2023-12-09 19:23:38,768 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 395451 effective words/s
2023-12-09 19:23:38,768 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 394771 effective words/s', 'datetime': '2023-12-09T19:23:38.768515', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:38,769 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:23:38.769193', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:23:43,049 - Processed run 1 for mu=0.05 on cuda:2. Elapsed time: 7.27 seconds
2023-12-09 19:23:43,916 - collecting all words and their counts
2023-12-09 19:23:43,916 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:23:43,975 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:23:43,975 - Creating a fresh vocabulary
2023-12-09 19:23:43,977 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:23:43.977482', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:43,977 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:23:43.977560', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:43,980 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:23:43,980 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:23:43,980 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:23:43.980399', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:43,985 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:23:43,985 - resetting layer weights
2023-12-09 19:23:43,985 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:23:43.985420', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:23:43,985 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:23:43.985777', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:44,990 - EPOCH 0 - PROGRESS: at 45.00% examples, 359571 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:23:46,005 - EPOCH 0 - PROGRESS: at 91.25% examples, 362091 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:23:46,157 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368971 effective words/s
2023-12-09 19:23:46,157 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368359 effective words/s', 'datetime': '2023-12-09T19:23:46.157650', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:46,157 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:23:46.157826', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:23:50,848 - Processed run 1 for mu=0.1 on cuda:3. Elapsed time: 7.80 seconds
2023-12-09 19:23:51,651 - collecting all words and their counts
2023-12-09 19:23:51,651 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:23:51,708 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:23:51,708 - Creating a fresh vocabulary
2023-12-09 19:23:51,710 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:23:51.710648', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:51,710 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:23:51.710722', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:51,713 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:23:51,713 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:23:51,713 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:23:51.713588', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:51,718 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:23:51,718 - resetting layer weights
2023-12-09 19:23:51,718 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:23:51.718561', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:23:51,719 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:23:51.719012', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:52,732 - EPOCH 0 - PROGRESS: at 46.25% examples, 366489 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:23:53,735 - EPOCH 0 - PROGRESS: at 100.00% examples, 397346 words/s, in_qsize 0, out_qsize 1
2023-12-09 19:23:53,736 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 397298 effective words/s
2023-12-09 19:23:53,736 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 396609 effective words/s', 'datetime': '2023-12-09T19:23:53.736181', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:23:53,736 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:23:53.736853', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:23:57,997 - Processed run 1 for mu=0.15 on cuda:4. Elapsed time: 7.15 seconds
2023-12-09 19:23:58,928 - collecting all words and their counts
2023-12-09 19:23:58,929 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:23:58,986 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:23:58,986 - Creating a fresh vocabulary
2023-12-09 19:23:58,988 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:23:58.988483', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:58,988 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:23:58.988550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:58,991 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:23:58,991 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:23:58,991 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:23:58.991379', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:23:58,995 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:23:58,995 - resetting layer weights
2023-12-09 19:23:58,996 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:23:58.996359', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:23:58,996 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:23:58.996851', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:00,030 - EPOCH 0 - PROGRESS: at 46.25% examples, 359500 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:01,032 - EPOCH 0 - PROGRESS: at 96.25% examples, 378946 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:24:01,038 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 392681 effective words/s
2023-12-09 19:24:01,038 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 392001 effective words/s', 'datetime': '2023-12-09T19:24:01.038287', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:01,038 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:01.038457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:07,470 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 9.47 seconds
2023-12-09 19:24:08,364 - collecting all words and their counts
2023-12-09 19:24:08,364 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:08,422 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:08,422 - Creating a fresh vocabulary
2023-12-09 19:24:08,424 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:08.424636', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:08,424 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:08.424703', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:08,427 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:08,427 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:08,427 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:08.427469', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:08,432 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:08,432 - resetting layer weights
2023-12-09 19:24:08,432 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:08.432377', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:08,432 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:08.432905', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:09,537 - EPOCH 0 - PROGRESS: at 46.25% examples, 336107 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:10,602 - EPOCH 0 - PROGRESS: at 96.25% examples, 355444 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:24:10,625 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365378 effective words/s
2023-12-09 19:24:10,625 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 364809 effective words/s', 'datetime': '2023-12-09T19:24:10.625908', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:10,626 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:10.626479', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:16,420 - Processed run 1 for mu=0.25 on cuda:2. Elapsed time: 8.95 seconds
2023-12-09 19:24:17,261 - collecting all words and their counts
2023-12-09 19:24:17,261 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:17,320 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:17,320 - Creating a fresh vocabulary
2023-12-09 19:24:17,322 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:17.322132', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:17,322 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:17.322209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:17,324 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:17,325 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:17,325 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:17.325051', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:17,329 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:17,329 - resetting layer weights
2023-12-09 19:24:17,330 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:17.330072', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:17,330 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:17.330540', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:18,341 - EPOCH 0 - PROGRESS: at 47.50% examples, 377270 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:19,317 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 403463 effective words/s
2023-12-09 19:24:19,317 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 402716 effective words/s', 'datetime': '2023-12-09T19:24:19.317573', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:19,317 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:19.317762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:24,955 - Processed run 1 for mu=0.3 on cuda:3. Elapsed time: 8.53 seconds
2023-12-09 19:24:26,050 - collecting all words and their counts
2023-12-09 19:24:26,050 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:26,110 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:26,110 - Creating a fresh vocabulary
2023-12-09 19:24:26,113 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:26.113021', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:26,113 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:26.113119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:26,115 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:26,116 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:26,116 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:26.116089', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:26,120 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:26,120 - resetting layer weights
2023-12-09 19:24:26,121 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:26.121338', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:26,121 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:26.121550', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:27,128 - EPOCH 0 - PROGRESS: at 42.50% examples, 338608 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:28,131 - EPOCH 0 - PROGRESS: at 90.00% examples, 358855 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:24:28,343 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 360496 effective words/s
2023-12-09 19:24:28,344 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 359952 effective words/s', 'datetime': '2023-12-09T19:24:28.344168', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:28,344 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:28.344424', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:33,607 - Processed run 1 for mu=0.35 on cuda:4. Elapsed time: 8.65 seconds
2023-12-09 19:24:34,670 - collecting all words and their counts
2023-12-09 19:24:34,670 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:34,731 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:34,731 - Creating a fresh vocabulary
2023-12-09 19:24:34,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:34.733174', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:34,733 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:34.733250', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:34,736 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:34,736 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:34,736 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:34.736095', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:34,740 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:34,740 - resetting layer weights
2023-12-09 19:24:34,741 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:34.741136', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:34,741 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:34.741551', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:35,822 - EPOCH 0 - PROGRESS: at 46.25% examples, 343482 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:36,870 - EPOCH 0 - PROGRESS: at 96.25% examples, 362272 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:24:36,889 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 373084 effective words/s
2023-12-09 19:24:36,889 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 372459 effective words/s', 'datetime': '2023-12-09T19:24:36.889905', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:36,890 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:36.890094', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:42,508 - Processed run 1 for mu=0.4 on cuda:1. Elapsed time: 8.90 seconds
2023-12-09 19:24:43,604 - collecting all words and their counts
2023-12-09 19:24:43,604 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:43,664 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:43,664 - Creating a fresh vocabulary
2023-12-09 19:24:43,666 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:43.666043', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:43,666 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:43.666117', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:43,668 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:43,668 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:43,668 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:43.668957', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:43,673 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:43,673 - resetting layer weights
2023-12-09 19:24:43,674 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:43.674020', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:43,674 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:43.674553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:44,772 - EPOCH 0 - PROGRESS: at 46.25% examples, 338224 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:45,841 - EPOCH 0 - PROGRESS: at 96.25% examples, 355932 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:24:45,866 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 365602 effective words/s
2023-12-09 19:24:45,866 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 365018 effective words/s', 'datetime': '2023-12-09T19:24:45.866718', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:45,866 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:45.866888', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:24:51,808 - Processed run 1 for mu=0.45 on cuda:2. Elapsed time: 9.30 seconds
2023-12-09 19:24:52,948 - collecting all words and their counts
2023-12-09 19:24:52,948 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:24:53,006 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:24:53,006 - Creating a fresh vocabulary
2023-12-09 19:24:53,008 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:24:53.008611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:53,008 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:24:53.008686', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:53,011 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:24:53,011 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:24:53,011 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:24:53.011478', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:24:53,016 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:24:53,016 - resetting layer weights
2023-12-09 19:24:53,016 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:24:53.016378', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:24:53,016 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:24:53.016936', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:54,029 - EPOCH 0 - PROGRESS: at 48.75% examples, 386560 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:24:55,006 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 402941 effective words/s
2023-12-09 19:24:55,006 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 402218 effective words/s', 'datetime': '2023-12-09T19:24:55.006369', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:24:55,006 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:24:55.006553', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:25:01,284 - Processed run 1 for mu=0.5 on cuda:3. Elapsed time: 9.47 seconds
2023-12-09 19:25:02,546 - collecting all words and their counts
2023-12-09 19:25:02,546 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:25:02,605 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:25:02,605 - Creating a fresh vocabulary
2023-12-09 19:25:02,607 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:25:02.607418', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:02,607 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:25:02.607482', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:02,610 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:25:02,610 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:25:02,610 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:25:02.610351', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:02,614 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:25:02,614 - resetting layer weights
2023-12-09 19:25:02,615 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:25:02.615266', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:25:02,615 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:25:02.615810', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:03,629 - EPOCH 0 - PROGRESS: at 50.00% examples, 395876 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:04,598 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 404183 effective words/s
2023-12-09 19:25:04,599 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 403484 effective words/s', 'datetime': '2023-12-09T19:25:04.599074', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:04,599 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:25:04.599254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:25:12,255 - Processed run 1 for mu=0.55 on cuda:4. Elapsed time: 10.97 seconds
2023-12-09 19:25:13,632 - collecting all words and their counts
2023-12-09 19:25:13,632 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:25:13,691 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:25:13,691 - Creating a fresh vocabulary
2023-12-09 19:25:13,693 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:25:13.693509', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:13,693 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:25:13.693587', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:13,696 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:25:13,696 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:25:13,696 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:25:13.696457', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:13,701 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:25:13,701 - resetting layer weights
2023-12-09 19:25:13,701 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:25:13.701392', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:25:13,701 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:25:13.701806', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:14,717 - EPOCH 0 - PROGRESS: at 45.00% examples, 355613 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:15,741 - EPOCH 0 - PROGRESS: at 91.25% examples, 358458 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:15,889 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366194 effective words/s
2023-12-09 19:25:15,889 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 365621 effective words/s', 'datetime': '2023-12-09T19:25:15.889937', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:15,890 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:25:15.890128', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:25:23,026 - Processed run 1 for mu=0.6 on cuda:1. Elapsed time: 10.77 seconds
2023-12-09 19:25:24,429 - collecting all words and their counts
2023-12-09 19:25:24,429 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:25:24,488 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:25:24,488 - Creating a fresh vocabulary
2023-12-09 19:25:24,490 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:25:24.490639', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:24,490 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:25:24.490716', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:24,493 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:25:24,493 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:25:24,493 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:25:24.493607', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:24,498 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:25:24,498 - resetting layer weights
2023-12-09 19:25:24,498 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:25:24.498626', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:25:24,499 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:25:24.499149', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:25,513 - EPOCH 0 - PROGRESS: at 47.50% examples, 375933 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:26,515 - EPOCH 0 - PROGRESS: at 100.00% examples, 397414 words/s, in_qsize 0, out_qsize 1
2023-12-09 19:25:26,516 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 397385 effective words/s
2023-12-09 19:25:26,516 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 396728 effective words/s', 'datetime': '2023-12-09T19:25:26.516128', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:26,516 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:25:26.516201', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:25:33,894 - Processed run 1 for mu=0.65 on cuda:2. Elapsed time: 10.87 seconds
2023-12-09 19:25:35,413 - collecting all words and their counts
2023-12-09 19:25:35,413 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:25:35,471 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:25:35,472 - Creating a fresh vocabulary
2023-12-09 19:25:35,473 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:25:35.473879', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:35,473 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:25:35.473962', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:35,476 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:25:35,476 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:25:35,476 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:25:35.476906', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:35,481 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:25:35,481 - resetting layer weights
2023-12-09 19:25:35,481 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:25:35.481889', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:25:35,482 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:25:35.482301', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:36,492 - EPOCH 0 - PROGRESS: at 45.00% examples, 357614 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:37,519 - EPOCH 0 - PROGRESS: at 91.25% examples, 358876 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:37,655 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368636 effective words/s
2023-12-09 19:25:37,655 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368086 effective words/s', 'datetime': '2023-12-09T19:25:37.655778', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:37,655 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:25:37.655955', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:25:47,057 - Processed run 1 for mu=0.7 on cuda:3. Elapsed time: 13.16 seconds
2023-12-09 19:25:48,753 - collecting all words and their counts
2023-12-09 19:25:48,753 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:25:48,812 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:25:48,812 - Creating a fresh vocabulary
2023-12-09 19:25:48,814 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:25:48.814216', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:48,814 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:25:48.814292', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:48,817 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:25:48,817 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:25:48,817 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:25:48.817183', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:25:48,821 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:25:48,821 - resetting layer weights
2023-12-09 19:25:48,822 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:25:48.822147', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:25:48,822 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:25:48.822638', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:49,831 - EPOCH 0 - PROGRESS: at 45.00% examples, 357812 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:50,853 - EPOCH 0 - PROGRESS: at 91.25% examples, 360071 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:25:50,994 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368960 effective words/s
2023-12-09 19:25:50,994 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368378 effective words/s', 'datetime': '2023-12-09T19:25:50.994395', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:25:50,994 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:25:50.994579', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:26:00,996 - Processed run 1 for mu=0.75 on cuda:4. Elapsed time: 13.94 seconds
2023-12-09 19:26:02,784 - collecting all words and their counts
2023-12-09 19:26:02,784 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:26:02,842 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:26:02,842 - Creating a fresh vocabulary
2023-12-09 19:26:02,844 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:26:02.844796', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:02,844 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:26:02.844871', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:02,847 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:26:02,847 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:26:02,847 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:26:02.847710', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:02,852 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:26:02,852 - resetting layer weights
2023-12-09 19:26:02,852 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:26:02.852605', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:26:02,853 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:26:02.853096', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:03,948 - EPOCH 0 - PROGRESS: at 46.25% examples, 339008 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:26:05,005 - EPOCH 0 - PROGRESS: at 96.25% examples, 358385 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:26:05,031 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367817 effective words/s
2023-12-09 19:26:05,032 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367226 effective words/s', 'datetime': '2023-12-09T19:26:05.032063', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:05,032 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:26:05.032244', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:26:16,463 - Processed run 1 for mu=0.8 on cuda:1. Elapsed time: 15.47 seconds
2023-12-09 19:26:18,465 - collecting all words and their counts
2023-12-09 19:26:18,465 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:26:18,523 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:26:18,524 - Creating a fresh vocabulary
2023-12-09 19:26:18,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:26:18.525859', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:18,525 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:26:18.525929', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:18,528 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:26:18,528 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:26:18,528 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:26:18.528804', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:18,533 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:26:18,533 - resetting layer weights
2023-12-09 19:26:18,533 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:26:18.533760', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:26:18,534 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:26:18.534310', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:19,545 - EPOCH 0 - PROGRESS: at 45.00% examples, 357051 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:26:20,593 - EPOCH 0 - PROGRESS: at 91.25% examples, 355158 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:26:20,717 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367062 effective words/s
2023-12-09 19:26:20,717 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366479 effective words/s', 'datetime': '2023-12-09T19:26:20.717365', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:20,717 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:26:20.717536', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:26:31,532 - Processed run 1 for mu=0.85 on cuda:2. Elapsed time: 15.07 seconds
2023-12-09 19:26:33,527 - collecting all words and their counts
2023-12-09 19:26:33,527 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:26:33,586 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:26:33,586 - Creating a fresh vocabulary
2023-12-09 19:26:33,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:26:33.588321', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:33,588 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:26:33.588398', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:33,591 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:26:33,591 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:26:33,591 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:26:33.591219', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:33,595 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:26:33,595 - resetting layer weights
2023-12-09 19:26:33,596 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:26:33.596192', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:26:33,596 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:26:33.596730', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:34,678 - EPOCH 0 - PROGRESS: at 46.25% examples, 343093 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:26:35,740 - EPOCH 0 - PROGRESS: at 96.25% examples, 359871 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:26:35,756 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 371026 effective words/s
2023-12-09 19:26:35,756 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 370448 effective words/s', 'datetime': '2023-12-09T19:26:35.756809', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:35,756 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:26:35.756874', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:26:49,311 - Processed run 1 for mu=0.9 on cuda:3. Elapsed time: 17.78 seconds
2023-12-09 19:26:51,749 - collecting all words and their counts
2023-12-09 19:26:51,750 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:26:51,807 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:26:51,807 - Creating a fresh vocabulary
2023-12-09 19:26:51,809 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:26:51.809669', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:51,809 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:26:51.809742', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:51,812 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:26:51,812 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:26:51,812 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:26:51.812556', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:26:51,817 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:26:51,817 - resetting layer weights
2023-12-09 19:26:51,817 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:26:51.817543', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:26:51,817 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:26:51.817957', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:52,840 - EPOCH 0 - PROGRESS: at 47.50% examples, 372950 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:26:53,834 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 397380 effective words/s
2023-12-09 19:26:53,834 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 396721 effective words/s', 'datetime': '2023-12-09T19:26:53.834558', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:26:53,834 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:26:53.834747', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:27:04,485 - Processed run 1 for mu=0.95 on cuda:4. Elapsed time: 15.17 seconds
2023-12-09 19:27:06,947 - collecting all words and their counts
2023-12-09 19:27:06,947 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:27:07,005 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:27:07,005 - Creating a fresh vocabulary
2023-12-09 19:27:07,007 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:27:07.007672', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:27:07,007 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:27:07.007734', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:27:07,010 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:27:07,010 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:27:07,010 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:27:07.010585', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:27:07,015 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:27:07,015 - resetting layer weights
2023-12-09 19:27:07,015 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:27:07.015547', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:27:07,016 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:27:07.016022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:27:08,098 - EPOCH 0 - PROGRESS: at 46.25% examples, 343155 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:27:09,159 - EPOCH 0 - PROGRESS: at 96.25% examples, 359958 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:27:09,190 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368555 effective words/s
2023-12-09 19:27:09,190 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367922 effective words/s', 'datetime': '2023-12-09T19:27:09.190928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:27:09,191 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:27:09.191096', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:27:21,035 - Processed run 1 for mu=1.0 on cuda:1. Elapsed time: 16.55 seconds
2023-12-09 19:38:37,091 - collecting all words and their counts
2023-12-09 19:38:37,091 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:38:37,149 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:38:37,150 - Creating a fresh vocabulary
2023-12-09 19:38:37,179 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:38:37.152087', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:37,180 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:38:37.180283', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:37,184 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:38:37,185 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:38:37,185 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:38:37.185139', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:37,191 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:38:37,191 - resetting layer weights
2023-12-09 19:38:37,191 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:38:37.191716', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:38:37,191 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:38:37.191842', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:38,211 - EPOCH 0 - PROGRESS: at 47.50% examples, 374348 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:38:39,198 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 399535 effective words/s
2023-12-09 19:38:39,198 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 398668 effective words/s', 'datetime': '2023-12-09T19:38:39.198600', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:39,198 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:38:39.198802', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:38:46,977 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.43 seconds
2023-12-09 19:38:48,037 - collecting all words and their counts
2023-12-09 19:38:48,037 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:38:48,097 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:38:48,097 - Creating a fresh vocabulary
2023-12-09 19:38:48,099 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:38:48.099810', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:48,099 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:38:48.099909', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:48,102 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:38:48,102 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:38:48,102 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:38:48.102874', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:48,107 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:38:48,107 - resetting layer weights
2023-12-09 19:38:48,108 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:38:48.108283', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:38:48,108 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:38:48.108738', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:49,209 - EPOCH 0 - PROGRESS: at 46.25% examples, 337207 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:38:50,269 - EPOCH 0 - PROGRESS: at 96.25% examples, 356916 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:38:50,294 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 366661 effective words/s
2023-12-09 19:38:50,294 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366058 effective words/s', 'datetime': '2023-12-09T19:38:50.294259', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:50,294 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:38:50.294438', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:38:56,965 - Processed run 1 for mu=0.4 on cuda:2. Elapsed time: 9.99 seconds
2023-12-09 19:38:57,695 - collecting all words and their counts
2023-12-09 19:38:57,696 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:38:57,755 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:38:57,755 - Creating a fresh vocabulary
2023-12-09 19:38:57,757 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:38:57.757119', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:57,757 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:38:57.757188', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:57,759 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:38:57,760 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:38:57,760 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:38:57.760052', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:38:57,765 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:38:57,765 - resetting layer weights
2023-12-09 19:38:57,765 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:38:57.765628', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:38:57,766 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:38:57.766022', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:58,773 - EPOCH 0 - PROGRESS: at 45.00% examples, 358716 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:38:59,788 - EPOCH 0 - PROGRESS: at 91.25% examples, 361515 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:38:59,928 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 370574 effective words/s
2023-12-09 19:38:59,928 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 369957 effective words/s', 'datetime': '2023-12-09T19:38:59.928512', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:38:59,928 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:38:59.928670', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:39:06,122 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 9.16 seconds
2023-12-09 19:39:07,179 - collecting all words and their counts
2023-12-09 19:39:07,179 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:39:07,239 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:39:07,239 - Creating a fresh vocabulary
2023-12-09 19:39:07,241 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:39:07.241869', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:39:07,241 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:39:07.241967', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:39:07,244 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:39:07,244 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:39:07,244 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:39:07.244971', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:39:07,250 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:39:07,250 - resetting layer weights
2023-12-09 19:39:07,250 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:39:07.250444', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:39:07,250 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:39:07.250938', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:39:08,342 - EPOCH 0 - PROGRESS: at 46.25% examples, 340272 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:39:09,397 - EPOCH 0 - PROGRESS: at 96.25% examples, 359306 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:39:09,424 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368670 effective words/s
2023-12-09 19:39:09,424 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368084 effective words/s', 'datetime': '2023-12-09T19:39:09.424902', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:39:09,425 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:39:09.425073', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:39:14,997 - Processed run 2 for mu=0.4 on cuda:2. Elapsed time: 8.87 seconds
2023-12-09 19:42:18,277 - collecting all words and their counts
2023-12-09 19:42:18,277 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:42:18,336 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:42:18,336 - Creating a fresh vocabulary
2023-12-09 19:42:18,365 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:42:18.338331', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:18,365 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:42:18.365890', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:18,370 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:42:18,371 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:42:18,371 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:42:18.371103', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:18,378 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:42:18,378 - resetting layer weights
2023-12-09 19:42:18,379 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:42:18.379496', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:42:18,379 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:42:18.379691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:19,474 - EPOCH 0 - PROGRESS: at 46.25% examples, 339380 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:42:20,543 - EPOCH 0 - PROGRESS: at 96.25% examples, 356520 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:42:20,550 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 369314 effective words/s
2023-12-09 19:42:20,550 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368569 effective words/s', 'datetime': '2023-12-09T19:42:20.550326', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:20,550 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:42:20.550520', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:42:31,896 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 15.21 seconds
2023-12-09 19:42:32,929 - collecting all words and their counts
2023-12-09 19:42:32,929 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:42:32,991 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:42:32,991 - Creating a fresh vocabulary
2023-12-09 19:42:32,993 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:42:32.993641', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:32,993 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:42:32.993753', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:32,996 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:42:32,996 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:42:32,996 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:42:32.996802', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:33,001 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:42:33,001 - resetting layer weights
2023-12-09 19:42:33,002 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:42:33.002231', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:42:33,002 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:42:33.002740', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:34,006 - EPOCH 0 - PROGRESS: at 45.00% examples, 359958 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:42:35,041 - EPOCH 0 - PROGRESS: at 91.25% examples, 358754 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:42:35,181 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367853 effective words/s
2023-12-09 19:42:35,181 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367227 effective words/s', 'datetime': '2023-12-09T19:42:35.181712', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:35,181 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:42:35.181794', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:42:41,183 - Processed run 1 for mu=0.4 on cuda:2. Elapsed time: 9.29 seconds
2023-12-09 19:42:42,131 - collecting all words and their counts
2023-12-09 19:42:42,131 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:42:42,189 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:42:42,189 - Creating a fresh vocabulary
2023-12-09 19:42:42,191 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:42:42.191491', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:42,191 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:42:42.191577', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:42,194 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:42:42,194 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:42:42,194 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:42:42.194613', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:42,199 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:42:42,199 - resetting layer weights
2023-12-09 19:42:42,200 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:42:42.200059', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:42:42,200 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:42:42.200516', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:43,296 - EPOCH 0 - PROGRESS: at 46.25% examples, 338635 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:42:44,361 - EPOCH 0 - PROGRESS: at 96.25% examples, 356823 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:42:44,375 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 368389 effective words/s
2023-12-09 19:42:44,375 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 367780 effective words/s', 'datetime': '2023-12-09T19:42:44.375807', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:44,376 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:42:44.375977', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:42:49,620 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 8.44 seconds
2023-12-09 19:42:50,621 - collecting all words and their counts
2023-12-09 19:42:50,621 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:42:50,682 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:42:50,683 - Creating a fresh vocabulary
2023-12-09 19:42:50,685 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:42:50.685050', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:50,685 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:42:50.685134', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:50,688 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:42:50,688 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:42:50,688 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:42:50.688116', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:42:50,693 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:42:50,693 - resetting layer weights
2023-12-09 19:42:50,693 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:42:50.693622', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:42:50,694 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:42:50.694033', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:51,782 - EPOCH 0 - PROGRESS: at 46.25% examples, 340967 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:42:52,843 - EPOCH 0 - PROGRESS: at 96.25% examples, 358759 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:42:52,864 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 369049 effective words/s
2023-12-09 19:42:52,865 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 368488 effective words/s', 'datetime': '2023-12-09T19:42:52.865141', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:42:52,865 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:42:52.865306', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:42:58,374 - Processed run 2 for mu=0.4 on cuda:2. Elapsed time: 8.75 seconds
2023-12-09 19:44:39,114 - collecting all words and their counts
2023-12-09 19:44:39,114 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:44:39,173 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:44:39,173 - Creating a fresh vocabulary
2023-12-09 19:44:39,203 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:44:39.175517', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:39,203 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:44:39.203355', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:39,207 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:44:39,208 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:44:39,208 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:44:39.208452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:39,215 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:44:39,215 - resetting layer weights
2023-12-09 19:44:39,216 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:44:39.216129', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:44:39,216 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:44:39.216310', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:44:40,301 - EPOCH 0 - PROGRESS: at 46.25% examples, 342572 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:44:41,346 - EPOCH 0 - PROGRESS: at 96.25% examples, 362354 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:44:41,356 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 374591 effective words/s
2023-12-09 19:44:41,357 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 373811 effective words/s', 'datetime': '2023-12-09T19:44:41.356947', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:44:41,357 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:44:41.357209', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:44:49,285 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.71 seconds
2023-12-09 19:44:50,312 - collecting all words and their counts
2023-12-09 19:44:50,312 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:44:50,373 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:44:50,373 - Creating a fresh vocabulary
2023-12-09 19:44:50,375 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:44:50.375069', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:50,375 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:44:50.375163', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:50,378 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:44:50,378 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:44:50,378 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:44:50.378117', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:50,382 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:44:50,383 - resetting layer weights
2023-12-09 19:44:50,383 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:44:50.383433', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:44:50,384 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:44:50.384038', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:44:51,392 - EPOCH 0 - PROGRESS: at 45.00% examples, 358492 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:44:52,412 - EPOCH 0 - PROGRESS: at 91.25% examples, 360557 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:44:52,564 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367505 effective words/s
2023-12-09 19:44:52,565 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366862 effective words/s', 'datetime': '2023-12-09T19:44:52.565154', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:44:52,565 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:44:52.565869', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:44:58,322 - Processed run 1 for mu=0.4 on cuda:2. Elapsed time: 9.04 seconds
2023-12-09 19:44:59,233 - collecting all words and their counts
2023-12-09 19:44:59,233 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:44:59,291 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:44:59,291 - Creating a fresh vocabulary
2023-12-09 19:44:59,293 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:44:59.293793', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:59,293 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:44:59.293865', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:59,296 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:44:59,296 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:44:59,296 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:44:59.296807', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:44:59,301 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:44:59,301 - resetting layer weights
2023-12-09 19:44:59,301 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:44:59.301928', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:44:59,302 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:44:59.302413', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:45:00,320 - EPOCH 0 - PROGRESS: at 47.50% examples, 374589 words/s, in_qsize 8, out_qsize 0
2023-12-09 19:45:01,318 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 397622 effective words/s
2023-12-09 19:45:01,318 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 396910 effective words/s', 'datetime': '2023-12-09T19:45:01.318504', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:45:01,318 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:45:01.318691', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:45:06,229 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 7.91 seconds
2023-12-09 19:45:07,316 - collecting all words and their counts
2023-12-09 19:45:07,316 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:45:07,375 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:45:07,375 - Creating a fresh vocabulary
2023-12-09 19:45:07,377 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:45:07.377487', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:45:07,377 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:45:07.377561', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:45:07,380 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:45:07,380 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:45:07,380 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:45:07.380387', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:45:07,385 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:45:07,385 - resetting layer weights
2023-12-09 19:45:07,385 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:45:07.385440', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:45:07,385 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:45:07.385792', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:45:08,463 - EPOCH 0 - PROGRESS: at 46.25% examples, 344390 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:45:09,522 - EPOCH 0 - PROGRESS: at 96.25% examples, 360845 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:45:09,531 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 373348 effective words/s
2023-12-09 19:45:09,532 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 372767 effective words/s', 'datetime': '2023-12-09T19:45:09.531982', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:45:09,532 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:45:09.532222', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:45:15,204 - Processed run 2 for mu=0.4 on cuda:2. Elapsed time: 8.97 seconds
2023-12-09 19:47:40,648 - collecting all words and their counts
2023-12-09 19:47:40,648 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:47:40,706 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:47:40,706 - Creating a fresh vocabulary
2023-12-09 19:47:40,736 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:47:40.708673', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:40,736 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:47:40.736326', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:40,740 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:47:40,741 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:47:40,741 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:47:40.741106', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:40,748 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:47:40,748 - resetting layer weights
2023-12-09 19:47:40,749 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:47:40.749609', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:47:40,749 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:47:40.749761', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:47:41,755 - EPOCH 0 - PROGRESS: at 43.75% examples, 349465 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:47:42,805 - EPOCH 0 - PROGRESS: at 91.25% examples, 355862 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:47:42,952 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 363900 effective words/s
2023-12-09 19:47:42,953 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 363175 effective words/s', 'datetime': '2023-12-09T19:47:42.953082', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:47:42,953 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:47:42.953278', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:47:50,649 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.58 seconds
2023-12-09 19:47:51,493 - collecting all words and their counts
2023-12-09 19:47:51,493 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:47:51,551 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:47:51,551 - Creating a fresh vocabulary
2023-12-09 19:47:51,553 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:47:51.553660', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:51,553 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:47:51.553762', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:51,556 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:47:51,556 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:47:51,556 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:47:51.556733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:47:51,561 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:47:51,561 - resetting layer weights
2023-12-09 19:47:51,562 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:47:51.562092', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:47:51,562 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:47:51.562608', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:47:52,570 - EPOCH 0 - PROGRESS: at 42.50% examples, 338547 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:47:53,643 - EPOCH 0 - PROGRESS: at 91.25% examples, 351465 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:47:53,767 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 363510 effective words/s
2023-12-09 19:47:53,767 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 362915 effective words/s', 'datetime': '2023-12-09T19:47:53.767504', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:47:53,767 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:47:53.767677', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:47:58,881 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 8.23 seconds
2023-12-09 19:52:00,426 - collecting all words and their counts
2023-12-09 19:52:00,427 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:52:00,492 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:52:00,492 - Creating a fresh vocabulary
2023-12-09 19:52:00,521 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:52:00.494202', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:00,522 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:52:00.522099', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:00,526 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:52:00,527 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:52:00,527 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:52:00.527438', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:00,535 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:52:00,535 - resetting layer weights
2023-12-09 19:52:00,536 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:52:00.536122', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:52:00,536 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:52:00.536280', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:52:01,604 - EPOCH 0 - PROGRESS: at 46.25% examples, 347845 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:52:02,654 - EPOCH 0 - PROGRESS: at 96.25% examples, 364252 words/s, in_qsize 3, out_qsize 1
2023-12-09 19:52:02,686 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 372803 effective words/s
2023-12-09 19:52:02,686 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 372054 effective words/s', 'datetime': '2023-12-09T19:52:02.686912', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:52:02,687 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:52:02.687110', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:52:10,347 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.59 seconds
2023-12-09 19:52:11,158 - collecting all words and their counts
2023-12-09 19:52:11,158 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:52:11,224 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:52:11,224 - Creating a fresh vocabulary
2023-12-09 19:52:11,226 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:52:11.226325', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:11,226 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:52:11.226420', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:11,229 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:52:11,229 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:52:11,229 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:52:11.229327', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:52:11,234 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:52:11,234 - resetting layer weights
2023-12-09 19:52:11,234 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:52:11.234627', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:52:11,235 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:52:11.235169', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:52:12,245 - EPOCH 0 - PROGRESS: at 46.25% examples, 367646 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:52:13,245 - EPOCH 0 - PROGRESS: at 100.00% examples, 398653 words/s, in_qsize 0, out_qsize 1
2023-12-09 19:52:13,246 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 398602 effective words/s
2023-12-09 19:52:13,246 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 397875 effective words/s', 'datetime': '2023-12-09T19:52:13.246332', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:52:13,247 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:52:13.247051', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:52:18,062 - Processed run 2 for mu=0.2 on cuda:1. Elapsed time: 7.71 seconds
2023-12-09 19:57:01,542 - collecting all words and their counts
2023-12-09 19:57:01,542 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 19:57:01,599 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 19:57:01,599 - Creating a fresh vocabulary
2023-12-09 19:57:01,628 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T19:57:01.601707', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:57:01,628 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T19:57:01.628848', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:57:01,633 - deleting the raw counts dictionary of 1000 items
2023-12-09 19:57:01,634 - sample=0.001 downsamples 0 most-common words
2023-12-09 19:57:01,634 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T19:57:01.634611', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 19:57:01,641 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 19:57:01,641 - resetting layer weights
2023-12-09 19:57:01,642 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T19:57:01.642260', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 19:57:01,642 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T19:57:01.642454', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:57:02,648 - EPOCH 0 - PROGRESS: at 45.00% examples, 359302 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:57:03,698 - EPOCH 0 - PROGRESS: at 91.25% examples, 355807 words/s, in_qsize 7, out_qsize 0
2023-12-09 19:57:03,825 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367140 effective words/s
2023-12-09 19:57:03,825 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366440 effective words/s', 'datetime': '2023-12-09T19:57:03.825681', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 19:57:03,825 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T19:57:03.825748', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 19:57:12,199 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 12.22 seconds
2023-12-09 20:00:57,495 - collecting all words and their counts
2023-12-09 20:00:57,495 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:00:57,554 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:00:57,554 - Creating a fresh vocabulary
2023-12-09 20:00:57,583 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:00:57.556468', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:00:57,584 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:00:57.584288', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:00:57,588 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:00:57,589 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:00:57,589 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:00:57.589733', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:00:57,597 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:00:57,597 - resetting layer weights
2023-12-09 20:00:57,598 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:00:57.598422', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:00:57,598 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:00:57.598591', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:00:58,606 - EPOCH 0 - PROGRESS: at 41.25% examples, 328848 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:00:59,690 - EPOCH 0 - PROGRESS: at 91.25% examples, 349628 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:00:59,816 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 361362 effective words/s
2023-12-09 20:00:59,817 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 360624 effective words/s', 'datetime': '2023-12-09T20:00:59.817070', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:00:59,817 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:00:59.817254', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:01:07,309 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.40 seconds
2023-12-09 20:03:26,756 - collecting all words and their counts
2023-12-09 20:03:26,756 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:03:26,814 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:03:26,814 - Creating a fresh vocabulary
2023-12-09 20:03:26,844 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:03:26.816339', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:03:26,844 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:03:26.844675', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:03:26,849 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:03:26,850 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:03:26,850 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:03:26.850755', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:03:26,859 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:03:26,859 - resetting layer weights
2023-12-09 20:03:26,860 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:03:26.860452', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:03:26,860 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:03:26.860631', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:03:27,898 - EPOCH 0 - PROGRESS: at 46.25% examples, 358065 words/s, in_qsize 8, out_qsize 0
2023-12-09 20:03:28,912 - EPOCH 0 - PROGRESS: at 96.25% examples, 376186 words/s, in_qsize 3, out_qsize 1
2023-12-09 20:03:28,923 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.1s, 388617 effective words/s
2023-12-09 20:03:28,924 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.1s, 387791 effective words/s', 'datetime': '2023-12-09T20:03:28.924006', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:03:28,924 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:03:28.924212', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:03:36,732 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.58 seconds
2023-12-09 20:08:04,135 - collecting all words and their counts
2023-12-09 20:08:04,135 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:08:04,194 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:08:04,194 - Creating a fresh vocabulary
2023-12-09 20:08:04,222 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:08:04.196237', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:08:04,223 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:08:04.223019', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:08:04,227 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:08:04,228 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:08:04,228 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:08:04.228704', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:08:04,236 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:08:04,236 - resetting layer weights
2023-12-09 20:08:04,236 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:08:04.236764', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:08:04,236 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:08:04.236922', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:08:05,313 - EPOCH 0 - PROGRESS: at 46.25% examples, 344989 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:08:06,374 - EPOCH 0 - PROGRESS: at 96.25% examples, 360819 words/s, in_qsize 3, out_qsize 1
2023-12-09 20:08:06,399 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 370694 effective words/s
2023-12-09 20:08:06,399 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 369981 effective words/s', 'datetime': '2023-12-09T20:08:06.399293', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:08:06,399 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:08:06.399479', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:08:18,056 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 15.50 seconds
2023-12-09 20:11:23,778 - collecting all words and their counts
2023-12-09 20:11:23,778 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:11:23,836 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:11:23,836 - Creating a fresh vocabulary
2023-12-09 20:11:23,866 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:11:23.838867', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:11:23,867 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:11:23.867214', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:11:23,871 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:11:23,872 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:11:23,872 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:11:23.872766', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:11:23,880 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:11:23,880 - resetting layer weights
2023-12-09 20:11:23,881 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:11:23.881782', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:11:23,881 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:11:23.881943', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:11:24,891 - EPOCH 0 - PROGRESS: at 45.00% examples, 358298 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:11:25,911 - EPOCH 0 - PROGRESS: at 91.25% examples, 360433 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:11:26,062 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 367715 effective words/s
2023-12-09 20:11:26,062 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 366931 effective words/s', 'datetime': '2023-12-09T20:11:26.062284', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:11:26,062 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:11:26.062484', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:11:34,027 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.83 seconds
2023-12-09 20:23:40,942 - collecting all words and their counts
2023-12-09 20:23:40,942 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:23:41,000 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:23:41,000 - Creating a fresh vocabulary
2023-12-09 20:23:41,031 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:23:41.002842', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:23:41,031 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:23:41.031552', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:23:41,036 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:23:41,036 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:23:41,036 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:23:41.036859', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:23:41,045 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:23:41,045 - resetting layer weights
2023-12-09 20:23:41,046 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:23:41.046121', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:23:41,046 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:23:41.046290', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:23:42,054 - EPOCH 0 - PROGRESS: at 42.50% examples, 338828 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:23:43,145 - EPOCH 0 - PROGRESS: at 91.25% examples, 348405 words/s, in_qsize 7, out_qsize 0
2023-12-09 20:23:43,257 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.2s, 362425 effective words/s
2023-12-09 20:23:43,258 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.2s, 361688 effective words/s', 'datetime': '2023-12-09T20:23:43.258236', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:23:43,258 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:23:43.258421', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:23:51,099 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.78 seconds
2023-12-09 20:25:03,286 - collecting all words and their counts
2023-12-09 20:25:03,286 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2023-12-09 20:25:03,343 - collected 1000 word types from a corpus of 800000 raw words and 10000 sentences
2023-12-09 20:25:03,343 - Creating a fresh vocabulary
2023-12-09 20:25:03,374 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 1000 unique words (100.00% of original 1000, drops 0)', 'datetime': '2023-12-09T20:25:03.345910', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:25:03,374 - Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 800000 word corpus (100.00% of original 800000, drops 0)', 'datetime': '2023-12-09T20:25:03.374667', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:25:03,378 - deleting the raw counts dictionary of 1000 items
2023-12-09 20:25:03,379 - sample=0.001 downsamples 0 most-common words
2023-12-09 20:25:03,379 - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 800000 word corpus (100.0%% of prior 800000)', 'datetime': '2023-12-09T20:25:03.379130', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'prepare_vocab'}
2023-12-09 20:25:03,384 - estimated required memory for 1000 words and 64 dimensions: 1012000 bytes
2023-12-09 20:25:03,384 - resetting layer weights
2023-12-09 20:25:03,385 - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-12-09T20:25:03.385475', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'build_vocab'}
2023-12-09 20:25:03,385 - Word2Vec lifecycle event {'msg': 'training model with 4 workers on 1000 vocabulary and 64 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-09T20:25:03.385594', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:25:04,406 - EPOCH 0 - PROGRESS: at 47.50% examples, 373848 words/s, in_qsize 8, out_qsize 0
2023-12-09 20:25:05,420 - EPOCH 0 - PROGRESS: at 100.00% examples, 394030 words/s, in_qsize 0, out_qsize 1
2023-12-09 20:25:05,420 - EPOCH 0: training on 800000 raw words (800000 effective words) took 2.0s, 393977 effective words/s
2023-12-09 20:25:05,421 - Word2Vec lifecycle event {'msg': 'training on 800000 raw words (800000 effective words) took 2.0s, 393124 effective words/s', 'datetime': '2023-12-09T20:25:05.420964', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'train'}
2023-12-09 20:25:05,421 - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1000, vector_size=64, alpha=0.025>', 'datetime': '2023-12-09T20:25:05.421540', 'gensim': '4.3.2', 'python': '3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]', 'platform': 'Linux-5.15.0-76-generic-x86_64-with-glibc2.31', 'event': 'created'}
2023-12-09 20:25:13,299 - Processed run 1 for mu=0.2 on cuda:1. Elapsed time: 11.60 seconds
