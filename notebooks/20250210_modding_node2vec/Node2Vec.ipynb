{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860d89c5-6cb7-4eea-9dd1-10e3509a8816",
   "metadata": {},
   "source": [
    "This is the implementation of Sadamori's Node2Vec in https://github.com/skojaku/community-detection-via-neural-embedding/tree/master/libs/embcom/embcom\n",
    "in one notebook, so that I can modify the functions easily.\n",
    "\n",
    "A problem with modifying the distance metric of Node2Vec is that it uses Gensim's skipgram model (which is also highly optimized) and it doesn't allow to easily modify the distances while still keeping the optimizations (at least I haven't figured it yet).\n",
    "\n",
    "In this notebook, we can look under the hood in an effort to modify it.\n",
    "\n",
    "I'm running it in a different environment so that it doesn't clash with existing gensim, I will try to add functionality to quickly switch between original operation and our modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ded30fd-00d2-41d0-aaec-831ac06cb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f84d7f-697a-4835-b404-54e2e71dfffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/gogandhi/miniconda3/envs/gensim_mod_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: Sadamori Kojaku\n",
    "# @Date:   2023-06-08 16:38:19\n",
    "# @Last Modified by:   Sadamori Kojaku\n",
    "# @Last Modified time: 2023-06-15 11:56:36\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def to_trans_mat(mat):\n",
    "    \"\"\"\n",
    "    Computes the transition matrix of a given Markov chain represented as a square matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : numpy.ndarray\n",
    "        The input matrix, which represents the transition probabilities of the Markov chain.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scipy.sparse.csr_matrix\n",
    "        The sparse CSR matrix representing the transition matrix of the input Markov chain.\n",
    "    \"\"\"\n",
    "    denom = np.array(mat.sum(axis=1)).reshape(-1).astype(float)\n",
    "    return sparse.diags(1.0 / np.maximum(denom, 1e-32), format=\"csr\") @ mat\n",
    " \n",
    "\n",
    "def to_adjacency_matrix(net):\n",
    "    \"\"\"\n",
    "    Converts an input graph representation to its corresponding adjacency matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : {scipy.sparse.csr_matrix, networkx.classes.graph.Graph, numpy.ndarray}\n",
    "        The input graph representation. If it's a numpy.ndarray, it will be converted to a sparse CSR matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scipy.sparse.csr_matrix\n",
    "        The sparse CSR matrix representing the adjacency matrix of the input graph.\n",
    "    \"\"\"\n",
    "    if sparse.issparse(net):\n",
    "        if type(net) == \"scipy.sparse.csr.csr_matrix\":\n",
    "            return net.astype(float)\n",
    "        return sparse.csr_matrix(net).astype(float)\n",
    "    elif \"networkx\" in \"%s\" % type(net):\n",
    "        return nx.adjacency_matrix(net).astype(float)\n",
    "    elif \"numpy.ndarray\" == type(net):\n",
    "        return sparse.csr_matrix(net).astype(float)\n",
    "\n",
    "def matrix_sum_power(A, T):\n",
    "    \"\"\"\n",
    "    Computes the sum of powers of an input matrix, up to a given exponent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        The input square matrix to exponentiate and sum.\n",
    "    T : int\n",
    "        The maximum exponent to compute the sum up to.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The resulting matrix obtained by computing the sum of powers of the input matrix A, up to exponent T.\n",
    "    \"\"\"\n",
    "    At = np.eye(A.shape[0])\n",
    "    As = np.zeros((A.shape[0], A.shape[0]))\n",
    "    for _ in range(T):\n",
    "        At = A @ At\n",
    "        As += At\n",
    "    return As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c8e05e-145b-4933-a163-d20e37211a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module contains sampler class which generates a sequence of nodes from\n",
    "a network using a random walk.\n",
    "\n",
    "All samplers should be the subclass of NodeSampler class.\n",
    "\"\"\"\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "class NodeSampler(metaclass=ABCMeta):\n",
    "    \"\"\"Super class for node sampler class.\n",
    "\n",
    "    Implement\n",
    "        - sampling\n",
    "\n",
    "    Optional\n",
    "        - get_decomposed_trans_matrix\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def sampling(self):\n",
    "        \"\"\"Generate a sequence of walks over the network.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        walks : numpy.ndarray (number_of_walks, number_of_steps)\n",
    "            Each row indicates a trajectory of a random walker\n",
    "            walk[i,j] indicates the jth step for walker i.\n",
    "        \"\"\"\n",
    "\n",
    "class Node2VecWalkSampler(NodeSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_walks=10,\n",
    "        walk_length=80,\n",
    "        p=1.0,\n",
    "        q=1.0,\n",
    "        **params\n",
    "    ):\n",
    "        \"\"\"Noe2VecWalk Sampler\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_walks : int (Optional; Default 1)\n",
    "            Number of walkers to simulate for each randomized network.\n",
    "            A larger value removes the bias better but takes more time.\n",
    "        walk_length : int\n",
    "            Number of steps for a single walker\n",
    "        p : float\n",
    "            Parameter for the node2vec\n",
    "        q : float\n",
    "            Parameter for the node2vec\n",
    "        window_length : int\n",
    "            Size of the window\n",
    "        verbose : bool\n",
    "            Set true to display the progress (NOT IMPLEMENTED)\n",
    "        \"\"\"\n",
    "        self.num_nodes = -1\n",
    "\n",
    "        # parameters for random walker\n",
    "        self.num_walks = int(num_walks)\n",
    "        self.walk_length = walk_length\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.walks = None\n",
    "\n",
    "    def sampling(self, net):\n",
    "        self.num_nodes = net.shape[0]\n",
    "        self.A = net\n",
    "\n",
    "        self.walks = simulate_node2vec_walk(\n",
    "            A = self.A,\n",
    "            num_walks = self.num_walks,\n",
    "            walk_length = self.walk_length,\n",
    "            start_node_ids = None,\n",
    "            p = self.p,\n",
    "            q = self.q,\n",
    "        )\n",
    "\n",
    "#\n",
    "# SimpleWalk Sampler\n",
    "#\n",
    "class SimpleWalkSampler(Node2VecWalkSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **params\n",
    "    ):\n",
    "        \"\"\"Simple walk without bias\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_walks : int (Optional; Default 1)\n",
    "            Number of walkers to simulate for each randomized network.\n",
    "            A larger value removes the bias better but takes more time.\n",
    "        walk_length : int\n",
    "            Number of steps for a single walker\n",
    "        window_length : int\n",
    "            Size of the window\n",
    "        verbose : bool\n",
    "            Set true to display the progress (NOT IMPLEMENTED)\n",
    "        \"\"\"\n",
    "        params[\"p\"] = 1\n",
    "        params[\"q\"] = 1\n",
    "        Node2VecWalkSampler.__init__(self, **params)\n",
    "\n",
    "\n",
    "#\n",
    "# node2vec walk\n",
    "#\n",
    "def simulate_node2vec_walk(\n",
    "    A,\n",
    "    num_walks,\n",
    "    walk_length,\n",
    "    start_node_ids = None,\n",
    "    p = 1,\n",
    "    q = 1,\n",
    "):\n",
    "    if A.getformat() != \"csr\":\n",
    "        raise TypeError(\"A should be in the scipy.sparse.csc_matrix\")\n",
    "\n",
    "    if start_node_ids is None:\n",
    "        start_node_ids = np.arange(A.shape[0])\n",
    "\n",
    "    is_weighted = np.max(A.data) != np.min(A.data)\n",
    "    A.sort_indices()\n",
    "    if is_weighted:\n",
    "        data = A.data / A.sum(axis=1).A1.repeat(np.diff(A.indptr))\n",
    "        A.data = _csr_row_cumsum(A.indptr, data)\n",
    "\n",
    "    walks = []\n",
    "    for _ in range(num_walks):\n",
    "        for start in start_node_ids:\n",
    "            if is_weighted:\n",
    "                walk = _random_walk_weighted(\n",
    "                    A.indptr, A.indices, A.data, walk_length, p, q, start\n",
    "                )\n",
    "            else:\n",
    "                walk = _random_walk(A.indptr, A.indices, walk_length, p, q, start)\n",
    "            walks.append(walk.tolist())\n",
    "\n",
    "    return walks\n",
    "\n",
    "@njit(nogil=True)\n",
    "def _csr_row_cumsum(indptr, data):\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(len(indptr) - 1):\n",
    "        acc = 0\n",
    "        for j in range(indptr[i], indptr[i + 1]):\n",
    "            acc += data[j]\n",
    "            out[j] = acc\n",
    "        out[j] = 1.0\n",
    "    return out\n",
    "\n",
    "@njit(nogil=True)\n",
    "def _neighbors(indptr, indices_or_data, t):\n",
    "    return indices_or_data[indptr[t] : indptr[t + 1]]\n",
    "\n",
    "\n",
    "@njit(nogil=True)\n",
    "def _isin_sorted(a, x):\n",
    "    return a[np.searchsorted(a, x)] == x\n",
    "\n",
    "\n",
    "@njit(nogil=True)\n",
    "def _random_walk(indptr, indices, walk_length, p, q, t):\n",
    "    max_prob = max(1 / p, 1, 1 / q)\n",
    "    prob_0 = 1 / p / max_prob\n",
    "    prob_1 = 1 / max_prob\n",
    "    prob_2 = 1 / q / max_prob\n",
    "\n",
    "    walk = np.empty(walk_length, dtype=indices.dtype)\n",
    "    walk[0] = t\n",
    "    neighbors = _neighbors(indptr, indices, t)\n",
    "    if not neighbors.size:\n",
    "        return walk[:1]\n",
    "    walk[1] = np.random.choice(_neighbors(indptr, indices, t))\n",
    "    for j in range(2, walk_length):\n",
    "        neighbors = _neighbors(indptr, indices, walk[j - 1])\n",
    "        if not neighbors.size:\n",
    "            return walk[:j]\n",
    "        if p == q == 1:\n",
    "            # faster version\n",
    "            walk[j] = np.random.choice(neighbors)\n",
    "            continue\n",
    "        while True:\n",
    "            new_node = np.random.choice(neighbors)\n",
    "            r = np.random.rand()\n",
    "            if new_node == walk[j - 2]:\n",
    "                if r < prob_0:\n",
    "                    break\n",
    "            elif _isin_sorted(_neighbors(indptr, indices, walk[j - 2]), new_node):\n",
    "                if r < prob_1:\n",
    "                    break\n",
    "            elif r < prob_2:\n",
    "                break\n",
    "        walk[j] = new_node\n",
    "    return walk\n",
    "\n",
    "\n",
    "@njit(nogil=True)\n",
    "def _random_walk_weighted(indptr, indices, data, walk_length, p, q, t):\n",
    "    max_prob = max(1 / p, 1, 1 / q)\n",
    "    prob_0 = 1 / p / max_prob\n",
    "    prob_1 = 1 / max_prob\n",
    "    prob_2 = 1 / q / max_prob\n",
    "\n",
    "    walk = np.empty(walk_length, dtype=indices.dtype)\n",
    "    walk[0] = t\n",
    "    neighbors = _neighbors(indptr, indices, t)\n",
    "    if not neighbors.size:\n",
    "        return walk[:1]\n",
    "    walk[1] = _neighbors(indptr, indices, t)[\n",
    "        np.searchsorted(_neighbors(indptr, data, t), np.random.rand())\n",
    "    ]\n",
    "    for j in range(2, walk_length):\n",
    "        neighbors = _neighbors(indptr, indices, walk[j - 1])\n",
    "        if not neighbors.size:\n",
    "            return walk[:j]\n",
    "        neighbors_p = _neighbors(indptr, data, walk[j - 1])\n",
    "        if p == q == 1:\n",
    "            # faster version\n",
    "            walk[j] = neighbors[np.searchsorted(neighbors_p, np.random.rand())]\n",
    "            continue\n",
    "        while True:\n",
    "            new_node = neighbors[np.searchsorted(neighbors_p, np.random.rand())]\n",
    "            r = np.random.rand()\n",
    "            if new_node == walk[j - 2]:\n",
    "                if r < prob_0:\n",
    "                    break\n",
    "            elif _isin_sorted(_neighbors(indptr, indices, walk[j - 2]), new_node):\n",
    "                if r < prob_1:\n",
    "                    break\n",
    "            elif r < prob_2:\n",
    "                break\n",
    "        walk[j] = new_node\n",
    "    return walk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af664afd-283f-4b29-8627-fc64798b2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: Sadamori Kojaku\n",
    "# @Date:   2022-08-26 09:51:23\n",
    "# @Last Modified by:   Sadamori Kojaku\n",
    "# @Last Modified time: 2023-02-19 15:33:48\n",
    "\"\"\"Module for embedding.\"\"\"\n",
    "# %%\n",
    "import gensim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Base class\n",
    "#\n",
    "class NodeEmbeddings:\n",
    "    \"\"\"Super class for node embedding class.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.in_vec = None\n",
    "        self.out_vec = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Estimating the parameters for embedding.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def transform(self, dim, return_out_vector=False):\n",
    "        \"\"\"Compute the coordinates of nodes in the embedding space of the\n",
    "        prescribed dimensions.\"\"\"\n",
    "        # Update the in-vector and out-vector if\n",
    "        # (i) this is the first to compute the vectors or\n",
    "        # (ii) the dimension is different from that for the previous call of transform function\n",
    "        if self.out_vec is None:\n",
    "            self.update_embedding(dim)\n",
    "        elif self.out_vec.shape[1] != dim:\n",
    "            self.update_embedding(dim)\n",
    "        return self.out_vec if return_out_vector else self.in_vec\n",
    "\n",
    "    def update_embedding(self, dim):\n",
    "        \"\"\"Update embedding.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Node2Vec(NodeEmbeddings):\n",
    "    \"\"\"A python class for the node2vec.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_walks : int (optional, default 10)\n",
    "        Number of walks per node\n",
    "    walk_length : int (optional, default 40)\n",
    "        Length of walks\n",
    "    window_length : int (optional, default 10)\n",
    "        Restart probability of a random walker.\n",
    "    p : node2vec parameter (TODO: Write doc)\n",
    "    q : node2vec parameter (TODO: Write doc)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_walks=10,\n",
    "        walk_length=80,\n",
    "        window_length=10,\n",
    "        p=1.0,\n",
    "        q=1.0,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.in_vec = None  # In-vector\n",
    "        self.out_vec = None  # Out-vector\n",
    "        self.window_length = window_length\n",
    "        self.sampler = Node2VecWalkSampler(\n",
    "            num_walks=num_walks,\n",
    "            walk_length=walk_length,\n",
    "            p=p,\n",
    "            q=q,\n",
    "        )\n",
    "        \n",
    "        self.sentences = None\n",
    "        self.model = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.w2vparams = {\n",
    "            \"sg\": 1,\n",
    "            \"min_count\": 0,\n",
    "            \"epochs\": 1,\n",
    "            \"workers\": 4,\n",
    "        }\n",
    "\n",
    "    def fit(self, net):\n",
    "        \"\"\"Estimating the parameters for embedding.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        net : nx.Graph object\n",
    "            Network to be embedded. The graph type can be anything if\n",
    "            the graph type is supported for the node samplers.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        self : Node2Vec\n",
    "        \"\"\"\n",
    "        A = to_adjacency_matrix(net)\n",
    "        self.sampler.sampling(A)\n",
    "        return self\n",
    "\n",
    "    def update_embedding(self, dim):\n",
    "        # Update the dimension and train the model\n",
    "        # Sample the sequence of nodes using a random walk\n",
    "        self.w2vparams[\"window\"] = self.window_length\n",
    "\n",
    "        self.w2vparams[\"vector_size\"] = dim\n",
    "        self.model = gensim.models.Word2Vec(\n",
    "            sentences=self.sampler.walks, **self.w2vparams\n",
    "        ) \n",
    "        #!TODO: GENSIM USES DOT SIMILARITY\n",
    "\n",
    "        num_nodes = len(self.model.wv.index_to_key)\n",
    "        self.in_vec = np.zeros((num_nodes, dim))\n",
    "        self.out_vec = np.zeros((num_nodes, dim))\n",
    "        for i in range(num_nodes):\n",
    "            if i not in self.model.wv:\n",
    "                continue\n",
    "            self.in_vec[i, :] = self.model.wv[i]\n",
    "            self.out_vec[i, :] = self.model.syn1neg[self.model.wv.key_to_index[i]]\n",
    "\n",
    "\n",
    "\n",
    "class Node2VecMatrixFactorization(NodeEmbeddings):\n",
    "    def __init__(self, verbose=False, window_length=10, num_blocks=500):\n",
    "        self.in_vec = None  # In-vector\n",
    "        self.out_vec = None  # Out-vector\n",
    "        self.window_length = window_length\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "    def fit(self, net):\n",
    "        A = to_adjacency_matrix(net)\n",
    "\n",
    "        self.A = A\n",
    "        self.deg = np.array(A.sum(axis=1)).reshape(-1)\n",
    "        return self\n",
    "\n",
    "    def update_embedding(self, dim):\n",
    "\n",
    "        P = to_trans_mat(self.A)\n",
    "        Ppow = matrix_sum_power(P, self.window_length) / self.window_length\n",
    "        stationary_prob = self.deg / np.sum(self.deg)\n",
    "        R = np.log(Ppow @ np.diag(1 / stationary_prob))\n",
    "\n",
    "        # u, s, v = rsvd.rSVD(R, dim=dim)\n",
    "        svd = TruncatedSVD(n_components=dim + 1, n_iter=7, random_state=42)\n",
    "        u = svd.fit_transform(R)\n",
    "        s = svd.singular_values_\n",
    "        self.in_vec = u @ sparse.diags(np.sqrt(s))\n",
    "        self.out_vec = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163609e9-b966-4d96-8581-160cdb223814",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deabd74b-4eb7-4ab2-a0e4-cafadb94908d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate our Node2Vec model with custom training parameters.\n",
    "node2vec_model = Node2Vec(num_walks=10, walk_length=80, window_length=10)\n",
    "\n",
    "# Fit the model on the graph.\n",
    "node2vec_model.fit(to_adjacency_matrix(G))\n",
    "\n",
    "# Compute node embeddings with target dimension, e.g., 128.\n",
    "emb_r = node2vec_model.transform(dim=64)\n",
    "\n",
    "\n",
    "\n",
    "# # Apply UMAP to reduce dimensionality to 2D\n",
    "# umap_reducer = umap.UMAP(n_components=2)\n",
    "# embeddings_2d = umap_reducer.fit_transform(emb_r)\n",
    "\n",
    "# # Plot the embeddings in 2D\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c='blue', alpha=0.6, edgecolors='k')\n",
    "# plt.xlabel(\"UMAP Dimension 1\")\n",
    "# plt.ylabel(\"UMAP Dimension 2\")\n",
    "# plt.title(\"64D Embeddings Projected into 2D using UMAP\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1bfa47-c9f1-4e0d-b200-580402c15137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore this message if you do not use Glove. Otherwise, install glove python package by 'pip install glove_python_binary' \n"
     ]
    }
   ],
   "source": [
    "import embcom\n",
    "\n",
    "\n",
    "def create_embedding(G, emb_params = {\n",
    "                                            \"window_length\": 10,\n",
    "                                            \"walk_length\": 80,\n",
    "                                            \"num_walks\": 10,\n",
    "                                            \"dim\" : 64,\n",
    "                                        }):\n",
    "  \n",
    "    model = embcom.embeddings.Node2Vec(window_length = emb_params['window_length'], walk_length=emb_params['walk_length'], num_walks=emb_params['num_walks'])\n",
    "            \n",
    "\n",
    "    model.fit(to_adjacency_matrix(G))\n",
    "    emb = model.transform(dim=emb_params['dim'])\n",
    "\n",
    "    return emb\n",
    "\n",
    "emb_p = create_embedding(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97dd16-b488-467a-af60-33b0d936734c",
   "metadata": {},
   "source": [
    "Check to see if the embeddings produced by our code and that from embcom module are similar to each other using normalized embedding loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3e3d9-c3c1-48e0-954e-a4069fcb9602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16693919511584615"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_normalized_embedding_loss(V_a, V_b):\n",
    "    \n",
    "    \n",
    "    def center_embeddings(V):\n",
    "        # Subtract the mean of each column from the corresponding entries\n",
    "        return V - np.mean(V, axis=0)\n",
    "\n",
    "    \n",
    "    # Step 1: Center both embedding matrices\n",
    "    V_a_centered = center_embeddings(V_a)\n",
    "    V_b_centered = center_embeddings(V_b)\n",
    "    \n",
    "    # Step 2: Calculate cosine similarity matrices for centered embeddings\n",
    "    C_a = cosine_similarity(V_a_centered)\n",
    "    C_b = cosine_similarity(V_b_centered)\n",
    "    \n",
    "    # Step 3: Calculate the absolute differences between cosine similarities\n",
    "    N = V_a.shape[0]\n",
    "    loss = 0\n",
    "    \n",
    "    # Only sum over the upper triangular part of the matrix (i < j)\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            loss += np.abs(C_a[i, j] - C_b[i, j])\n",
    "    \n",
    "    # Step 4: Normalize the loss\n",
    "    normalized_loss = (2 / (N * (N - 1))) * loss\n",
    "    \n",
    "    return normalized_loss\n",
    "\n",
    "\n",
    "\n",
    "loss = calculate_normalized_embedding_loss(emb_p, emb_r)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac4578-a9b8-42ba-ada5-ef5e9e621fc8",
   "metadata": {},
   "source": [
    "They are fine enough(ig)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d034a09-1956-493a-ab24-62c73dd832cf",
   "metadata": {},
   "source": [
    "## Going from dot similarity to Euclidean distance\n",
    "Now as an initial step we want to modify N2V to use not just dot similarity but also Euclidean distance.\n",
    "So note all the steps where it uses a distance measure first:\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daae6f-368a-4d31-ab62-94023d1286d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim_mod_env",
   "language": "python",
   "name": "gensim_mod_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
