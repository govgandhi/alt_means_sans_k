{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cf065d-d09b-4520-bc0e-319b806da7c5",
   "metadata": {},
   "source": [
    "In this notebook, we will use the node2vecs package which was modified in \"Final - Modding Sadamori's Torch N2V.ipynb\" in the previously timestamped folder. We modified the loss functions to use cosine and Euclidean distances apart from just dot similarity. The autograd function was used to verify our manual jacobian calculations. \n",
    "We now generate embeddings through this modified node2vec to suit our needs later. We want to use the embeddings to run clustering with different distance metrics to see if there's something interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5760f3a-2bf2-4a41-9ffd-e54aaa8e4c35",
   "metadata": {},
   "source": [
    "I want to use another set of networks because of some weird aberrations that were happening in low mixing limits in the previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6744e68-2501-4847-9872-a30e3c968cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing k=50:   0%|                                                                                | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task 2] Training model using cosine similarity for Run 1, mu 0.15, k 50 on cuda:0...\n",
      "[Task 11] Training model using cosine similarity for Run 1, mu 0.6, k 50 on cuda:1...[Task 6] Training model using cosine similarity for Run 1, mu 0.35, k 50 on cuda:0...\n",
      "\n",
      "[Task 12] Training model using cosine similarity for Run 1, mu 0.65, k 50 on cuda:0...[Task 1] Training model using cosine similarity for Run 1, mu 0.1, k 50 on cuda:1...\n",
      "\n",
      "[Task 8] Training model using cosine similarity for Run 1, mu 0.45, k 50 on cuda:0...\n",
      "[Task 9] Training model using cosine similarity for Run 1, mu 0.5, k 50 on cuda:1...\n",
      "[Task 4] Training model using cosine similarity for Run 1, mu 0.25, k 50 on cuda:0...\n",
      "[Task 0] Training model using cosine similarity for Run 1, mu 0.05, k 50 on cuda:0...[Task 13] Training model using cosine similarity for Run 1, mu 0.7, k 50 on cuda:1...\n",
      "\n",
      "[Task 10] Training model using cosine similarity for Run 1, mu 0.55, k 50 on cuda:0...\n",
      "[Task 5] Training model using cosine similarity for Run 1, mu 0.3, k 50 on cuda:1...[Task 7] Training model using cosine similarity for Run 1, mu 0.4, k 50 on cuda:1...\n",
      "\n",
      "[Task 15] Training model using cosine similarity for Run 1, mu 0.8, k 50 on cuda:1...[Task 16] Training model using cosine similarity for Run 1, mu 0.85, k 50 on cuda:0...\n",
      "[Task 14] Training model using cosine similarity for Run 1, mu 0.75, k 50 on cuda:0...[Task 17] Training model using cosine similarity for Run 1, mu 0.9, k 50 on cuda:1...\n",
      "\n",
      "\n",
      "[Task 18] Training model using cosine similarity for Run 1, mu 0.95, k 50 on cuda:0...[Task 19] Training model using cosine similarity for Run 1, mu 1.0, k 50 on cuda:1...\n",
      "\n",
      "[Task 3] Training model using cosine similarity for Run 1, mu 0.2, k 50 on cuda:1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████▌                                            | 12210/31250 [11:45<10:38, 29.81it/s, loss=1.3]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from node2vecs import TorchNode2Vec\n",
    "\n",
    "def process_task(task):\n",
    "    \"\"\"\n",
    "    Process a single task: load the network and community table, train embeddings using three similarity metrics,\n",
    "    and save embeddings, network, and community table to the output directory.\n",
    "    \n",
    "    task: tuple (k, run, mu, task_idx)\n",
    "    \"\"\"\n",
    "    k, run, mu, task_idx = task\n",
    "    # Alternate GPU devices: tasks with even task_idx use cuda:0, odd use cuda:1\n",
    "    device = f\"cuda:{task_idx % 2}\"\n",
    "    \n",
    "    # Define input and output directories for this k value\n",
    "    input_base = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_mu_change_10000_{k}_3.0_minc50\"\n",
    "    output_base = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_cosine_change_10000_{k}_3.0_minc50\"\n",
    "    \n",
    "    input_run_dir = os.path.join(input_base, f\"Run_{run}\")\n",
    "    output_run_dir = os.path.join(output_base, f\"Run_{run}\")\n",
    "    os.makedirs(output_run_dir, exist_ok=True)\n",
    "    \n",
    "    mu_str = f\"{mu}\"\n",
    "    net_filename = f\"net_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu_str}_k_{k}_mincomm_50.npz\"\n",
    "    comm_filename = f\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu_str}_k_{k}_mincomm_50.npz\"\n",
    "    \n",
    "    net_path = os.path.join(input_run_dir, net_filename)\n",
    "    comm_path = os.path.join(input_run_dir, comm_filename)\n",
    "    \n",
    "    if not os.path.exists(net_path):\n",
    "        print(f\"[Task {task_idx}] Network file not found: {net_path}\")\n",
    "        return\n",
    "    if not os.path.exists(comm_path):\n",
    "        print(f\"[Task {task_idx}] Community file not found: {comm_path}\")\n",
    "        return\n",
    "    \n",
    "    # Load the network as a scipy sparse matrix\n",
    "    try:\n",
    "        A = sp.load_npz(net_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Task {task_idx}] Error loading network file {net_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load the community table; assume it's saved in an npz file\n",
    "    try:\n",
    "        community_table = pd.read_csv(comm_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Task {task_idx}] Error loading community file {comm_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Define the similarity metrics to test\n",
    "    similarity_measures = [\"cosine\"]\n",
    "    embeddings_dict = {}\n",
    "    \n",
    "    for sim in similarity_measures:\n",
    "        print(f\"[Task {task_idx}] Training model using {sim} similarity for Run {run}, mu {mu_str}, k {k} on {device}...\")\n",
    "        try:\n",
    "            model = TorchNode2Vec(\n",
    "                vector_size=64,\n",
    "                similarity_metric=sim,\n",
    "                device=device,\n",
    "                num_workers=1\n",
    "            )\n",
    "            model.fit(A)\n",
    "            emb = model.transform()\n",
    "            embeddings_dict[sim] = emb\n",
    "        except Exception as e:\n",
    "            print(f\"[Task {task_idx}] Error training {sim} model for Run {run}, mu {mu_str}, k {k} on {device}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Save the embeddings dictionary as a pickle file\n",
    "    out_filename = f\"embeddings_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu_str}_k_{k}_mincomm_50.pkl\"\n",
    "    out_path = os.path.join(output_run_dir, out_filename)\n",
    "    try:\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            pickle.dump(embeddings_dict, f)\n",
    "        print(f\"[Task {task_idx}] Saved embeddings to {out_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Task {task_idx}] Error saving embeddings to {out_path}: {e}\")\n",
    "    \n",
    "    # # Save the network to the output folder\n",
    "    # network_out_path = os.path.join(output_run_dir, net_filename)\n",
    "    # try:\n",
    "    #     sp.save_npz(network_out_path, A)\n",
    "    #     print(f\"[Task {task_idx}] Saved network to {network_out_path}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"[Task {task_idx}] Error saving network to {network_out_path}: {e}\")\n",
    "    \n",
    "    # # Save the community table as a CSV file to the output folder\n",
    "    # community_out_path = os.path.join(output_run_dir, f\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu_str}_k_{k}_mincomm_50.csv\")\n",
    "    # try:\n",
    "    #     if not isinstance(community_table, pd.DataFrame):\n",
    "    #         community_table = pd.DataFrame(community_table)\n",
    "    #     community_table.to_csv(community_out_path, index=False)\n",
    "    #     print(f\"[Task {task_idx}] Saved community table to {community_out_path}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"[Task {task_idx}] Error saving community table to {community_out_path}: {e}\")\n",
    "\n",
    "# Process k values sequentially while parallelizing runs and mu-values\n",
    "for k in [50]:\n",
    "    tasks = []\n",
    "    mu_values = [round(x, 2) for x in np.arange(0.05, 1.01, 0.05)]\n",
    "    #mu_values = [0.05]\n",
    "    task_idx = 0\n",
    "    for run in range(1, 11):\n",
    "        for mu in mu_values:\n",
    "            tasks.append((k, run, mu, task_idx))\n",
    "            task_idx += 1\n",
    "    \n",
    "    # Use a ProcessPoolExecutor to run tasks in parallel; adjust max_workers as needed\n",
    "    with ProcessPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(process_task, task) for task in tasks]\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing k={k}\"):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0086d7-2980-4c82-846d-878e4634a7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim_mod_env",
   "language": "python",
   "name": "gensim_mod_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
