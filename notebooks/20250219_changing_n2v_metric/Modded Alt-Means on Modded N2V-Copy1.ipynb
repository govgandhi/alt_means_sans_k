{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294b892e-2a06-4ea4-b028-b7f719235af9",
   "metadata": {},
   "source": [
    "We have obtained the embeddings for 10,000 node networks of params in this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164f9e36-6fe1-4bdb-a3c6-f4f0cd9b7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 # k = {5,10,50}\n",
    "mu = 0.1\n",
    "run_no = 1\n",
    "\n",
    "base = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_change_10000_{k}_3.0_minc50/Run_{run_no}/\" \n",
    "emb_path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_cosine_change_10000_{k}_3.0_minc50/Run_{run_no}/\"\n",
    "\n",
    "net_filename = f\"net_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.npz\"  # A = sp.load_npz(net_path)\n",
    "comm_filename = f\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.csv\" # pd.read_csv()\n",
    "emb_filename = f\"embeddings_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.pkl\" # embeddings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d247f-de93-4272-9ac2-7349337034ec",
   "metadata": {},
   "source": [
    "For instance, we load it to see the embeddings as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c02f866-885a-4eb0-b546-9c80e2b64546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cosine'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(emb_path_name+emb_filename, 'rb') as f:  # open a text file\n",
    "    emb_dict = pickle.load(f) # deserialize using load()\n",
    "emb_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa962c-4932-4a0d-8345-b7dec59c29cf",
   "metadata": {},
   "source": [
    "Now we want to take these embeddings, and run Alt-means clustering with different metrics on them to see which combination comes out on top.\n",
    "N2V ... K-Means \\\n",
    "Euc ... Dot? \\\n",
    "Euc ... Euc? \\\n",
    "Dot ... Dot? \\\n",
    "I have a strong feeling this is bound to change based on the dimensionality of the embedding vectors, so I will test the cases with embedding dimensions = 8,16,32,128 also. But we're getting ahead of ourselves now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b0f4e-0769-4d80-8416-3e4848ef99f3",
   "metadata": {},
   "source": [
    "# The modified Alt-Means algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b772104b-c3e0-4938-8b68-7486de282a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writing this script such that if I run it with input parameters, \n",
    "it should give me element centric similarity for the methods, we query\n",
    "each method we query can run withinn this or out. Will decide.\n",
    "Use chanage_mu_test.py as reference.\n",
    "'''\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "#import os\n",
    "#import networkx as nx\n",
    "#import gensim\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.cluster import OPTICS, DBSCAN\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import faiss\n",
    "#import lfr\n",
    "#import embcom\n",
    "#import csv\n",
    "import sys\n",
    "sys.path.append(\"/nobackup/gogandhi/alt_means_sans_k/\")\n",
    "\n",
    "from scripts.nets_and_embeddings import create_and_save_network_and_embedding\n",
    "#from scripts.clustering_methods import clustering_method_values\n",
    "from scripts.nets_and_embeddings import load_net_and_embedding\n",
    "\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.xmeans import xmeans, splitting_type\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import FCPS_SAMPLES\n",
    "import numpy as np\n",
    "import belief_propagation\n",
    "#import infomap\n",
    "from graph_tool.all import Graph,minimize_blockmodel_dl\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Define a function that calculates element-centric similarity:\n",
    "def calc_esim(y, ypred):\n",
    "\n",
    "    ylab, y = np.unique(y, return_inverse=True)\n",
    "    ypredlab, ypred = np.unique(ypred, return_inverse=True)\n",
    "    \n",
    "    Ka, Kb = len(ylab), len(ypredlab)\n",
    "    K = np.maximum(Ka, Kb)\n",
    "    N = len(y)\n",
    "    \n",
    "    UA = sparse.csr_matrix((np.ones_like(y), (np.arange(y.size), y)), shape=(N,K))\n",
    "    UB = sparse.csr_matrix((np.ones_like(ypred), (np.arange(ypred.size), ypred)), shape=(N, K))    \n",
    "    \n",
    "    nA = np.array(UA.sum(axis=0)).reshape(-1)\n",
    "    nB = np.array(UB.sum(axis=0)).reshape(-1)\n",
    "\n",
    "# nAB[i][j] is read as the number of elements that belong to ith ground truth label and jth predicrted label.\n",
    "# nAB[1][0] = 1 For ground truth label with index 1 and predicted label 0 we have 1 element. i.e. 0000|1| vs 1110|0|\n",
    "\n",
    "    nAB = (UA.T @ UB).toarray()\n",
    "    nAB_rand = np.outer(nA, nB) / N\n",
    "    \n",
    "# assuming that each element has an equal probability of being assigned to any label,\n",
    "# and the expected counts are calculated based on label frequencies.\n",
    "\n",
    "\n",
    "    # Calc element-centric similarity\n",
    "    Q = np.maximum(nA[:, None] @ np.ones((1, K)), np.ones((K, 1)) @ nB[None, :]) \n",
    "    Q = 1 / np.maximum(Q, 1)\n",
    "    S = np.sum(np.multiply(Q, (nAB**2))) / N\n",
    "    \n",
    "    # Calc the expected element-centric similarity for random partitions\n",
    "    #Q = np.maximum(nA[:, None] @ np.ones((1, K)), np.ones((K, 1)) @ nB[None, :]) \n",
    "    #Q = 1 / np.maximum(Q, 1)\n",
    "    Srand = np.sum(np.multiply(Q, (nAB_rand**2))) / N\n",
    "    Scorrected = (S - Srand) / (1 - Srand)\n",
    "    return Scorrected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e71955-5a95-4790-9f4a-d4aad46032a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def louvain(Z, w1, b0, num_neighbors=100, iteration=50, device=\"cuda:0\", return_member_matrix=False, metric=\"dotsim\"):\n",
    "    num_nodes = Z.shape[0]\n",
    "    node_size = np.ones(num_nodes)\n",
    "    U = sparse.identity(num_nodes, format=\"csr\")\n",
    "    Vt = Z.copy()\n",
    "\n",
    "    while True:\n",
    "        cids_t = label_switching(\n",
    "            Z=Vt,\n",
    "            num_neighbors=num_neighbors,\n",
    "            rho=b0 / w1,\n",
    "            node_size=node_size,\n",
    "            epochs=iteration,\n",
    "            device=device,\n",
    "            metric=metric\n",
    "        )\n",
    "        _, cids_t = np.unique(cids_t, return_inverse=True)\n",
    "\n",
    "        if int(max(cids_t) + 1) == Vt.shape[0]:\n",
    "            break\n",
    "\n",
    "        num_nodes_t = len(cids_t)\n",
    "        k = int(np.max(cids_t) + 1)\n",
    "        Ut = sparse.csr_matrix((np.ones(num_nodes_t), (np.arange(num_nodes_t), cids_t)), shape=(num_nodes_t, k))\n",
    "        U = U @ Ut\n",
    "        Vt = Ut.T @ Vt\n",
    "        node_size = np.array(Ut.T @ node_size).reshape(-1)\n",
    "\n",
    "    if return_member_matrix:\n",
    "        return U\n",
    "    cids = np.array((U @ sparse.diags(np.arange(U.shape[1]))).sum(axis=1)).reshape(-1)\n",
    "    return cids\n",
    "    \n",
    "\n",
    "def find_knn_edges(emb, num_neighbors, target=None, metric=\"dotsim\", device=None):\n",
    "    k = int(np.minimum(num_neighbors + 1, emb.shape[0]).astype(int))\n",
    "    # Normalize embeddings if metric is cosine\n",
    "    if metric == \"cosine\":\n",
    "        emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "        if target is not None:\n",
    "            target = target / np.linalg.norm(target, axis=1, keepdims=True)\n",
    "\n",
    "    indices, distances = find_knn(\n",
    "        emb if target is None else target, emb, num_neighbors=k, metric=metric, device=device\n",
    "    )\n",
    "    r = np.outer(np.arange(indices.shape[0]), np.ones((1, indices.shape[1]))).astype(int)\n",
    "    r, c, distances = r.reshape(-1), indices.astype(int).reshape(-1), distances.reshape(-1)\n",
    "    if len(r) == 0:\n",
    "        return r, c, distances\n",
    "    return r, c, distances\n",
    "\n",
    "\n",
    "def find_knn(target, emb, num_neighbors, metric=\"dotsim\", device=None):\n",
    "    if metric == \"dotsim\" or metric == \"cosine\":\n",
    "        index = faiss.IndexFlatIP(emb.shape[1])\n",
    "        if metric == \"cosine\":\n",
    "            emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "            target = target / np.linalg.norm(target, axis=1, keepdims=True)\n",
    "    elif metric == \"euclidean\":\n",
    "        index = faiss.IndexFlatL2(emb.shape[1])\n",
    "    elif metric == \"manhattan\":\n",
    "        index = faiss.IndexFlatL1(emb.shape[1]) # THIS DOES NOT EXIST, CAN'T DO INDEXING FOR MANHATTAN I GUESS\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified.\")\n",
    "\n",
    "    if device is None:\n",
    "        index.add(emb.astype(np.float32))\n",
    "        distances, indices = index.search(target.astype(np.float32), k=num_neighbors)\n",
    "    else:\n",
    "        gpu_id = int(device[-1])\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, gpu_id, index)\n",
    "        index.add(emb.astype(np.float32))\n",
    "        distances, indices = index.search(target.astype(np.float32), k=num_neighbors)\n",
    "        index.reset()\n",
    "\n",
    "    return indices, distances\n",
    "\n",
    "\n",
    "def label_switching(Z, rho, num_neighbors=50, node_size=None, device=None, epochs=50, metric=\"dotsim\"):\n",
    "    num_nodes, dim = Z.shape\n",
    "    if node_size is None:\n",
    "        node_size = np.ones(num_nodes)\n",
    "    Z = Z.copy(order=\"C\").astype(np.float32)\n",
    "\n",
    "    # Normalize Z for cosine similarity without adding extra dimensions\n",
    "    if metric == \"cosine\":\n",
    "        Z1 = Z / np.linalg.norm(Z, axis=1, keepdims=True)\n",
    "        Zrho = Z1  # Use the normalized Z1 directly without adding extra dimensions\n",
    "    else:\n",
    "        Z1 = Z\n",
    "        Zrho = Z\n",
    "\n",
    "    # Perform nearest neighbor search with consistent dimensions\n",
    "    r, c, v = find_knn_edges(Zrho, target=Z1, num_neighbors=num_neighbors, metric=metric, device=device)\n",
    "    A = sparse.csr_matrix((v, (r, c)), shape=(num_nodes, num_nodes))\n",
    "\n",
    "    return _label_switching_(A.indptr, A.indices, Z, num_nodes, rho, node_size, epochs, metric=metric)\n",
    "\n",
    "    \n",
    "def _label_switching_(A_indptr, A_indices, Z, num_nodes, rho, node_size, epochs=100, metric=\"dotsim\"):\n",
    "    Nc = np.zeros(num_nodes)\n",
    "    cids = np.arange(num_nodes)\n",
    "    Vc = Z.copy()\n",
    "\n",
    "    if metric in [\"dotsim\", \"cosine\"]:\n",
    "        Vnorm = np.sum(np.multiply(Z, Z), axis=1).reshape(-1)\n",
    "\n",
    "    for nid in range(num_nodes):\n",
    "        Nc[nid] += node_size[nid]\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        order = np.random.choice(num_nodes, size=num_nodes, replace=False)\n",
    "        updated_node_num = 0\n",
    "\n",
    "        for node_id in order:\n",
    "            neighbors = A_indices[A_indptr[node_id]:A_indptr[node_id + 1]]\n",
    "            c = cids[node_id]\n",
    "            clist = np.unique(cids[neighbors])\n",
    "            next_cid = -1\n",
    "\n",
    "            if metric == \"euclidean\":\n",
    "                dqmin = float(\"inf\")\n",
    "                qself = np.sum((Z[node_id, :] - Vc[c, :]) ** 2) + rho * node_size[node_id] * (Nc[c] - node_size[node_id])                \n",
    "                dqmin = float(\"inf\")\n",
    "                # Modification: if the node is in a singleton cluster, subtract a tiny bias.\n",
    "                if Nc[c] == node_size[node_id]:\n",
    "                    qself = -1e-6  # small negative offset encourages merge\n",
    "                else:\n",
    "                    qself = np.sum((Z[node_id, :] - Vc[c, :]) ** 2) + rho * node_size[node_id] * (Nc[c] - node_size[node_id])\n",
    "            \n",
    "            elif metric == \"manhattan\":\n",
    "                dqmin = float(\"inf\")\n",
    "                qself = np.sum(np.abs(Z[node_id, :] - Vc[c, :])) + rho * node_size[node_id] * (Nc[c] - node_size[node_id])\n",
    "            else:  # dotsim or cosine\n",
    "                dqmax = 0\n",
    "                qself = np.sum(Z[node_id, :] * Vc[c, :]) - Vnorm[node_id] - rho * node_size[node_id] * (Nc[c] - node_size[node_id])\n",
    "\n",
    "            for cprime in clist:\n",
    "                if c == cprime:\n",
    "                    continue\n",
    "\n",
    "                if metric == \"euclidean\":\n",
    "                    dq = np.sum((Z[node_id, :] - Vc[cprime, :]) ** 2) + rho * node_size[node_id] * Nc[cprime] - qself\n",
    "                    if dq < dqmin:\n",
    "                        next_cid = cprime\n",
    "                        dqmin = dq\n",
    "                elif metric == \"manhattan\":\n",
    "                    dq = np.sum(np.abs(Z[node_id, :] - Vc[cprime, :])) + rho * node_size[node_id] * Nc[cprime] - qself\n",
    "                    if dq < dqmin:\n",
    "                        next_cid = cprime\n",
    "                        dqmin = dq\n",
    "                else:  # dotsim or cosine\n",
    "                    dq = (np.sum(Z[node_id, :] * Vc[cprime, :]) - rho * node_size[node_id] * Nc[cprime]) - qself\n",
    "                    if dq > dqmax:\n",
    "                        next_cid = cprime\n",
    "                        dqmax = dq\n",
    "\n",
    "            if (metric in [\"euclidean\", \"manhattan\"] and dqmin >= 0) or (metric in [\"dotsim\", \"cosine\"] and dqmax <= 1e-16):\n",
    "                continue\n",
    "\n",
    "            Nc[c] -= node_size[node_id]\n",
    "            Nc[next_cid] += node_size[node_id]\n",
    "\n",
    "            Vc[c, :] -= Z[node_id, :]\n",
    "            Vc[next_cid, :] += Z[node_id, :]\n",
    "\n",
    "            cids[node_id] = next_cid\n",
    "            updated_node_num += 1\n",
    "\n",
    "        if (updated_node_num / max(1, num_nodes)) < 1e-3:\n",
    "            break\n",
    "\n",
    "    return cids\n",
    "\n",
    "\n",
    "def proposed_method_labels(emb, device_name, metric=\"dotsim\"):\n",
    "    if metric == \"cosine\":\n",
    "        emb = emb / np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "    rpos, cpos, vpos = find_knn_edges(emb, num_neighbors=250, device=device_name, metric=metric)\n",
    "    cneg = np.random.choice(emb.shape[0], len(cpos))\n",
    "    vneg = np.array(np.sum(emb[rpos, :] * emb[cneg, :], axis=1)).reshape(-1)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(\n",
    "        np.concatenate([vpos, vneg]).reshape((-1, 1)),\n",
    "        np.concatenate([np.ones_like(vpos), np.zeros_like(vneg)]),\n",
    "    )\n",
    "    w1, b0 = model.coef_[0, 0], -model.intercept_[0]\n",
    "    return louvain(emb, w1, b0, device=device_name, metric=metric)\n",
    "\n",
    "\n",
    "def clustering_method_values(net, community_table, emb, score_keys, device_name):\n",
    "    #X = np.einsum(\"ij,i->ij\", emb, 1 / np.maximum(np.linalg.norm(emb, axis=1), 1e-24))\n",
    "    #X = emb.copy()\n",
    "\n",
    "    def method_score(key):\n",
    "        if key == \"proposed_euclidean\":\n",
    "            return calc_esim(community_table[\"community_id\"], proposed_method_labels(emb, device_name, metric=\"euclidean\"))\n",
    "        elif key == \"proposed_cosine\":\n",
    "            return calc_esim(community_table[\"community_id\"], proposed_method_labels(emb, device_name, metric=\"cosine\"))\n",
    "        elif key == \"proposed_dot\":\n",
    "            return calc_esim(community_table[\"community_id\"], proposed_method_labels(emb, device_name, metric=\"dotsim\"))\n",
    "        elif key == \"proposed_manhattan\":\n",
    "            return calc_esim(community_table[\"community_id\"], proposed_method_labels(emb, device_name, metric=\"manhattan\"))\n",
    "\n",
    "    score_dictionary = {key: method_score(key) for key in score_keys}\n",
    "    return score_dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15730d8e-ad07-4807-9948-ef0164b6cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net_and_embedding(net_filename, comm_filename, emb_filename):\n",
    "    net = sparse.load_npz(net_filename)\n",
    "    community_table = pd.read_csv(comm_filename)\n",
    "    \n",
    "    with open(emb_filename, 'rb') as f:  # open a text file\n",
    "        emb_dict = pickle.load(f) # deserialize using load()\n",
    "\n",
    "    return net, community_table, emb_dict\n",
    "    \n",
    "N=10000\n",
    "mu_values = np.round(np.arange(0.05, 1.05, 0.05),decimals=2)\n",
    "\n",
    "params = {\n",
    "    \"N\": N,\n",
    "    \"k\": 5,\n",
    "    \"maxk\":  int(np.sqrt(10 * N)),\n",
    "    \"minc\": 50,\n",
    "    \"maxc\": int(np.ceil(np.sqrt(N * 10))),\n",
    "    \"tau\": 3.0,\n",
    "    \"tau2\": 1.0,\n",
    "    \"mu\": 0.2,\n",
    "    }\n",
    "\n",
    "\n",
    "emb_params = {\n",
    "    \"method\": \"node2vec\",\n",
    "    \"window_length\": 10,\n",
    "    \"walk_length\": 80,\n",
    "    \"num_walks\": 10,\n",
    "    \"dim\": 64,\n",
    "}\n",
    "\n",
    "\n",
    "k=5 # k = {5,10,50}\n",
    "mu = 0.1\n",
    "run_no = 1\n",
    "\n",
    "path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_change_10000_{k}_3.0_minc50_immutable/Run_{run_no}/\" \n",
    "emb_path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_cosine_change_10000_{k}_3.0_minc50/Run_{run_no}/\"\n",
    "\n",
    "net_filename = path_name + f\"net_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.npz\"  # A = sp.load_npz(net_path)\n",
    "comm_filename = path_name + f\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.csv\" # pd.read_csv()\n",
    "emb_filename = emb_path_name + f\"embeddings_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{k}_mincomm_50.pkl\" # embeddings_dict\n",
    "\n",
    "#\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_0.1_k_50_mincomm_50.npz\"\n",
    "\n",
    "net, community_table, emb_dict = load_net_and_embedding(net_filename, comm_filename, emb_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8413c7aa-bd10-4d9d-9c7e-cdf24dc903a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sigma (median distance): 1.3874172\n",
      "{'proposed_dot': 0.9767038945388538, 'proposed_cosine': 0.9767038945388539}\n",
      "20.07363247871399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# Assume `emb` is your (N x D) embedding matrix\n",
    "\n",
    "t1 = time.time()\n",
    "score_keys = {\"proposed_cosine\",\"proposed_dot\"}\n",
    "for key in ['cosine']:\n",
    "    emb = emb_dict[key]\n",
    "\n",
    "    print(clustering_method_values(net, community_table, emb, score_keys,device_name=\"cuda:0\"))\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c2725-0e3c-4f0a-a581-ae4acee14ecb",
   "metadata": {},
   "source": [
    "Before we parallelize and get results for all the LFR networks of varying mixing rates and varying network densities. We will start with an example of just one network. We load the network, community information, embeddings, and run the modified K-Means using Dot, Euclidean and Cosine similarities on the embedding vectors generated using Node2Vec using Dot, Euclidean and Cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936a0fbe-f3a8-443d-aa04-847369af414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net_and_embedding(net_filename, comm_filename, emb_filename):\n",
    "    net = sparse.load_npz(net_filename)\n",
    "    community_table = pd.read_csv(comm_filename)\n",
    "    \n",
    "    with open(emb_filename, 'rb') as f:  # open a text file\n",
    "        emb_dict = pickle.load(f) # deserialize using load()\n",
    "\n",
    "    return net, community_table, emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009c8e3-af82-4f5a-a4f3-79450d5a1dc7",
   "metadata": {},
   "source": [
    "We go through 20 iterations of Kmeans, and use the best clustering of the them. The Kmeans++ (which is the standard optimized implementation) performs comparable to our Kmeans_euclidean which is our baseline for our modified version especially in the euclidean-euclidean case. When embeddings are generated using other methods, it does falter a bit. This is exciting news! Which means there could be more to uncover!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e3eef-1b75-47e3-8e83-533f3a6bdebf",
   "metadata": {},
   "source": [
    "# Parallelization to get clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bd635-1569-4f54-8eaa-eded78c7f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   0%|▊                                                                                                                                                        | 1/200 [00:17<57:51, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.05 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   1%|█▌                                                                                                                                                       | 2/200 [00:35<57:57, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.1 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   2%|██▎                                                                                                                                                      | 3/200 [00:52<56:59, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.15 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   2%|███                                                                                                                                                      | 4/200 [01:09<56:54, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.2 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   2%|███▊                                                                                                                                                   | 5/200 [01:30<1:00:08, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.25 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   3%|████▌                                                                                                                                                  | 6/200 [01:54<1:05:52, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.3 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   4%|█████▎                                                                                                                                                 | 7/200 [02:37<1:30:09, 28.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.35 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   4%|██████                                                                                                                                                 | 8/200 [03:44<2:08:47, 40.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.4 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   4%|██████▊                                                                                                                                                | 9/200 [05:57<3:40:12, 69.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.45 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   5%|███████▌                                                                                                                                              | 10/200 [07:52<4:23:55, 83.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.5 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   6%|████████▎                                                                                                                                             | 11/200 [09:45<4:51:13, 92.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.55 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   6%|████████▉                                                                                                                                            | 12/200 [11:42<5:13:41, 100.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.6 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   6%|█████████▊                                                                                                                                            | 13/200 [13:17<5:06:39, 98.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.65 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   7%|██████████▌                                                                                                                                           | 14/200 [14:55<5:04:59, 98.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.7 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   8%|███████████▏                                                                                                                                         | 15/200 [16:42<5:10:49, 100.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.75 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   8%|███████████▉                                                                                                                                         | 16/200 [18:47<5:31:43, 108.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.8 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   8%|████████████▋                                                                                                                                        | 17/200 [20:32<5:26:49, 107.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.85 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:   9%|█████████████▍                                                                                                                                       | 18/200 [22:13<5:19:43, 105.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.9 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  10%|██████████████▏                                                                                                                                      | 19/200 [24:20<5:37:27, 111.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.95 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  10%|██████████████▉                                                                                                                                      | 20/200 [25:45<5:11:34, 103.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 1.0 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  10%|███████████████▊                                                                                                                                      | 21/200 [26:02<3:52:11, 77.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.05 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  11%|████████████████▌                                                                                                                                     | 22/200 [26:20<2:57:03, 59.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.1 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  12%|█████████████████▎                                                                                                                                    | 23/200 [26:37<2:18:48, 47.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.15 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  12%|██████████████████                                                                                                                                    | 24/200 [26:55<1:52:14, 38.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.2 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  12%|██████████████████▊                                                                                                                                   | 25/200 [27:15<1:35:39, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.25 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  13%|███████████████████▌                                                                                                                                  | 26/200 [27:47<1:33:54, 32.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.3 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  14%|████████████████████▎                                                                                                                                 | 27/200 [28:26<1:39:19, 34.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.35 for embedding 'cosine'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing combinations:  14%|█████████████████████                                                                                                                                 | 28/200 [29:37<2:10:26, 45.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 2 with Mu 0.4 for embedding 'cosine'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming these functions are defined elsewhere:\n",
    "# from your_module import load_net_and_embedding, clustering_method_values\n",
    "\n",
    "# Parameters\n",
    "N = 10000\n",
    "K = 10\n",
    "mu_values = np.round(np.arange(0.05, 1.05, 0.05), decimals=2)\n",
    "params_template = {\n",
    "    \"N\": N,\n",
    "    \"k\": K,\n",
    "    \"maxk\": int(np.sqrt(10 * N)),\n",
    "    \"minc\": 50,\n",
    "    \"maxc\": int(np.ceil(np.sqrt(N * 10))),\n",
    "    \"tau\": 3.0,\n",
    "    \"tau2\": 1.0,\n",
    "}\n",
    "emb_params = {\n",
    "    \"method\": \"node2vec\",\n",
    "    \"window_length\": 10,\n",
    "    \"walk_length\": 80,\n",
    "    \"num_walks\": 10,\n",
    "    \"dim\": 64,\n",
    "}\n",
    "\n",
    "#score_keys = ['kmeans++', 'kmeans_euclidean', 'kmeans_dot', 'kmeans_cosine']\n",
    "score_keys = { \"proposed_cosine\",\"proposed_dot\"}\n",
    "\n",
    "# Output directory – one file per embedding type\n",
    "output_dir = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_cosine_change_10000_{K}_3.0_minc50/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to process a single run and mu value\n",
    "def process_run(run_no, mu):    \n",
    "    path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_change_10000_{K}_3.0_minc50_immutable/Run_{run_no}/\" \n",
    "    emb_path_name = f\"/nobackup/gogandhi/alt_means_sans_k/data/experiment_n2v_metric_cosine_change_10000_{K}_3.0_minc50/Run_{run_no}/\"\n",
    "    \n",
    "    net_filename = path_name + f\"net_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{K}_mincomm_50.npz\"  # A = sp.load_npz(net_path)\n",
    "    comm_filename = path_name + f\"community_table_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{K}_mincomm_50.csv\" # pd.read_csv()\n",
    "    emb_filename = emb_path_name + f\"embeddings_LFR_n_10000_tau1_3.0_tau2_1.0_mu_{mu}_k_{K}_mincomm_50.pkl\" # embeddings_dict\n",
    "\n",
    "    # Load network, community table, and the embedding dictionary\n",
    "    net, community_table, emb_dict = load_net_and_embedding(net_filename, comm_filename, emb_filename)\n",
    "    \n",
    "    # For each embedding in the dictionary, run clustering and prepare a result string\n",
    "    results = []\n",
    "    for emb_key, emb in emb_dict.items():\n",
    "        result = clustering_method_values(net, community_table, emb, score_keys,device_name=\"cuda:0\")\n",
    "        result_values = [result[key] for key in score_keys]\n",
    "        # Format: run_no,mu,score1,score2,...\n",
    "        result_str = f\"{run_no},{mu},\" + \",\".join(map(str, result_values))\n",
    "        results.append((emb_key, result_str))\n",
    "        print(f\"Completed Run {run_no} with Mu {mu} for embedding '{emb_key}'\")\n",
    "    return results\n",
    "\n",
    "# Function to process all run/mu combinations sequentially with tqdm and immediate file writing\n",
    "def process_all_combinations_sequential():\n",
    "    # Generate all combinations of run numbers and mu values (modify as needed)\n",
    "    #runs_mu_combinations = [(run_no, mu) for run_no in [3] for mu in mu_values[15:]]\n",
    "    runs_mu_combinations = [(run_no, mu) for run_no in range(1, 11) for mu in mu_values]\n",
    "    total_combinations = len(runs_mu_combinations)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each combination sequentially with a tqdm progress bar\n",
    "    for run_no, mu in tqdm(runs_mu_combinations, total=total_combinations, desc=\"Processing combinations\"):\n",
    "        run_results = process_run(run_no, mu)\n",
    "        for emb_key, result_str in run_results:\n",
    "            output_file = os.path.join(output_dir, f\"n2v_{emb_key}_altmeans_clustering.txt\")\n",
    "            # Write header if file doesn't exist\n",
    "            if not os.path.exists(output_file):\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    header = \"run_no,mu,\" + \",\".join(score_keys) + \"\\n\"\n",
    "                    f.write(header)\n",
    "            # Append result line and flush immediately\n",
    "            with open(output_file, \"a\") as f:\n",
    "                f.write(result_str + \"\\n\")\n",
    "    \n",
    "    total_elapsed_time = time.time() - start_time\n",
    "    print(f\"All combinations processed sequentially. Total elapsed time: {total_elapsed_time:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_combinations_sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1743a0dc-f6cf-4d88-b263-3decbb9453dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8 , 0.85, 0.9 , 0.95, 1.  ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1a08a9c-77dc-4916-b200-a2c3a4d1e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Run 1 with Mu 0.1 for embedding 'dot'\n",
      "Completed Run 1 with Mu 0.1 for embedding 'euclidean'\n",
      "Completed Run 1 with Mu 0.1 for embedding 'cosine'\n",
      "Direct call results: [('dot', '1,0.1,0.930774835825718,0.9078791558988919,0.8109024487542578,0.8850640546357088'), ('euclidean', '1,0.1,1.0,1.0,0.47745189633168655,1.0'), ('cosine', '1,0.1,0.9577367930235333,0.9694957803036819,0.7632839896711154,1.0')]\n",
      "72.08514332771301\n"
     ]
    }
   ],
   "source": [
    "# Instead of using ProcessPoolExecutor, run the function directly:\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "results = process_run(1, 0.1)\n",
    "print(\"Direct call results:\", results)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160f34b-e176-413c-b994-3263a5309472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmeans_env",
   "language": "python",
   "name": "kmeans_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
